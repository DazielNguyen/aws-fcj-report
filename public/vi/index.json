[
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders (Track 2: Migration \u0026amp; Modernization)” Mục Đích Của Sự Kiện Hoàn thành quá trình di chuyển và hiện đại hóa quy mô lớn với AWS Hiện đại hóa ứng dụng bằng các công cụ hỗ trợ AI tạo sinh Thảo luận nhóm: Hiện đại hóa ứng dụng: Đẩy nhanh quá trình chuyển đổi kinh doanh Chuyển đổi VMware với công nghệ hiện đại hóa đám mây dựa trên AI Bảo mật AWS ở quy mô lớn: Từ phát triển đến sản xuất Danh Sách Diễn Giả Nguyen Van Hai - Director of Software Engineering, Techcombank Nguyen The Vinh - Co-Founder \u0026amp; CTO, Ninety Eight Nguyen Minh Nganh - AI Specialist, OCB Nguyen Manh Tuyen - Head of Data Application, LPBank Securities Nội Dung Nổi Bật 1. Tìm hiểu về các chiến lược di chuyển và hiện đại hóa quy mô lớn với AWS thông qua các nghiên cứu điển hình thực tế từ Techcombank. Hành trình hiện đại hóa của Techcombank\nAssess: Đánh giá được môi trường kiểm kê, và xác định được khoảng trống. Mobilize: Thiết lập CCoE, xác định hàng rào, xây dựng sự lưu loát của điện toán đám mây. Migrate \u0026amp; Modernize: Ưu tiên khối lượng công việc có tác động cao Reinvent: AI, tự động hóa, sản phẩm dữ liệu, mô hình doanh mới. Generative trong hiện đại hóa quy mô.\nCode Transformation: Java 8 -\u0026gt; 21, .NET -\u0026gt; .NET 8 Dependency Mapping: Lập bản đồ phụ thuộc để phân tích tự động các mối quan hệ của hệ thống. Environment Assessment: Amazon có hàng ngàn dịch vụ hiện tại hóa với AI có thể đáp ứng được cho doanh nghiệp. Giải pháp và chiến lược mà Techcombank đã ứng dụng trong việc dùng các dịch vụ của AWS.\nAmazon EKS Amazon Aurora MySQL Amazon MSK Amazon ElastiCache for Redis OSS. Tổng quan về chiến lược Modernization Strategy Blueprint. Hiện đại hóa với các công nghệ gốc của AWS.\nAlign: Tài trợ việc triển khai và động lực doanh nghiệp. | Assess: Hiểu rõ về con người, quy trình, và công nghệ | Mobilize: CoE, quản trị, đào tạo | Modernize: Replatform, refactor, rebuild | Reinvent: Data, AI và hiện đại hóa các ứng dụng cho sự đổi mới 2. Tìm hiểu về việc hiện đại hóa ứng dụng bằng các công cụ Generative AI, với những hiểu biết thực tế từ VPBank Hiện đại hóa là quá trình chuyển đổi dần dần các ứng dụng để đạt được lợi ích về tính khả dụng, khả năng mở rộng, tính linh hoạt trong kinh doanh và tối ưu hóa chi phí khi chạy trên nền tảng đám mây Top 4 trường hợp sử dụng hàng đầu - Hiện đại hóa ứng dụng với Generative AI.\nUse case 1: Streamline VMware Migration with AWS Transform for VMware\nĐẩy nhanh quá trình di chuyển và hiện đại hóa cơ sở hạ tầng với khám phá thông minh và thực thi tự động\nRút ngắn thời gian di chuyển VMware với tính năng tự động hóa thông minh của AWS Transform.\nChuyển đổi các cấu hình mạng phức tạp chỉ trong vài giờ thay vì vài tuần nhờ tính năng khám phá, ánh xạ phụ thuộc và lập kế hoạch làn sóng tự động do AWS cung cấp.\nMở rộng quy trình di chuyển của bạn với tính năng tạo nhóm bảo mật tự động, lựa chọn phiên bản EC2 thông minh và các tùy chọn triển khai linh hoạt, bao gồm cấu hình VPC dạng hub-and-spoke hoặc cấu hình VPC riêng biệt.\nCải thiện thời gian thực hiện lên đến 90%, đồng thời giảm 80% công sức thủ công.\nUse case 2: GenAl Development with AWS Serverless and Container Solutions\nXây dựng các ứng dụng GenAl sẵn sàng cho doanh nghiệp trên nền tảng AWS Serverless và Container\nAWS cung cấp hai giải pháp mạnh mẽ cho việc phát triển và triển khai ứng dụng GenAl:\nKhông máy chủ với AWS Bedrock: Phát triển và triển khai nhanh chóng các ứng dụng GenAl bằng AWS Lambda, ECS với Fargate, Step Functions và EventBridge. Lý tưởng cho chatbot, tạo tài liệu và xử lý nội dung thông minh. Tận dụng các bản cập nhật và kiến ​​trúc tham chiếu mới nhất của AWS Bedrock.\nDựa trên container với Amazon EKS: Xây dựng, đào tạo và chạy các ứng dụng GenAl trên Kubernetes, tận dụng khả năng điều phối mạnh mẽ của nó. Sử dụng các công cụ nguồn mở và dịch vụ đám mây gốc cho khối lượng công việc GenAl có khả năng mở rộng. Triển khai linh hoạt trên cả môi trường đám mây và tại chỗ với sự đổi mới liên tục từ cộng đồng OSS.\nChọn một trong hai cách tiếp cận hoặc kết hợp cả hai để phù hợp nhất với yêu cầu ứng dụng GenAl cụ thể của bạn và đẩy nhanh hành trình AI của bạn.\nUse case 3: Revolutionize NET Modernization with AWS Transform for NET\nChuyển đổi các ứng dụng Windown cũ sang Cloud-native với tự động hóa được hỗ trợ bởi AI-powered.\nHiện đại hóa các ứng dụng chạy trên Windows nhanh hơn tới 4 lần với AWS Transform for NET. Tận dụng khả năng tự động hóa của AI để phân tích các phụ thuộc, tái cấu trúc mã và tối ưu hóa cho việc triển khai Linux, đồng thời cắt giảm chi phí cấp phép tới 40%. Chuyển đổi hàng trăm ứng dụng song song với khả năng kiểm tra và xác thực tự động - từ các ứng dụng MVC cũ sang các dịch vụ WCF. Các tính năng nâng cao bao gồm hiện đại hóa Ul tự động, xử lý gói riêng và lập kế hoạch sóng thông minh, mang lại khả năng hiện đại hóa toàn diện với tốc độ vượt trội. Use case 4: Nâng cao Kỹ thuật Nền tảng với Gen Al \u0026amp; IDP\nTận dụng sức mạnh của các trợ lý thông minh như AWS Transform Developer với Nền tảng phát triển nội bộ.\nViệc mở rộng quy mô hiện đại hóa ở cấp độ doanh nghiệp đòi hỏi thời gian và đầu tư để phát triển Nền tảng Phát triển Nội bộ (IDP). Gartner dự đoán rằng đến năm 2026, 80% các tổ chức kỹ thuật phần mềm sẽ thành lập các nhóm nền tảng với tư cách là nhà cung cấp nội bộ các dịch vụ, thành phần và công cụ có thể tái sử dụng để triển khai ứng dụng.\nKhai thác sức mạnh của các trợ lý thông minh như AWS Transform Developer với IDP để:\nTạo quy trình làm việc và tự động hóa các tác vụ lặp lại.\nTìm hiểu các phương pháp hay nhất của IDP từ các tổ chức hàng đầu, chẳng hạn như Adobe, Expedia, JPMC và Goldman Sachs.\nHiểu rõ các bản thiết kế container và kiến ​​trúc tham chiếu của AWS để mang lại tốc độ và khả năng mở rộng nhanh chóng cho sáng kiến ​​hiện đại hóa quy mô doanh nghiệp.\nCác động lực hiện đại hóa phổ biến\nGiảm chi phí\nGiảm/loại bỏ chi phí bản quyền Windows \u0026amp; SQL Server Xây dựng kiến trúc khớp với tải thực tế để tối ưu chi phí Tận dụng kiến trúc ARM64 để có hiệu năng/giá thành tốt hơn Tăng tốc độ đổi mới\nTách monolith thành các dịch vụ nhỏ hơn / microservices Tận dụng công nghệ mới và các tính năng ngôn ngữ C# Tự động hóa các quy trình thủ công Cải thiện khả năng mở rộng\nMở rộng từng thành phần / dịch vụ riêng lẻ Mở rộng chi tiết với containers / serverless Thu hút và giữ chân nhân tài\n3. Nhận thông tin chuyên sâu từ các chuyên gia hàng đầu trong ngành thông qua các buổi thảo luận chuyên đề về hiện đại hóa ứng dụng .NET Framework so với đa nền tảng .NET\n.NET Framework:\nChỉ hệ điều hành Windows Phiên bản 1.0 được phát hành vào năm 2002 Phiên bản cuối cùng là 4.8*, phát hành năm 2019 Cài đặt nguyên khối - Số lượng lớn các thư viện được cài đặt cùng một lúc. EC2, Elastic Beanstalk, ECS và EKS. .NET (trước đây là .NET Core)\nĐa nền tảng (Windows, Linux, MacOS) Phiên bản 1.0 được phát hành năm 2016 Phiên bản GA hiện tại là 8.0, được phát hành vào năm 2023 Hỗ trợ nhiều phiên bản để cài đặt Hầu hết các thư viện được phân phối riêng lẻ EC2, Elastic Beanstalk, ECS, EKS, Lambda Fargate AWS Transform: Trí thông minh được phối hợp\nTrải nghiệm web thống nhất -\u0026gt; Tự động hóa đầu cuối -\u0026gt; Cơ quan chuyên trách -\u0026gt; Định hướng mục tiêu -\u0026gt; Con người trong vòng lặp -\u0026gt; Hợp tác được đơn giản hóa AWS Transform cho .NET\nLợi ích khách hàng\nGiảm chi phí vận hành lên đến 40% Loại bỏ thương mại giấy phép hệ điều hành Tiếp cận nhóm nhà phát triển lớn hơn Quy mô đám mây và hiệu suất. Lợi ích kỹ thuật\nHỗ trợ khắc phục lỗ hổng bảo mật Hỗ trợ đa nền tảng: Windows, macOS, Linux (x86-64, arm64) Tương thích với x86-64 và arm64 LightweightContainer Kiến trúc Lambda Serverless Hoàn thành nâng cấp ngôn ngữ trong vài phút thông qua Amazon Q\nĐẩy nhanh hiện đại hóa ứng dụng Nâng cấp Ngôn ngữ Tự động (Java, .NET) Giảm Nợ Kỹ thuật Tiết kiệm Chi phí và Hiệu quả Vận hành Nâng cao Lợi thế Cạnh tranh Ứng dụng Kiro: Giải pháp cho việc phát triển theo thông số kĩ thuật\nKiro giúp các nhà phát triển và nhóm kỹ thuật vận chuyển phần mềm chất lượng cao với các tác nhân AI. Kiro biến lời nhắc của bạn thành các yêu cầu rõ ràng, thiết kế hệ thống và các nhiệm vụ riêng biệt Lặp lại với Kiro trên thông số kỹ thuật và kiến ​​trúc của bạn Các tác nhân Kiro triển khai thông số kỹ thuật trong khi vẫn giúp bạn kiểm soát. Agent hook\nPhân quyền các tác vụ cho các tác nhân Al được kích hoạt khi có sự kiện như \u0026rsquo;lưu tệp' Các tác nhân tự động thực thi ở chế độ nền dựa trên các lời nhắc được xác định trước của bạn Các hook tác nhân giúp bạn mở rộng quy mô công việc bằng cách tạo tài liệu, kiểm tra đơn vị hoặc tối ưu hóa hiệu suất mã Quản lí ngữ cảnh nâng cao\nKết nối với tài liệu, cơ sở dữ liệu, API và nhiều hơn nữa với tích hợp MCP gốc Cấu hình cách bạn muốn các tác nhân Kiro tương tác với từng dự án thông qua các tệp chỉ đạo Thả một hình ảnh về thiết kế Ul của bạn hoặc một bức ảnh về buổi thảo luận kiến ​​trúc của bạn và Kiro có thể sử dụng nó để hướng dẫn việc triển khai Sức mạnh, tính linh hoạt và bảo mật\nTương thích với VS code\nKiro hỗ trợ plugin, theme và cài đặt VS Code Open VSX trong môi trường Al-ready được sắp xếp hợp lý Các mô hình Claude tiên tiến\nLựa chọn giữa các mô hình Claude Sonnet 3.7 hoặc Sonnet 4, với nhiều tùy chọn hơn sẽ sớm được bổ sung Bảo mật cấp doanh nghiệp\nKiro được xây dựng và vận hành bởi AWS Các trường hợp sử dụng\nXây dựng ứng dụng mới\nNhanh chóng chuyển từ nguyên mẫu sang mã sản xuất và triển khai, với các phương pháp hay nhất được tích hợp sẵn, bao gồm thiết kế có cấu trúc, tài liệu hướng dẫn hoặc phạm vi kiểm thử Xây dựng trên các ứng dụng hiện có\nVới thông số kỹ thuật và quản lý ngữ cảnh thông minh, Kiro giúp bạn dễ dàng tích hợp và xây dựng trên các ứng dụng hiện có mà vẫn duy trì tính nhất quán Tái cấu trúc và hiện đại hóa\nKiro hiểu rõ cơ sở mã của bạn và có thể hướng dẫn bạn chính xác trong việc tái cấu trúc hơn một triệu cơ sở mã LOC 4. Tìm hiểu về hiện đại hóa đám mây dựa trên AI dành riêng cho môi trường VMware Trạng thái tương lai của khối lượng công việc VMware của bạn\nRELOCATE: Amazon EVS | REHOST: Amazon EC2 | REPLATFORM TO CONTAINERS: Amazon ECS or Amazon EKS | REPLATFORM TO MANAGED SERVICES: Amazon RDS, Amazon FSx, Amazon WorkSpaces, and more | REFACTOR: Modern Application =\u0026gt; Áp dụng nhanh chóng, nền tảng của lợi ích đám mây và ROI nhanh....................----\u0026gt;....................Tất cả các lợi ích gốc của đám mây và ROl cao Chuyển đổi AWS cho VMware\nHiện đại hóa khối lượng công việc VMware lên Amazon EC2 với các tác nhân AI được thiết kế riêng Tự động hóa và đơn giản hóa các tác vụ chuyển đổi Giảm chi phí và phí cấp phép với Amazon EC2 Nâng cao bảo mật, khả năng mở rộng và phục hồi Thúc đẩy đổi mới với hơn 200 dịch vụ gốc của AWS Lập bản đồ công nghệ gốc từ VMware sang AWS\nMột cách tiếp cận dựa trên AI của agentic để hiện đại hóa VMware\n1. Kết nối với môi trường VMware của bạn | 2. Phân tích khối lượng công việc, sự phụ thuộc và mức độ sẵn sàng | 3. Chuyển đổi cấu hình mạng VMware sang các cấu trúc AWS gốc | 4. Tạo các kế hoạch sóng thông minh dựa trên sự phụ thuộc của ứng dụng | 5. Xác thực với nhóm của bạn, sau đó thực hiện =\u0026gt; Chuyển đổi từng bước với xác thực human-in-the-loop Lí do AWS Transform dành cho việc di chuyển sang VMware?\nChi phí thấp hơn\nLoại bỏ phí cấp phép VMware Tối ưu hóa chi phí cơ sở hạ tầng với khả năng điều chỉnh kích thước phiên bản do AI điều khiển Di chuyển nhanh hơn\nTăng tốc chuyển đổi mạng lên đến 80 lần Giảm thiểu gián đoạn, bảo toàn tính toàn vẹn của ứng dụng và đẩy nhanh quá trình chuyển đổi Cải thiện bảo mật\nTăng cường bảo mật với nền tảng đám mây gốc Di chuyển an toàn với quy trình xác thực human-in-the-loop Đổi mới ở quy mô lớn\nGiảm nợ kỹ thuật và xây dựng các ứng dụng hiện đại, có khả năng mở rộng Tích hợp liền mạch với hơn 200 dịch vụ gốc của AWS như data lakes, phân tích nâng cao và AI/ML 5. Kết nối và học hỏi trực tiếp từ các Kiến trúc sư Giải pháp AWS và các chuyên gia trong ngành Phần này các chuyên gia đưa ra những vấn đề khó khăn khi những bước đầu triển khai hiện đại hóa toàn bộ hệ thống từ on-premises lên AWS.\nHọ đưa ra những kế hoạch và chiến lược cụ thể ở từng phần, và họ chuyển những phần quan trọng nhất và thực hiện nó trước. Trong đó họ cũng tuân thủ các quy định và luật pháp hiện hành trong việc quản lí và không thu thập thông tin người dùng. Khi họ đưa lên AWS điều quan trọng nhất là họ có thể mở rộng quy mô của mình rất nhanh, và do đó họ nhận được rất nhiều lợi nhuận khi chuyển lên môi trường AWS. Và việc ứng dụng AI hiện nay rất hiệu quả trong công việc kinh doanh của họ, như anh Vinh đã ứng dụng AI trong việc nhận biết những giao dịch có khả năng lừa đảo, chống Hacker trong Blockchain. 6. Hiểu các phương pháp hay nhất về bảo mật AWS từ phát triển đến môi trường sản xuất Những Gì Học Được Khung 5 bước: Align → Assess → Mobilize → Modernize → Reinvent. GenAI-assisted modernization: code transformation (Java 8→21, .NET→8), dependency mapping, environment assessment. Ưu tiên workloads tác động cao, human-in-the-loop, đo ROI. Tư Duy Thiết Kế Problem→Pilot→Scale; ưu tiên value-first. Strangler Fig refactor từng phần; event-driven mindset. Platform thinking/IDP, security-by-design, governance sớm. Kiến Trúc Kỹ Thuật Microservices, containers (EKS/ECS/Fargate), serverless (Lambda/Step Functions/EventBridge). Data: Aurora MySQL, MSK (Kafka), ElastiCache (Redis). VMware→AWS: rehost EC2 → replatform containers/managed → refactor app. Multi-arch (x86_64 + ARM64), observability end-to-end. Chiến Lược Hiện Đại Hóa Assess/Mobilize/MM/Reinvent (Techcombank blueprint). AWS Transform: for VMware \u0026amp; .NET (tự động hóa di trú/kiểm thử/UL modernization). Cost-first: bỏ license Windows/SQL, right-size, ARM64. Scale \u0026amp; Innovate: tách monolith, automation CI/CD, adopt GenAI. Ứng Dụng Vào Công Việc Lập migration backlog theo ROI; chọn pilot nhỏ. Chuẩn hóa container baseline (EKS) + Bedrock pattern cho GenAI. Dùng Amazon Q/Transform để nâng cấp ngôn ngữ \u0026amp; refactor nhanh. Thiết kế IDP nội bộ: template dịch vụ, golden path, policy guardrails. Trải nghiệm trong event “GenAI-powered Migration \u0026amp; Modernization mang lại cái nhìn toàn diện về cách chuyển đổi ứng dụng \u0026amp; DB ở quy mô doanh nghiệp. Điểm nổi bật: demo tự động hóa di chuyển VMware/.NET, kiến trúc tham chiếu serverless–container, bài học định lượng ROI và mô hình governance thực chiến, cùng case study giúp rút ngắn thời gian di chuyển và giảm chi phí đáng kể.”\nHọc hỏi từ các diễn giả có chuyên môn cao Techcombank: vận hành theo CCoE, đo business outcomes, lộ trình 5 bước. Ninety Eight: AI chống gian lận, security posture mạnh, realtime. OCB/LPBankS: data products, automation, cloud scale an toàn. Trải nghiệm kỹ thuật thực tế Thấy rõ dependency mapping, wave planning, auto SG/EC2 sizing, hub-and-spoke VPC. Auto code upgrade, cross-platform .NET, UI modernization tự động. Ứng dụng công cụ hiện đại AWS Transform (VMware/.NET), Amazon Q (auto language upgrade). Bedrock, Lambda, ECS/Fargate, EKS, Step Functions, EventBridge. Aurora, MSK, ElastiCache, EC2; IDP tooling; Kiro (spec→tasks/agents, MCP). Kết nối và trao đổi Chốt best practices từ SA \u0026amp; ngân hàng lớn; checklist governance/security. Kết nối để mentorship, pattern reuse, đối chiếu ROI \u0026amp; benchmark. Event tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống.\nChiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống.\nCác công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại.\nModernize có chiến lược: đo lường ROI, ưu tiên theo giá trị.\nTự động hóa + GenAI rút ngắn thời gian, giảm nợ kỹ thuật.\nPlatform/IDP là đòn bẩy quy mô; security-by-default không thể thiếu.\nHuman-in-the-loop đảm bảo an toàn khi tự động hóa diện rộng.\nMột số hình ảnh khi tham gia sự kiện Hơn 400 nhà phát triển công nghệ đầy nhiệt huyết tại Thành phố Hồ Chí Minh, văn phòng AWS (Tầng 36) đã tụ họp để theo dõi phiên họp toàn thể trực tiếp từ Hà Nội, cùng chia sẻ sự phấn khích và kiến ​​thức về AWS Cloud Day Vietnam 2025\nTổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Văn Anh Duy\nSố điện thoại: 0387 883 041\nEmail: duynguyenvananh@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Trí Tuệ Nhân Tạo\nLớp: SE181823\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Chuyển hướng lưu lượng ra Internet thông qua một transparent forward proxy bởi Vijay Menon | vào ngày 08 tháng 09 năm 2025 | trong Amazon VPC, AWS Transit Gateway, AWS Transit Gateway network manager, Networking \u0026amp; Content Delivery | Permalink | Share\nCentralized egress là nguyên tắc sử dụng một điểm kiểm tra chung, duy nhất cho toàn bộ lưu lượng mạng đi ra Internet. Cách tiếp cận này có lợi về mặt bảo mật vì nó hạn chế việc phơi lộ tới các tài nguyên độc hại có thể truy cập từ bên ngoài, như hạ tầng malware command and control (C\u0026amp;C). Hoạt động kiểm tra này thường được thực hiện bởi firewall như AWS Network Firewall, và khách hàng thường cũng muốn chèn một forward proxy trên đường đi có hoặc không có firewall. Proxy có thể hoạt động ở hai chế độ: chế độ explicit proxy, trong đó mọi client cần truy cập Internet được cấu hình dùng explicit proxy và gửi lưu lượng outbound được hỗ trợ thông qua cấu hình explicit proxy. Một triển khai như vậy được mô tả trong bài, How to set up an outbound VPC proxy with domain whitelisting and content filtering. Tuy nhiên, có những hệ thống không thể cấu hình explicit proxy, và khách hàng thường tìm cách để transparently redirect lưu lượng từ những hệ thống như vậy sang Internet thông qua proxy.\nTrong bài viết này, tôi giải thích một kiến trúc có thể dùng để triển khai proxy trên đường egress ra Internet và transparently lưu lượng tới đó bằng Web Cache Communication Protocol (WCCP). Tôi sẽ trình bày tổng quan khái niệm về việc triển khai transparent proxy với WCCP trong kiến trúc dựa trên AWS Transit Gateway. Các chi tiết triển khai cụ thể có thể khác nhau tùy theo yêu cầu của tổ chức và công nghệ bạn chọn.\nCác trường hợp sử dụng thực tế Dưới đây là ba trường hợp sử dụng thực tế.\nSecure internet access: Tổ chức có thể dùng kiến trúc này để đảm bảo toàn bộ lưu lượng Internet outbound đi qua các kiểm soát bảo mật mà không cần cấu hình explicit proxy trên từng thiết bị client.\nData loss prevention: Kiểm tra lưu lượng transparently cho phép doanh nghiệp phát hiện và chặn dữ liệu nhạy cảm rời khỏi mạng, ngay cả khi các endpoint không hỗ trợ cấu hình explicit proxy.\nRegulatory compliance: Các ngành công nghiệp có yêu cầu tuân thủ nghiêm ngặt có thể thực hiện kiểm tra và ghi nhật ký liên tục tất cả lưu lượng mạng để đáp ứng các tiêu chuẩn theo quy định.\nĐiều kiện tiên quyết Trước khi bắt đầu, bạn nên quen thuộc với các khái niệm và dịch vụ mạng của AWS sau:\nAmazon Virtual Private Clouds (Amazon VPCs) Route tables AWS Transit Gateway Transit Gateway Connect attachments AWS Network Firewall NAT Gateway Thiết bị ảo của bên thứ ba (WCCP-compliant routers and proxy servers) chức năng WCCP. Tổng quan về kiến trúc Kiến trúc tập trung vào một Egress VPC chứa các WCCP-compliant virtual routers và proxy server chạy trên Amazon Elastic Compute Cloud (Amazon EC2). Các virtual router này redirect lưu lượng tới proxy bằng WCCP. Thiết lập này cho phép kiểm tra minh bạch và lọc lưu lượng truy cập mà không cần thay đổi cấu hình phía máy khách. Hình 1 cho thấy sơ đồ, theo sau là các chi tiết của kiến trúc.\nHình 1: Sơ đồ kiến trúc tổng thể\nCác thành phần chính Transit Gateway: Transit Gateway đóng vai trò hub trung tâm cho kết nối mạng, cho phép quản lý đơn giản hóa các kết nối giữa VPCs và mạng on-premises. Trong kiến trúc của chúng tôi, Transit Gateway định tuyến lưu lượng giữa nhiều Spoke VPCs, cũng như giữa Spoke VPCs và Internet thông qua Egress VPC để kiểm tra.\nTransit Gateway Connect attachments: Connect attachment cung cấp khả năng tích hợp thiết bị ảo bên thứ ba với Transit Gateway. Trong thiết kế của chúng tôi, các attachments:\nKết nối Transit Gateway với WCCP-compliant routers thông qua Generic routing encapsulation (GRE) chạy trên Connect attachment Cho phép chuyển hướng lưu lượng mà không cần sửa đổi route table trong từng VPC Mang lại linh hoạt cho mở rộng và tính sẵn sàng cao Bạn có thể tham khảo bài, Simplify SD-WAN connectivity with AWS Transit Gateway Connect, như làm nền tảng để triển khai Transit Gateway với Connect attachments. Sau đó, bạn có thể sửa đổi cách triển khai để phù hợp với các yêu cầu được nêu trong bài này.\nEgress VPC: Egress VPC là môi trường chuyên biệt:\nChứa các WCCP-compliant routers and proxy servers chạy trên Amazon EC2 trong private subnet Chứa firewall trong các private subnet riêng Thực thi chính sách bảo mật tập trung bằng proxy và firewall Sử dụng NAT Gateway trong public subnet để kết nối Internet thông qua Internet Gateway (IGW) WCCP-compliant routers running on Amazon EC2: Đây là thành phần nòng cốt của triển khai transparent proxy:\nNằm inline trên đường đi của lưu lượng từ Spoke VPCs ra Internet Intercept lưu lượng dựa trên chính sách đã cấu hình Redirect các loại lưu lượng cụ thể tới proxy server Trả lưu lượng đã xử lý về đường đi ban đầu Proxy servers running on Amazon EC2: Đây là các thiết bị ảo dựa trên Amazon EC2 hoạt động như forward proxy (ví dụ Squid) tương tác và và nhận lưu lượng được chuyển hướng từ thiết bị định tuyến WCCP đã đề cập trước đó. Sử dụng WCCP, chúng áp các chính sách cấu hình cho toàn bộ lưu lượng egress và chuyển tiếp tới chức năng bảo mật tiếp theo trên đường đi. Trong ví dụ này, chúng tôi sử dụng AWS Network Firewall. Tuy nhiên, các proxy này có thể daisy chain với các hệ thống bảo mật/kiểm tra khác, như hệ thống Data Loss Protection (DLP), trên đường đi trước khi lưu lượng được định tuyến ra Internet.\nKết nối Như thể hiện ở Hình 1, Spoke VPCs kết nối tới Transit Gateway bằng VPC attachment. Các attachment này được associate với Spoke VPC Route Table (việc định tuyến sẽ được giải thích ở phần sau). Egress VPC kết nối tới cùng Transit Gateway bằng VPC attachment, và một Connect attachment được cấp phát giữa Transit Gateway và Egress VPC qua VPC attachment này. Connect attachment này được dùng để thiết lập GRE tunnel giữa Transit Gateway và thiết bị ảo trong Egress VPC, đóng vai trò WCCP router. Egress VPC này có kết nối Internet thông qua IGW đính kèm.\nĐịnh tuyến (tham khảo Hình 1) Spoke VPCs: Mỗi Spoke VPC cần truy cập Internet có các subnet gắn với route table chứa default route trỏ tới Transit Gateway được gắn với VPC đó. Cấu hình này định tuyến toàn bộ lưu lượng đi Internet tới Transit Gateway, nơi VPC attachment của Spoke VPC được gắn với Transit Gateway Spoke Route Table.\nTransit Gateway Configuration:\nTransit Gateway Spoke Route Table chứa các route được propagate cho tất cả Spoke VPCs và một default route được propagate từ Connect attachment. Default route này được tạo bởi WCCP virtual appliance trong Egress VPC và được advertised tới Transit Gateway thông qua BGP peering trên GRE tunnel.\nTrên Transit Gateway, Egress VPC attachment được gắn với Egress Route Table. Bảng này chứa route được propagate tới Egress VPC CIDR từ Egress VPC attachment, cũng như các route được propagate tới toàn bộ Spoke VPC CIDR từ các attachment tương ứng.\nConnect attachment được gắn với route table riêng của nó. Route table này chứa các route của Spoke VPC được propagate cũng như default route advertised bởi WCCP router trên phiên BGP thông qua GRE tunnel.\nEgress VPC Configuration: Egress VPC cần cấu hình định tuyến bổ sung để kích hoạt chức năng transparent proxy.\nThiết bị WCCP router trong private subnet thiết lập GRE tunnel với Transit Gateway và tạo phiên BGP peering.\nThông qua các phiên BGP này, WCCP router advertise tuyến đường default route đến Transit Gateway và nhận toàn bộ các tiền tố của Spoke VPC.\nWCCP router chuyển hướng lưu lượng đi Internet tới forward proxy trong cùng subnet bằng WCCP (thảo luận chi tiết sẽ được đưa ra sau trong bài này).\nSubnet-specific Routing: private subnets (WCCP Router và Proxy servers).\nRoute table có các entry cho Transit Gateway CIDR connect attachment peers trỏ về Transit Gateway.\nDefault route trỏ tới firewall ở private subnet riêng.\nPrivate subnets (firewalls):\nDefault route trỏ tới NAT Gateway trong public subnet thuộc AWS Availability Zone’s (AZ’s) tương ứng.\nCác định tuyến tới WCCP router ENI trong cùng AZ cho lưu lượng chiều về không khớp quy tắc chuyển hướng WCCP.\nPublic Subnets (NAT Gateways):\nDefault route trỏ tới IGW.\nCác định tuyến tới firewall endpoint trong cùng AZ cho lưu lượng chiều về không khớp quy tắc chuyển hướng WCCP.\nChuyển hướng WCCP Toàn bộ lưu lượng đi Internet tới các định tuyến WCCP sẽ được đánh giá theo các quy tắc chuyển hướng WCCP đã cấu hình và được chuyển tiếp tới proxy trong cùng subnet. Để dự phòng, các định tuyến WCCP này cấu hình chuyển hướng WCCP để kết nối với proxy ở AZ khác. Chuyển hướng WCCP có thể được cấu hình để xử lý toàn bộ lưu lượng được hỗ trợ hoặc các loại lưu lượng được chọn. Cơ chế cấu hình thay đổi tùy nhà cung cấp thiết bị ảo WCCP. Lưu lượng tới proxy sẽ được đánh giá và xử lý theo cấu hình rồi chuyển tiếp tới firewall trên đường ra Internet. Như đã đề cập, nếu cần, proxy có thể chain với các chức năng khác như DLP.\nHướng dẫn gói tin Bức hình sau phác thảo hành trình của gói tin.\nHình 2: Sơ đồ kiến ​​trúc với luồng gói tin\nForward path: Phần này giải thích cách gói tin đi từ tài nguyên trong Spoke VPC tới đích trên Internet thông qua proxy và firewall trong Egress VPC.\n(A) Lưu lượng từ nguồn trong Spoke VPCs đi về Internet theo default route của subnet route table và đi vào Transit Gateway.\n(B) Khi nó ở trong Transit Gateway, nó đi theo tuyến đường trong Spoke Route Table trên Transit Gateway, bảng này chuyển tiếp lưu lượng tới Transit Gateway Connect attachment. Có nhiều GRE tunnel chạy trên Connect attachment, tất cả đều advertise default route tới Transit Gateway, do đó Transit Gateway dùng Equal Cost Multi-Pathing (ECMP) để gửi lưu lượng tới WCCP virtual appliance trong Egress VPC.\n(C) WCCP-virtual appliance chặn lưu lượng và xác định có cần kiểm tra hay không. Lưu lượng cần kiểm tra được redirect tới proxy server, nơi áp dụng security policy, content filtering, hoặc các kiểm soát khác trước khi chuyển tiếp tới Network Firewall.\n(CD) Lưu lượng không khớp quy tắc chuyển hướng WCCP sẽ thoát khỏi WCCP virtual appliance và đi trực tiếp tới Network Firewall theo subnet route table.\n(D) Lưu lượng đã qua proxy được Source NATed sang địa chỉ IP của proxy và rời proxy tới Network Firewall theo subnet route table. Bảng này có default route trỏ tới Network Firewall endpoint trong cùng AZ của Egress VPC.\n(E) Network Firewall kiểm tra lưu lượng và, nếu được phép, gửi tới NAT Gateway trong cùng AZ của Egress VPC theo default route cấu hình trong subnet route table của nó.\n(F) NAT Gateway thực hiện Source NAT trên lưu lượng và gửi tới đích trên Internet.\nReverse path: Phần này giải thích cách gói tin chiều về đi từ Internet tới tài nguyên trong Spoke VPC thông qua proxy và firewall trong Egress VPC.\n(G) Lưu lượng chiều về từ Internet đi vào chính NAT Gateway đó do Source NAT.\n(H) Theo subnet route table, NAT Gateway chuyển tiếp lưu lượng tới Network Firewall trong cùng AZ.\n(I) Network Firewall gửi lưu lượng tới proxy server trong cùng AZ nếu luồng này ở chiều đi đã khớp quy tắc chuyển hướng WCCP và đã được Source NAT bởi proxy server.\n(J) Proxy server gửi lưu lượng chiều về của luồng đã qua proxy tới WCCP router sử dụng cấu hình WCCP trên proxy server.\n(IJ) Lưu lượng chiều về của luồng không khớp quy tắc chuyển hướng được Network Firewall gửi tới WCCP router theo subnet route table.\n(K) Có nhiều GRE tunnel từ WCCP router tới Transit Gateway qua Connect attachment. Spoke VPC CIDR được quảng bá tới WCCP router qua các tunnel này. WCCP router dùng ECMP để gửi lưu lượng tới Transit Gateway qua các GRE tunnel.\n(L) Transit Gateway dùng Connect attachment route table để chuyển tiếp lưu lượng tới Spoke VPC attachment tương ứng.\n(M) Trong Spoke VPC, lưu lượng theo local routes để tới đích từ Transit Gateway ENI.\nNhững cân nhắc Cân nhắc bốn điểm sau khi thực hiện giải pháp này.\nKích thước thiết bị ảo WCCP Bảo đảm chọn kích thước phù hợp cho WCCP virtual appliance để xử lý khối lượng lưu lượng kỳ vọng. Bạn có thể tham khảo tài liệu Amazon EC2 instance network bandwidth để chọn EC2 instance hỗ trợ nhu cầu về lưu lượng truy cập của bạn. Lập kế hoạch dự phòng bằng cách triển khai qua nhiều AZ. Dự phòng ở cấp component (đối với WCCP router hoặc Proxy server) có thể triển khai bằng automatic instance recovery. WCCP configuration Định nghĩa service group để phân loại lưu lượng cho các chính sách kiểm tra khác nhau khi cần. Có thể dùng service group khác nhau cho primary và secondary proxy server. Cấu hình redirection theo yêu cầu của bạn. Bạn có thể dùng nhiều thuộc tính như port, protocol, source/destination addresses. Triển khai authentication giữa WCCP router và proxy server (ngoài phạm vi bài viết này). Proxy selection Chọn giải pháp proxy hỗ trợ tích hợp WCCP. Cân nhắc yêu cầu hiệu năng theo khối lượng lưu lượng dự kiến. Tham khảo tài liệu Amazon EC2 instance network bandwidth để chọn EC2 instance hỗ trợ nhu cầu về lưu lượng truy cập của bạn. Monitoring and logging Triển khai logging toàn diện cho cả WCCP router và proxy server. Dưới đây là một số ví dụ về log cần thu thập. Do triển khai WCCP và proxy phụ thuộc nhà cung cấp/giải pháp, các log này có thể được gọi bằng tên khác nhau. Hãy tham khảo tài liệu nhà cung cấp để biết chi tiết: Trên WCCP router:\nTrạng thái dịch vụ WCCP, chuyển hướng gói tin, và giao tiếp logs router-to-proxy Thống kê lưu lượng trên interface Số lần ACL khớp cho các rule liên quan WCCP Dữ liệu NetFlow/sFlow phục vụ phân tích lưu lượng\nTrên proxy server: Access log và Error log (client IP, URL, status code, bytes transferred, timing, connection failures, timeouts) Log dịch vụ WCCP (service registration, group membership) Log hiệu năng cache (hit/miss ratio) Log xử lý kết nối (TCP connections, handshakes) Log authentication (nếu áp dụng) Log kiểm tra SSL/TLS (đối với lưu lượng HTTPS) Sử dụng tài nguyên hệ thống (CPU, memory, disk I/O) Thiết lập các cảnh báo cho các bất thường về lưu lượng hoặc sự cố sức khỏe của proxy, và tạo dashboards để trực quan hóa các mẫu lưu lượng và các security events. Bạn có thể xuất các logs đã đề cập trước đó sang Amazon CloudWatch để thiết lập các cảnh báo và tạo dashboards. Kết luận\nViệc triển khai transparent proxies bằng WCCP với AWS Transit Gateway mang lại một giải pháp mạnh mẽ cho các tổ chức muốn nâng cao security posture mà không làm gián đoạn trải nghiệm người dùng. Việc tập trung các kiểm soát bảo mật trong một egress VPC và sử dụng các router tương thích WCCP cho phép tổ chức đạt được khả năng kiểm tra lưu lượng toàn diện đồng thời duy trì hiệu năng mạng và khả năng mở rộng.\nKiến trúc này mang lại tính linh hoạt để thích ứng với các yêu cầu bảo mật thay đổi và nhu cầu mạng ngày càng tăng, khiến nó trở thành lựa chọn xuất sắc cho các doanh nghiệp muốn củng cố hạ tầng bảo mật đám mây. Để biết thêm thông tin và các lựa chọn kiến trúc cho centralized egress, hãy truy cập AWS Whitepaper, Centralized egress to internet.\nVijay Menon Vijay Menon là một Principal Solutions Architect làm việc tại Singapore, có nền tảng về mạng quy mô lớn và hạ tầng truyền thông. Anh ấy thích học các công nghệ mới và giúp khách hàng giải quyết những vấn đề kỹ thuật phức tạp bằng cách cung cấp các giải pháp sử dụng các sản phẩm và dịch vụ AWS. Khi không hỗ trợ khách hàng, anh ấy thích chạy đường dài và dành thời gian cho gia đình và bạn bè. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Xây dựng ứng dụng multi-Region Serverless có khả năng phục hồi trên AWS bởi Vamsi Vikash Ankam | vào ngày 08 tháng 09 năm 2025 | trong Advanced (300), Resilience, Serverless, Technical How-to | Permalink | Share\nCác ứng dụng mission-critical đòi hỏi tính sẵn sàng cao và khả năng chống chịu trước nămtrongcác gián đoạn tiềm ẩn. Trong trò chơi trực tuyến, hàng triệu người chơi kết nối đồng thời, khiến các thách thức về tính sẵn sàng trở nên rõ rệt. Khi nền tảng game gặp sự cố, người chơi mất tiến độ, giải đấu bị gián đoạn, và danh tiếng thương hiệu bị ảnh hưởng. Môi trường truyền thống thường cấp phát dư thừa tài nguyên tính toán để đối phó các thách thức này, dẫn đến thiết lập phức tạp cùng chi phí hạ tầng và vận hành cao. Hạ tầng Amazon Web Services (AWS) serverless hiện đại mang lại một cách tiếp cận hiệu quả hơn. Bài viết này trình bày các thực tiễn kiến trúc tốt nhất để xây dựng ứng dụng serverless có khả năng phục hồi, minh họa qua việc triển khai cơ chế ủy quyền multi-Region serverless.\nTổng quan Nếu chỉ nhận ra tầm quan trọng của tính sẵn sàng sau khi đã trải qua thảm họa thì đã quá muộn. Ứng dụng có thể thất bại vì nhiều lý do như sự cố hạ tầng, lỗi mã nguồn, lỗi cấu hình, đột biến lưu lượng bất ngờ, hoặc gián đoạn dịch vụ ở cấp độ regional. Các dịch vụ nghiệp vụ trọng yếu như hệ thống xác thực, bộ xử lý thanh toán, và tính năng game thời gian thực đòi hỏi tính sẵn sàng cao. Để giảm thiểu tác động đến trải nghiệm người dùng và doanh thu kinh doanh, hãy thiết lập bounded recovery times cho các dịch vụ trọng yếu trong thời gian xảy ra sự cố.\nCác kiến trúc AWS serverless vốn dĩ cung cấp tính sẵn sàng cao thông qua triển khai multi-Availability Zone (AZ) và khả năng mở rộng tích hợp. Các dịch vụ này giảm thiểu việc quản trị hạ tầng đồng thời vận hành theo mô hình định giá pay-for-value ở cấp độ Regional. Mô hình AWS serverless pay-for-value cho phép triển khai cost-effective multi-Region, khiến đây trở thành lựa chọn lý tưởng để xây dựng kiến trúc có khả năng phục hồi.\nHình 1: Biểu đồ cho thấy các nguyên nhân gây lỗi, tác động của chúng và tần suất xảy ra\nBiểu đồ trước đó ánh xạ các failures—from lỗi vận hành thường gặp cho tới những sự kiện thảm họa hiếm gặp. Nó hướng dẫn các tổ chức ưu tiên các chiến lược khôi phục multi-Region dựa trên xác suất xảy ra và tác động tiềm tàng đối với doanh nghiệp.\nCác quyết định Regional Để xác định cách tiếp cận multi-Region phù hợp, hãy đánh giá cẩn trọng các yếu tố sau:\nĐánh giá liệu các yêu cầu Recovery Time Objective (RTO) and Recovery Point Objective (RPO) của bạn có thể được đáp ứng trong một Region đơn lẻ, hay cần một kiến trúc multi-Region là cần thiết để đạt được các mục tiêu khôi phục của bạn. Liệu các lợi ích kinh doanh của dự phòng multi-Region có lớn hơn chi phí vận hành của việc sao chép dữ liệu, đồng bộ hóa, và chi phí cùng độ phức tạp triển khai gia tăng hay không? Đánh giá liệu các luật về chủ quyền dữ liệu, yêu cầu tuân thủ, hoặc hạn chế địa lý có ngăn việc sao chép dữ liệu giữa các AWS Regions cụ thể hay không. Đảm bảo rằng các Regions được chọn trong một giải pháp \u0026ldquo;multi-Region\u0026rdquo; có khả năng tương thích dịch vụ, giới hạn quota, và mức giá phù hợp với nhu cầu của bạn. Sau khi đánh giá các yêu cầu này, nếu tổ chức xác định cần khối lượng công việc multi-Region, thì họ phải chọn giữa hai mẫu kiến trúc: triển khai Active-Passive hoặc Active-Active. Mỗi mẫu đưa ra lợi ích và đánh đổi riêng về khả năng phục hồi, chi phí, và độ phức tạp vận hành.\nMẫu triển khai multi-Region Các phần sau đây phác thảo các mẫu triển khai multi-Region khác nhau: Active-Passive, và Active-Active.\nActive-Passive Trong mẫu này, một AWS Region đóng vai trò “Active” Region, xử lý toàn bộ lưu lượng sản xuất, trong khi các Region(s) khác ở trạng thái “Passive”, như thể hiện trong hình sau. Passive Region(s) sao chép dữ liệu và cấu hình từ Active Region mà không phục vụ yêu cầu, và sẵn sàng xử lý khi xảy ra gián đoạn ở “Active” Region. Tùy theo mức độ quan trọng của ứng dụng, passive Regions triển khai mức độ sẵn sàng hạ tầng khác nhau: hạ tầng triển khai đầy đủ (Hot Standby), triển khai một phần (Warm Standby), hoặc hạ tầng cốt lõi tối thiểu (Pilot Light).\nKiến trúc Active-Passive truyền thống cần đầu tư đáng kể cho hạ tầng nhàn rỗi: load balancer, auto-scaling group, running compute resources, và monitoring systems. Các tổ chức có thể sử dụng các ứng dụng AWS serverless với mô hình định giá pay-for-value để chủ yếu trả chi phí sao chép dữ liệu, không phải tài nguyên tính toán nhàn rỗi. AWS quản lý hạ tầng bên dưới, loại bỏ phần lớn chi phí vận hành.\nHạn ngạch dịch vụ, giới hạn API, và thiết lập concurrency phải tương ứng giữa các AWS Regions để để cung cấp khả năng failover liền mạch. AWS Lambda cung cấp provisioned concurrency để giữ functions warm và phản hồi nhanh, đặc biệt hữu ích cho các Regions thứ cấp trong quá trình failover. Nó giúp giảm cold start bằng cách duy trì môi trường warm execution, do đó hệ thống có thể xử lý đột biến lưu lượng với ít cold start hơn. Lưu ý provisioned concurrency phát sinh costs tính toán bất kể mức sử dụng. Cân nhắc triển khai auto-scaling cho provisioned concurrency dựa trên các mẫu lưu lượng để tối ưu chi phí trong các giai đoạn nhàn rỗi.\nMẫu này phù hợp với các tổ chức đang tìm kiếm giải pháp cost-effective disaster recovery (DR), bởi vì chi phí AWS serverless chỉ áp dụng khi tài nguyên được sử dụng tích cực tại Region thứ cấp. Các dịch vụ quản lý như Amazon DynamoDB Global Tables và Amazon Aurora Global Database xử lý sao chép dữ liệu, giúp đơn giản hóa triển khai. Cơ chế ủy quyền serverless được trình bày ở phần sau minh họa mẫu này trong thực tế.\nHình 2: Mẫu Active-Passive với các đường chấm chỉ ra các standby Regions, trong khi mẫu Active-Active phục vụ lưu lượng đồng thời\nActive-Active Trong mẫu này, multiple Regions phục vụ lưu lượng đồng thời, phân phối tải và cung cấp khả năng failover nhanh chóng. Kiến trúc Active-Active là expensive và được thiết kế cho mức sẵn sàng cao nhất. Tuy nhiên, chúng không mặc định cung cấp DR cho mọi dạng lỗi tiềm ẩn. Cách tiếp cận này phù hợp với các ứng dụng cần định tuyến theo vị trí địa lý, hoặc yêu cầu sẵn sàng cao nhất.\nTriển khai Active-Active đòi hỏi kỹ thuật nghiêm ngặt để xử lý đồng bộ dữ liệu và giải quyết xung đột. Mỗi Region phải được sized để gánh toàn bộ tải ứng dụng nếu một Region khác bị suy giảm dịch vụ. Người dùng đang hoạt động được phân bổ trên các AWS Regions, vì vậy gián đoạn ở một Region sẽ chuyển hướng toàn bộ lưu lượng sang các Regions còn lại, điều này đòi hỏi họ phải xử lý load kết hợp. Để cải thiện khả năng phục hồi của ứng dụng, hãy triển khai retry mechanisms, circuit breaker, và chiến lược fallback. Lập kế hoạch cho static stability bằng cách pre-provisioning capacity và áp dụng bộ nhớ đệm client-side. Các dịch vụ như Amazon Route 53 với định tuyến latency-based và Amazon DynamoDB Global Tables với strong consistency cung cấp nền tảng nhưng cần kiểm thử kỹ dưới nhiều kịch bản lỗi khác nhau. Bài viết này không đề cập đến triển khai Active-Active.\nMulti-Region serverless authorizer Để minh họa kịch bản Active-Passive, chúng ta xây dựng một ứng dụng mẫu cho thấy cách xây dựng multi-Region serverless authorizer sử dụng Amazon API Gateway, Lambda functions và Amazon Route53. Các nền tảng game và giải trí hiện đại lưu trữ các dịch vụ trọng yếu như ghép cặp người chơi, phát trực tiếp, và phân tích thể thao thời gian thực. Những dịch vụ này phụ thuộc vào hệ thống ủy quyền vững chắc—khi ủy quyền thất bại, người chơi không thể tham gia trận đấu, người xem mất quyền truy cập luồng phát, và sự kiện trực tiếp không khả dụng. Bài viết này trình bày cách xây dựng fault-tolerant, multi-Region serverless authorizer trong khi vẫn duy trì chi phí thấp hơn so với các môi trường truyền thống.\nKiến trúc Serverless multi-Region thường bao gồm các lớp Định tuyến, Tính toán, và Dữ liệu. Khi triển khai multi-Region deployments, việc sao chép dữ liệu giữa các AWS Regions là điều thiết yếu, bất kể các dịch vụ tính toán được sử dụng. Lớp tính toán phải ưu tiên tính bất biến để đảm bảo xử lý sự kiện an toàn trên các AWS Regions.\nSử dụng Powertools for Lambda để xử lý tính bất biến hiệu quả, hoặc triển khai các giải pháp tùy chỉnh bằng cách sử dụng unique event IDs với DynamoDB như một kho lưu trữ có tính bất biến. Dù bài viết tập trung vào triển khai dịch vụ authorizer, mẫu này có thể áp dụng để xây dựng các multi-Region microservice cho nhiều chức năng trọng yếu, như quản lý phiên chơi, điều phối phân phối nội dung, quản lý tùy thích người dùng, và dịch vụ hồ sơ.\nTổng quan demo Để minh họa vận hành multi-Region serverless authorizer, chúng ta có thể xem xét quy trình làm việc:\nỨng dụng frontend xác thực với Identity Provider để lấy token xác thực.\nToken xác thực được gửi đến một multi-Region DNS endpoint có khả năng phục hồi, được lưu trữ trên Route 53 trong bản demo này.\nRoute 53 định tuyến yêu cầu kèm token đến API Gateway ở primary Region.\nRoute 53 giám sát sức khỏe ứng dụng bằng một hàm Lambda giả lập trong demo này. Trong môi trường sản xuất, hãy triển khai các kiểm tra sức khỏe sâu để giám sát toàn bộ ngăn xếp dịch vụ.\nKhi ủy quyền thành công, ứng dụng nhận phản hồi. Nếu Route 53 phát hiện suy giảm ở primary Region, nó kích hoạt cảnh báo Amazon CloudWatch, mà chủ sở hữu ứng dụng có thể dùng để đánh giá và phê duyệt chuyển hướng lưu lượng sang Region thứ cấp.\nLưu lượng mới sẽ được định tuyến đến API Gateway ở Region thứ cấp sau khi được phê duyệt failover thủ công.\nCác kiểm tra sức khỏe của Route 53 tiếp tục giám sát sức khỏe primary Region và khôi phục định tuyến lưu lượng khi Region này phục hồi.\nHình 3: Quy trình làm việc Multi-Region serverless authorizer với Route53 failover giữa các primary Region và thứ cấp\nHình trên cho thấy kiến trúc minh họa cả khả năng failover và fallback thông qua cảnh báo CloudWatch và quy trình phê duyệt thủ công. Cách tiếp cận này phù hợp với thực tiễn tốt cho ứng dụng trọng yếu, nơi việc failover tự động không được khuyến nghị dù về mặt kỹ thuật là khả thi. Nhóm có thể dùng cách này để đánh giá mức sẵn sàng kỹ thuật, tác động kinh doanh, và đưa ra quyết định phù hợp về thời điểm và tác động tiềm tàng đến doanh thu.\nBản demo triển khai multi-Region serverless authorizer đóng vai trò là kiến trúc tham chiếu. Các triển khai thực tế cần đánh giá kỹ chiến lược failover dựa trên mức độ quan trọng của doanh nghiệp và các yêu cầu vận hành.\nTesting các kịch bản multi-Region\nỨng dụng demo lưu trữ frontend trên Amazon Elastic Container Service (Amazon ECS). Cấu hình health check của Route 53 trong GitHub này xác định các tham số failover chính:\nFailureThreshold: Chỉ định số lần kiểm tra tình trạng liên tiếp không thành công trước khi Route 53 đánh dấu endpoint là unhealthy. RequestInterval: Standard: Chu kỳ 30 giây ($0.50 mỗi health check/tháng) Fast: Chu kỳ 10 giây ($1.00 mỗi health check/tháng) Route53HealthCheck: Type: AWS::Route53::HealthCheck Properties: HealthCheckConfig: FailureThreshold: 2 FullyQualifiedDomainName: \\!Ref DomainName Port: 443 RequestInterval: 10 ResourcePath: /failure Type: HTTPS HealthCheckTags: \\- Key: Environment Value: Production \\- Key: Name Value: multi-authorizer-health-check Chu kỳ nhanh giúp phát hiện lỗi nhanh hơn. Tuy nhiên, nó làm tăng chi phí health check thông qua nhiều hoạt động ghi log, xử lý yêu cầu, và tài nguyên tính toán backend. Các vấn đề tạm thời như trục trặc mạng, lỗi thoáng qua, hoặc độ trễ từ bên thứ ba có thể tự khắc phục trong vài phút. Việc triển khai xử lý retry hiệu quả sẽ giới thiệu các phức tạp không cần thiết và tiềm ẩn inconsistencies dữ liệu. Hãy chọn chu kỳ phù hợp dựa trên SLAs kinh doanh và cân nhắc chi phí.\nĐể kiểm thử kịch bản failover, kiến trúc sử dụng một hàm Lambda giả làm endpoint health check. Chúng tôi kích hoạt cảnh báo CloudWatch bằng cách mô phỏng mã trạng thái phản hồi 500 từ hàm này, điều này sẽ thúc đẩy quá trình quyết định failover thủ công, như minh họa ở hình sau.\nHình 4: Ảnh chụp màn hình console hiển thị multi-authorizer-health-check với trạng thái “Unhealthy”\nBộ nhớ đệm DNS xảy ra ở nhiều tầng (trình duyệt, hệ điều hành, ISP, và VPN). Để quan sát hành vi failover ngay lập tức, hãy xóa bộ nhớ đệm trình phân giải DNS ở từng tầng\nĐể kiểm thử khả năng phục hồi toàn diện hơn, cân nhắc áp dụng thực hành chaos engineering. Bạn có thể dùng chaos-lambda-extension để đưa độ trễ hoặc sửa đổi phản hồi hàm theo cách có kiểm soát. AWS Fault Injection Service (AWS FIS), một dịch vụ được quản lý toàn phần, cho phép thực hiện các thí nghiệm fault inject để cải thiện khả năng phục hồi, hiệu năng và khả năng quan sát. Kết hợp các công cụ này giúp xác thực kiến trúc multi-Region dưới nhiều điều kiện lỗi có kiểm soát.\nKhả năng quan sát trong triển khai multi-Region Triển khai kiến trúc multi-Region chỉ là bước đầu. Khả năng quan sát Cross-Region đòi hỏi theo dõi tài nguyên của Region A từ Region B và ngược lại. CloudWatch cho phép điều này thông qua giám sát cross-account and cross-Region, cung cấp logs và metrics hợp nhất trong một dashboard. Triển khai kiểm tra tình trạng hoạt động chuyên sâu để xác minh chức năng quan trọng của ứng dụng trên các AWS Regions.\nMặc dù các dịch vụ AWS serverless được phân phối, việc xác định lỗi chính xác đòi hỏi kết hợp nhiều điểm dữ liệu. Cảnh báo CloudWatch composite giúp gom các tín hiệu này lại, tạo điều kiện cho quyết định sáng suốt. Cân nhắc triển khai giải pháp giám sát tùy chỉnh để truy vết yêu cầu end-to-end xuyên các AWS Regions. Góc nhìn toàn diện này giúp quản lý độ phức tạp của multi-Region và phản ứng nhanh với các vấn đề tiềm ẩn.\nKết luận Xây dựng ứng dụng multi-Region có khả năng phục hồi đòi hỏi cân nhắc kỹ các mẫu kiến trúc, chi phí, và độ phức tạp vận hành. Các dịch vụ AWS Serverless, với mô hình pay-for-value, giảm đáng kể thách thức khi triển khai kiến trúc multi-Region. Mẫu authorizer được trình bày trong bài cho thấy cách tổ chức có thể đạt tính sẵn sàng cao mà không cần gánh chi phí hạ tầng nhàn rỗi như cách tiếp cận truyền thống. Nhóm có thể làm theo các mẫu kiến trúc và thực tiễn tốt này để xây dựng giải pháp vững chắc, hiệu quả chi phí, duy trì tính sẵn sàng dịch vụ trong thời gian gián đoạn.\nĐể tìm hiểu các khái niệm về khả năng phục hồi, hãy truy cập AWS Developer Center. Mã nguồn đầy đủ của bản demo dùng trong bài viết có sẵn tại GitHub repository của chúng tôi. Để mở rộng kiến thức về serverless, hãy truy cập Serverless Land.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Tóm tắt hành tuần về AWS: AWS Transform, Amazon Neptune, và nhiều hơn nữa (Ngày 08 tháng 09 năm 2025) bởi Esra Kayabali | ngày 08 tháng 09 năm 2025 | trong Amazon Bedrock, Amazon Elastic Container Service, Amazon Neptune, Announcements, AWS Transform, AWS User Notifications, Launch, News | Permalink | Comments | Share\nMùa hè đã khép lại ở Utrecht, nơi tôi sống tại Hà Lan. Trong hai tuần nữa, tôi sẽ tham dự AWS Community Day 2025, tổ chức tại Kinepolis Jaarbeurs Utrecht vào ngày 24 tháng 09. Sự kiện kéo dài một ngày sẽ quy tụ hơn 500 chuyên gia cloud trên khắp Hà Lan, với 25 phiên breakout trải rộng 5 track kỹ thuật. Ngày hội sẽ mở đầu bằng các virtual keynotes lúc 9:00 sáng, tiếp theo là các phiên song song tập trung vào các triển khai thực tiễn của serverless architectures và container optimization strategies, mang lại giá trị cho mọi cấp độ kinh nghiệm.\nAWS Community Day Netherlands 2024 năm ngoái đã quy tụ một cộng đồng đa dạng gồm các practitioner, diễn giả và người yêu thích AWS, cùng nhau tạo nên một hội nghị do cộng đồng dẫn dắt với giá trị chia sẻ tri thức cao. Nếu bạn dự định tham dự, cứ thoải mái tìm gặp tôi để trao đổi về các dịch vụ AWS hoặc chia sẻ kinh nghiệm triển khai cloud của bạn!\nCác lần ra mắt tuần trước Hãy cùng điểm qua các thông báo mới của tuần trước.\nĐánh giá của AWS Transform hiện bao gồm lưu trữ tách rời – AWS Transform đã mở rộng khả năng assessment để phân tích on-premises cơ sở hạ tầng lưu trữ tách biệt, giúp khách hàng xác định migration total cost of ownership (TCO). Assessment hiện đánh giá Storage Area Network (SAN), Network Attached Storage (NAS), file servers, object storage, và virtual environments, đồng thời đề xuất dịch vụ đích trên AWS phù hợp như Amazon S3, Amazon EBS, và Amazon FSx. Công cụ cung cấp so sánh TCO toàn diện giữa môi trường hiện tại và AWS, kèm khuyến nghị tối ưu hiệu năng và chi phí. Vì storage có thể chiếm tới 45% tổng cơ hội migration, nâng cấp này giúp khách hàng hình dung các lựa chọn migration trên AWS. AWS Transform assessment hiện khả dụng tại US East (N. Virginia) và Europe (Frankfurt).\nAmazon Bedrock hiện hỗ trợ tính năng suy luận liên khu vực toàn cầu cho Anthropic Claude Sonnet 4 – Model Anthropic Claude Sonnet 4 trong Amazon Bedrock nay hỗ trợ Global cross-Region inference, cho phép các inference requests được định tuyến đến bất kỳ commercial AWS Region được hỗ trợ nào để xử lý. Nâng cấp này tối ưu tài nguyên sẵn có và tăng model throughput bằng cách phân phối lưu lượng qua nhiều Region. Trước đây, bạn có thể chọn cross-Region inference profiles gắn với từng khu vực (US, EU, APAC). Global cross-Region inference profile mới mang lại linh hoạt bổ sung cho các generative AI không cần ràng buộc địa lý, giúp xử lý traffic bursts ngoài kế hoạch và tăng throughput. Hướng dẫn triển khai chi tiết có tại Amazon Bedrock documentation.\nCơ sở dữ liệu Amazon Neptune hiện đã hỗ trợ Điểm cuối công cộng, giúp truy cập phát triển trở nên đơn giản hơn – Amazon Neptune nay hỗ trợ Public Endpoints, cho phép kết nối trực tiếp đến Neptune databases từ bên ngoài VPC mà không cần cấu hình mạng phức tạp. Tính năng này giúp nhà phát triển truy cập graph databases an toàn từ máy phát triển cá nhân mà không cần VPN hoặc bastion hosts, đồng thời vẫn đảm bảo bảo mật qua IAM authentication, VPC security groups, và encryption in transit. Bạn có thể bật Public Endpoints cho các Neptune clusters chạy engine version 1.4.6 trở lên qua AWS Management Console, AWS CLI, hoặc AWS SDK. Tính năng này không tính phí bổ sung ngoài Neptune pricing tiêu chuẩn, và khả dụng ở mọi AWS Region nơi Neptune Database được cung cấp. Chi tiết triển khai có trong Amazon Neptune documentation.\nECS Exec hiện đã được hỗ trợ trên Bảng điều khiển quản lý AWS – Amazon ECS nay hỗ trợ ECS Exec trực tiếp trong AWS Management Console, cho phép secure, interactive shell access vào container đang chạy mà không cần mở inbound ports hay quản lý SSH keys. Trước đây chỉ có qua API/CLI/SDK, tính năng này giúp troubleshooting thuận tiện khi truy cập container ngay trong console. Bạn có thể bật ECS Exec khi tạo/cập nhật services và standalone tasks, rồi kết nối tới container bằng cách chọn “Connect” trên trang chi tiết task, mở phiên tương tác qua CloudShell. Console cũng hiển thị AWS CLI command tương ứng để dùng trên máy cục bộ. Tính năng khả dụng ở tất cả AWS commercial Regions và được ghi trong ECS developer guide.\nCấu hình thông báo tổ chức cho thông báo người dùng AWS hiện đã có sẵn rộng rãi – AWS User Notifications nay hỗ trợ Organizational Notification Configurations, giúp người dùng AWS Organizations cấu hình và quan sát notifications tập trung trên toàn tổ chức. Management accounts hoặc delegated administrators có thể cấu hình thông báo cho các organizational units cụ thể hoặc cho toàn bộ accounts trong tổ chức. Dịch vụ hỗ trợ cấu hình notifications cho bất kỳ Amazon EventBridge event được hỗ trợ, như console sign-ins without MFA, với thông báo hiển thị trong Console Notifications Center của admin và AWS Console Mobile Application. User Notifications hỗ trợ tối đa 5 delegated administrators và khả dụng tại mọi AWS Region nơi dịch vụ được cung cấp. Chi tiết triển khai có tại AWS User Notifications user guide.\nĐể xem danh sách đầy đủ các thông báo của AWS, hãy theo dõi trang What’s New at AWS.\nSự kiện AWS sắp tới Đánh dấu lịch và đăng ký các sự kiện AWS sắp tới.\nAWS Summits – Sự kiện trực tuyến và trực tiếp miễn phí kết nối cộng đồng cloud computing để giao lưu, cộng tác và học hỏi về AWS. Đăng ký tại thành phố gần bạn: Zurich (Ngày 11 tháng 09), Los Angeles (Ngày 17 tháng 09), và Bogotá (Ngày 09 tháng 10).\nAWS re:Invent 2025 – Hẹn gặp tại Las Vegas từ December 1–5, nơi những người tiên phong cloud từ khắp thế giới tụ hội để cập nhật đổi mới AWS, học hỏi ngang hàng, thảo luận chuyên sâu do chuyên gia dẫn dắt và mở rộng kết nối. Đừng quên khám phá event catalog.\nAWS Community Days – Chuỗi hội nghị do cộng đồng dẫn dắt, có thảo luận kỹ thuật, workshop, và hands-on labs dẫn dắt bởi các người dùng AWS chuyên gia và lãnh đạo ngành chia sẻ: Baltic (Ngày 10 tháng 09), Aotearoa (Ngày 18 tháng 09), Nam Phi (Ngày 20 tháng 09), Bolivia (Ngày 20 tháng 09), Bồ Đào Nha (Ngày 27 tháng 09).\nDuyệt tất cả các sự kiện trực tiếp và trực tuyến do AWS tổ chức tại đây.\nVậy là hết cho tuần này. Hẹn gặp lại bạn vào Thứ 2 tuần tới trong Tóm tắt hàng tuần!\n— Esra\nBài viết này là một phần của series Tóm tắt hàng tuần. Quay lại mỗi tuần để xem nhanh những tin tức và thông báo thú vị từ AWS!\nTAGS: Week in Review\nEsra Kayabali Esra Kayabali là Senior Solutions Architect tại AWS, chuyên về analytics gồm data warehousing, data lakes, big data analytics, batch và real-time data streaming, cùng data integration. Cô có hơn mười năm kinh nghiệm software development và solution architecture. Cô đam mê học hỏi cộng tác, chia sẻ tri thức và dẫn dắt cộng đồng trên hành trình công nghệ cloud. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/",
	"title": "Giải thích RAG",
	"tags": [],
	"description": "",
	"content": "Định nghĩa ngắn gọn RAG (viết tắt của Retrieval-Augmented Generation) là một kỹ thuật hoặc kiến trúc phần mềm trong lĩnh vực Trí tuệ nhân tạo (AI), được thiết kế để tối ưu hóa đầu ra của một Mô hình Ngôn ngữ Lớn (LLM).\nVề mặt bản chất, RAG là sự kết hợp giữa hai cơ chế:\nCơ chế truy xuất thông tin (Information Retrieval): Tìm kiếm dữ liệu từ một nguồn kiến thức bên ngoài (External Knowledge Base) có độ tin cậy cao. Cơ chế tạo sinh văn bản (Text Generation): Sử dụng khả năng hiểu và tổng hợp ngôn ngữ của LLM để tạo ra câu trả lời tự nhiên. Mục tiêu của RAG là cung cấp cho LLM thêm ngữ cảnh (context) chính xác, cập nhật và cụ thể, giúp mô hình vượt qua giới hạn của dữ liệu huấn luyện tĩnh (static training data).\nVì sao cần RAG? Các mô hình LLM truyền thống thường gặp 3 vấn đề lớn mà RAG có thể giải quyết:\nCập nhật thông tin (Freshness): LLM không cần huấn luyện lại (Re-training) hay tinh chỉnh (Fine-tuning) mà vẫn trả lời được các thông tin mới nhất, chỉ cần cập nhật vào cơ sở dữ liệu tìm kiếm. Sở hữu dữ liệu (Proprietary Data): Cho phép AI trả lời các câu hỏi về dữ liệu riêng tư của doanh nghiệp (tài liệu nội bộ, code base, thông tin khách hàng) mà mô hình gốc không hề biết. Tính xác thực (Grounding): Giảm thiểu \u0026ldquo;ảo giác\u0026rdquo; (Hallucination - AI bịa thông tin) bằng cách buộc AI phải trích dẫn hoặc dựa trên đoạn văn bản thực tế được tìm thấy. Kiến trúc hoạt động Quy trình xử lý một câu hỏi của RAG diễn ra như sau:\nBước Tên gọi Mô tả hành động 1 Retrieval (Truy xuất) Hệ thống tìm kiếm các đoạn văn bản liên quan nhất đến câu hỏi trong kho dữ liệu (thường dùng Vector Database). 2 Augmentation (Tăng cường) Ghép câu hỏi của người dùng + Dữ liệu vừa tìm được thành một \u0026ldquo;lời nhắc\u0026rdquo; (prompt) hoàn chỉnh. 3 Generation (Tạo sinh) Gửi prompt đó cho AI (LLM) để nó tổng hợp và viết ra câu trả lời cuối cùng cho người dùng. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu tổng quan Trong bài thực hành này, chúng ta sẽ tập trung xây dựng một trợ lý AI thông minh có khả năng \u0026ldquo;đọc hiểu\u0026rdquo; và trả lời câu hỏi dựa trên dữ liệu riêng của doanh nghiệp (kỹ thuật RAG).\nMục tiêu chính là thiết lập một quy trình xử lý dữ liệu hoàn toàn tự động và không máy chủ (Serverless), bao gồm các bước:\nIngestion (Nhập liệu): Đưa tài liệu gốc vào hệ thống. Indexing (Tạo chỉ mục): Chuyển đổi văn bản thành vector và lưu trữ để tra cứu. Retrieval \u0026amp; Generation (Truy xuất \u0026amp; Tạo sinh): Cấu hình mô hình AI để tìm kiếm thông tin liên quan và trả lời câu hỏi của người dùng. 💡 Điểm nổi bật: Giải pháp này giúp bạn không cần quản lý bất kỳ hạ tầng máy chủ nào, tối ưu hóa chi phí và thời gian vận hành.\nNội dung Giải thích RAG Giới thiệu các dịch vụ "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/5.1.2-services/",
	"title": "Giới thiệu các dịch vụ",
	"tags": [],
	"description": "",
	"content": "Kiến trúc giải pháp được xây dựng dựa trên sự phối hợp của 4 thành phần dịch vụ chính sau đây:\nKnowledge Bases for Amazon Bedrock Đây là một khả năng được quản lý toàn diện (fully managed capability) giúp kết nối các Mô hình Nền tảng (Foundation Models) với nguồn dữ liệu nội bộ của doanh nghiệp.\nTự động hóa quy trình RAG: Quản lý toàn bộ luồng công việc từ đầu đến cuối (end-to-end), bao gồm nhập dữ liệu (ingestion), chia nhỏ văn bản (chunking), tạo vector (embedding) và truy xuất thông tin (retrieval). Kết nối ngữ cảnh: Giúp các ứng dụng AI trả lời câu hỏi dựa trên dữ liệu riêng tư thay vì chỉ dựa vào dữ liệu huấn luyện chung chung. Không cần quản lý hạ tầng: Loại bỏ nhu cầu tự xây dựng và duy trì các đường ống dữ liệu (data pipelines) phức tạp. Amazon Simple Storage Service (Amazon S3) Là dịch vụ lưu trữ đối tượng (object storage) với khả năng mở rộng, độ bền dữ liệu 99,999999999% (11 số 9) và bảo mật hàng đầu.\nVai trò nguồn dữ liệu (Data Source): Đóng vai trò là kho chứa \u0026ldquo;sự thật\u0026rdquo; (source of truth). Lưu trữ tài liệu: Chứa các tệp phi cấu trúc như PDF, Word, hoặc Text mà doanh nghiệp muốn AI học. Đồng bộ hóa: Knowledge Base sẽ định kỳ quét bucket S3 này để đồng bộ hóa và cập nhật kiến thức mới nhất. Amazon OpenSearch Serverless Là tùy chọn triển khai không máy chủ (serverless) của Amazon OpenSearch Service, giúp chạy khối lượng công việc tìm kiếm và phân tích mà không cần quản lý cụm (cluster).\nVai trò kho lưu trữ Vector (Vector Store): Lưu trữ các chỉ mục vector (vector embeddings) được tạo ra từ tài liệu gốc. Tìm kiếm ngữ nghĩa (Semantic Search): Thực hiện thuật toán tìm kiếm tương đồng (similarity search/k-NN) để xác định các đoạn văn bản có ý nghĩa gần nhất với câu hỏi của người dùng. Tự động mở rộng: Tự động điều chỉnh tài nguyên tính toán và lưu trữ dựa trên nhu cầu thực tế. Amazon Bedrock Foundation Models (FMs) Cung cấp quyền truy cập vào các mô hình AI hàng đầu thông qua API thống nhất. Trong kiến trúc này, chúng ta sử dụng hai loại mô hình với vai trò riêng biệt:\nEmbedding Model (Amazon Titan Embeddings v2): Chuyển đổi văn bản (tài liệu từ S3 và câu hỏi của người dùng) thành các vector số học. Giúp máy tính có thể so sánh mức độ tương đồng về ý nghĩa giữa các đoạn văn. Text Generation Model (Anthropic Claude 3): Đóng vai trò là \u0026ldquo;bộ não\u0026rdquo; suy luận. Nhận câu hỏi kèm theo thông tin ngữ cảnh đã được truy xuất từ Vector Store. Tổng hợp thông tin và sinh ra câu trả lời tự nhiên, chính xác, có kèm trích dẫn nguồn. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/5.3.1-create-kb/",
	"title": "Khởi tạo Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Chúng ta sẽ sử dụng Amazon Bedrock Wizard để thiết lập toàn bộ kiến trúc RAG. Quá trình này sẽ kết nối nguồn dữ liệu S3, mô hình Embedding và tự động khởi tạo kho lưu trữ Vector (OpenSearch Serverless).\nCác Bước Thực hiện Đăng nhập vào AWS Management Console và truy cập dịch vụ Amazon Bedrock. Trong menu bên trái, chọn Knowledge bases. Nhấp vào nút Create knowledge base ở góc trên bên phải của màn hình. Chọn Knowledge Base with vector store Bước 1: Cấu hình Knowledge Base\nTrên màn hình cấu hình đầu tiên:\nKnowledge base name: Nhập tên knowledge-base-demo Knowledge Base description - optional: Nhập Knowledge Base from AWS Overview (Phần này bạn cần mô tả dữ liệu bạn đã upload lên S3 trước đó). IAM permissions: Chọn tùy chọn Create and use a new service role. Service role name: Giữ giá trị mặc định do AWS đề xuất (bắt đầu bằng AmazonBedrockExecutionRoleForKnowledgeBase_...). Nhấp Next. Bước 2: Cấu hình Nguồn Dữ liệu\nKết nối đến S3 Bucket chứa các tài liệu:\nData source name: Nhập knowledge-base-demo S3 URI: Nhấp vào nút Browse S3. Trong cửa sổ pop-up, chọn bucket rag-workshop-demo\u0026gt; mà bạn đã tạo trong phần trước. Nhấp Choose. Giữ lại các cấu hình Default. Nhấp Next. Bước 3: Lưu trữ \u0026amp; Xử lý Đây là bước quan trọng nhất để xác định mô hình AI và vị trí lưu trữ vector:\nEmbeddings model:\nNhấp Select model. Chọn model: Titan Embeddings G1 - Text v2. Vector Store:\nVector store creation method: Chọn Quick create a new vector store - Recommended Vector store type - new: Chọn Amazon OpenSearch Serverless Lưu ý: Tùy chọn này cho phép AWS tự động tạo một cluster Amazon OpenSearch Serverless để lưu trữ dữ liệu, giúp bạn không phải quản lý cơ sở hạ tầng thủ công. Nhấp Next. Bước 4: Xem xét và Tạo Knowledge Base\nXem xét tất cả thông tin cấu hình trên trang Review. Đảm bảo các mục S3 URI và Model đều chính xác. Cuộn xuống cuối trang và nhấp vào nút Create knowledge base. Bước 5: Chờ Khởi tạo\nSau khi nhấp Create, hệ thống sẽ bắt đầu quá trình khởi tạo cơ sở hạ tầng nền cho Vector Store.\nThời gian chờ: Khoảng 2 - 5 phút. Lưu ý: Vui lòng không đóng trình duyệt trong thời gian này. Thành công: Khi màn hình hiển thị thông báo màu xanh \u0026ldquo;Knowledge base created successfully\u0026rdquo;, bạn đã hoàn thành bước này và sẵn sàng cho phần tiếp theo. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.2-prerequiste/5.2.1-model-access/",
	"title": "Kiểm tra truy cập Model",
	"tags": [],
	"description": "",
	"content": "Tổng quan Theo chính sách mới của AWS, các mô hình nền tảng (Foundation Models) thường được tự động kích hoạt. Tuy nhiên, đối với các mô hình của đối tác thứ ba như Anthropic (Claude), người dùng lần đầu tiên sử dụng tại một Region mới bắt buộc phải khai báo thông tin sử dụng (Use Case) mới có thể gọi được mô hình.\nĐảm bảo tài khoản AWS của bạn có quyền truy cập và sử dụng mô hình Anthropic Claude 3 Sonnet. Đây là bước bắt buộc để tránh lỗi AccessDenied khi Chatbot hoạt động sau này. Nếu đây là lần đầu tiên bạn sử dụng model này tại Region mới, bạn cần thực hiện khai báo mục đích sử dụng (Use Case).\nKiểm tra truy cập Chúng ta sẽ thực hiện một bài kiểm tra nhanh (Test Run) để đảm bảo tài khoản của bạn đã sẵn sàng.\nĐầu tiên ở thanh tìm kiếm, truy cập vào Amazon Bedrock.\nBước 1. Truy cập Chat Playground\nTại menu bên trái Bedrock Console, tìm mục Playgrounds. Click Chat. Bước 2. Chọn Model kiểm thử\nClick Select model (phía trên khung chat). Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet). Throughput: Chọn On-demand. Click Apply. Bước 3. Gửi tin nhắn kích hoạt\nTrong khung chat: Nhập Hello. Click Run. Quan sát kết quả: Nếu AI trả lời: Thành công (Chuyển ngay sang phần 5.2.2). Nếu hiện lỗi màu đỏ hoặc popup \u0026ldquo;Submit use case details\u0026rdquo;: Cần khai báo thông tin (Làm tiếp bước 4 bên dưới).\nBước 4. Khai báo Use Case (Chỉ thực hiện nếu gặp lỗi ở bước 3)\nClick Submit use case details (trong thông báo lỗi). Điền biểu mẫu: Company Name: Nhập Personal Learning. Company website URL: Nhập https://daihoc.fpt.edu.vn/ Industry: Chọn Education. Chọn Intended Use Describe\u0026hellip; Nhập Research \u0026amp; Development. Click Submit. Đợi 1 phút, quay lại khung chat, Click Run lại tin nhắn Hello để xác nhận thành công. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với các nền tảng AWS và tìm hiểu về chương trình FCJ 2025\nTuần 2: Dịch vụ mạng trên AWS (AWS VPC, VPC Peering \u0026amp; Transit Gateway, VPN \u0026amp; Direct Connect, Elastic Load Balancing)\nTuần 3: Dịch vụ Compute VM trên AWS (Amazon EC2, Amazon Lighsail, Amazon EFS/FSX, AWS Application Migration Service (MGN) Tuần 4: Dịch vụ lưu trữ trên AWS (S3, Snow Family, Amazon Storage Gateway, Disaster Recovery on AWS, AWS Backup)\nTuần 5: Dịch vụ Bảo Mật trên AWS - \u0026ldquo;Security is job zero\u0026rdquo; (Share Responsibility Model, AWS Identify and Access Management, Amazon Cognito, AWS Organization, AWS Identify Center (SSO), AWS Key Management Service - KMS, AWS Security Hub)\nTuần 6: Dịch vụ Cơ sở dữ liệu trên AWS (Database Concepts, Amazon RDS, Amazon Aurora, Amazon Redshift, Amazon ElastiCache)\nTuần 7: Học và bổ sung thêm kiến thức về AWS Cloud, dựa trên khóa học trên Skill Builder, hoàn thành training Certificate Cloud Practitioner\nTuần 8: Học và bổ sung kiến thức về NLP và FastAPI để ứng dụng vào dự án cuối kì\nTuần 9: Triển khai dự án Sprint 01 - Nghiên cứu về mô hình Speech to Text và OCR\nTuần 10: Triển khai dự án Sprint 02 - Cải tiến và nâng cấp chất lượng các mô hình\nTuần 11: Triển khai dự án Sprint 03 - Làm quen với các dịch vụ hỗ trợ trên AWS và ứng dụng vào dự án\nTuần 12: Triển khai dự án Sprint 04 - Kiểm tra toàn bộ các mô hình và xử lý lỗi\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối với những bạn trong team và làm quen với các anh chị Champion trong First Cloud Journey. Tìm hiểu về các dịch vụ của AWS đem lại cho khách hàng. Hoàn thành bài Lab cũng như kiến thức của Module 1 trong FJC 2025 Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Đọc kĩ các lưu ý, nội quy và quy định tại AWS\n- Kết nối và giao lưu với các thành viên trong team\n- Lập nhóm và lên kế hoạch học tập cũng như về timing của dự án cần chuẩn bị trong kì thực tập tại doanh nghiệp.\n- Tạo google sheet để quản lí việc học tập và cũng như theo dõi tiến độ của thành viên trong team. 08/09/2025 08/09/2025 Module 01 3 - Tìm hiểu về các khái niệm cơ bản:\n+ Hiểu về điện toán đám mây là gì?\n+ Lợi ích của việc sử dụng điện toán đám mây là gì?.\n+ Điều gì tạo nên sự khác biệt của AWS.\n+ Làm sao để bắt đầu một hành trình lên mây? 09/09/2025 09/09/2025 Module 01 4 - Tìm hiểu về hạ tầng toàn cầu của AWS.\n- Tìm hiểu về công cụ Quản Lý AWS Services.\n- Cách tối ưu hóa chi phí trên AWS.\n- Thực hành Lab 01:\n+ Tạo AWS account.\n+ Cài MFA cho tài khoản cũng như hiểu về MFA là gì?\n+ Tạo Admin Group và Admin User.\n+ Thử nghiệm dùng AWS Support. 10/09/2025 10/09/2025 Module 01 5 - Thực hành Lab 07:\n+ Tạo Budget\n+ Tạo Cost Budget\n+ Tạo Usage Budget\n+ Tạo RI Budget\n+ Tạo Saving Plan Budget\n+ Cách xóa tài nguyên.\n- Tìm hiểu về các dịch vụ của từng Budget\n- Và nhận biết những Budget nào phù hợp với đối tượng nào. 11/09/2025 11/09/2025 Module 01 6 - Thực hành Lab 09:\n+ Tìm hiểu các gói hỗ trợ của AWS Support\n+ Truy cập AWS Support\n+ Khởi tạo các yêu cầu hỗ trợ. 12/09/2025 12/09/2025 Module 01 Kết quả đạt được tuần 1: Hiểu AWS là gì và các khái niệm và dịch vụ mà AWS cung cấp:\nĐiện toán đám mây. Sự khác biệt của AWS Cách để bắt đầu một hành trình lên mây Hạ tầng toàn cầu của AWS Công cụ quản lí AWS Services Cách tối ưu hóa chi phí trên AWS Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định MFA cho tài khoản Admin Group Admin User AWS Support Biết cách thiết lập các Budget:\nCost Budget Usage Budget RI Budget Saving Plan Budget Clean tài nguyên Hiểu rõ về các gói hỗ trợ và cách truy cập AWS Support\nGói Basic Gói Developer Gói Business Gói Enterprise "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm” Mục Đích Của Sự Kiện Hiểu rõ cách AI có thể tự động hóa và tối ưu hóa từng giai đoạn trong vòng đời phát triển phần mềm (Software Development Lifecycle – SDLC). Nắm bắt được triết lý AI hỗ trợ con người thay vì thay thế con người trong quá trình xây dựng ứng dụng. Trực tiếp quan sát cách Amazon Q và các công cụ AI khác hỗ trợ lập trình viên từ giai đoạn khởi tạo ý tưởng, viết mã, đến triển khai hạ tầng (IaC – Infrastructure as Code). Nhận thức được xu hướng “AI-first development” – nơi AI trở thành một phần tự nhiên của quy trình phát triển phần mềm tương lai. Danh Sách Diễn Giả Anh Toan Huynh - PMP, Senior Solutions Architect, AWS Chị My Nguyen - Senior Solutions Architect, AWS Nội Dung Nổi Bật Thử thách khi lập trình với AI Phần mở đầu trình bày những hạn chế và thách thức khi đưa AI vào lập trình:\nAI chưa thể xử lý các project có logic phức tạp, đòi hỏi hiểu biết sâu về ngữ cảnh nghiệp vụ. Lập trình viên khó kiểm soát chi tiết trong mã sinh ra nếu không mô tả rõ ràng mục tiêu và phạm vi. Chất lượng code phụ thuộc nhiều vào prompt và context mà người dùng cung cấp. Đây chính là lý do AI-DLC ra đời: tạo ra một quy trình có cấu trúc, giúp AI và con người phối hợp hiệu quả hơn.\nAI in Development – How AI is Changing Software Phần này phân tích cách AI đang thay đổi ngành phần mềm:\nAI hỗ trợ sinh code, tạo tài liệu kỹ thuật, thiết kế API, và kiểm thử tự động. Developer chuyển vai trò từ “code writer” sang “AI orchestrator” — người điều phối, định hướng và đánh giá đầu ra. Các công cụ như Amazon Q, GitHub Copilot, ChatGPT for Developers trở thành công cụ trung tâm trong workflow của team dev hiện đại. Giới thiệu về AI-DLC là gì AI-Driven Development Lifecycle (AI-DLC) là phương pháp tiếp cận phát triển phần mềm có sự đồng hành của AI, nơi mỗi bước được thiết kế để cung cấp cho AI ngữ cảnh và mục tiêu cụ thể nhằm tạo ra kết quả chính xác hơn.\nInception\nBuild Context on Existing Codes – AI được “nuôi” bằng mã nguồn hiện tại để hiểu cấu trúc dự án. Elaborate Intent with User Stories – Developer mô tả yêu cầu thông qua user story, làm rõ mục tiêu. Plan with Units of Work – Phân tách công việc thành các đơn vị nhỏ để AI có thể thực thi và sinh code từng phần. Construction\nDomain Model (Component Model) – Xây dựng mô hình miền hoặc sơ đồ kiến trúc logic. Generate Code \u0026amp; Test – AI sinh code và test tự động dựa trên thông tin đã lên kế hoạch. Add Architectural Components – Bổ sung các thành phần kiến trúc như API, data layer, logging, security. Deploy with IaC \u0026amp; Tests – Tự động triển khai hệ thống với Infrastructure as Code và test tích hợp. Mỗi bước đều cung cấp thêm “rich context” cho bước kế tiếp, giúp AI hiểu sâu hơn về hệ thống và sinh ra kết quả ngày càng chính xác.\nCORE CONCEPTS – Ba nguyên lý cốt lõi Context Awareness – AI cần có ngữ cảnh rõ ràng về mã, yêu cầu và domain để hoạt động hiệu quả. Collaborative Generation – Con người và AI hợp tác: AI sinh code, con người định hướng và kiểm duyệt. Continuous Refinement – Quy trình lặp lại liên tục để tinh chỉnh đầu ra và cải thiện chất lượng. Mob Elaboration Mob Elaboration là phương pháp mở rộng yêu cầu (intent elaboration) theo hình thức cộng tác nhóm:\nNhiều thành viên cùng nhau mô tả yêu cầu, đặt câu hỏi, và bổ sung thông tin cho AI. Giúp AI hiểu sâu hơn về nghiệp vụ, mục tiêu và logic phức tạp của dự án. Cách tiếp cận này giúp giảm rủi ro hiểu sai yêu cầu, đặc biệt trong các team lớn hoặc đa miền. 5-Stage Sequential Process của AI-DLC AI-DLC được thực hiện qua 5 giai đoạn:\nInception – Hiểu yêu cầu, phân tích hệ thống. Construction – Tạo mô hình miền và cấu trúc ban đầu. Generation – Sinh mã tự động. Testing – Tự động hóa kiểm thử đơn vị và tích hợp. Deployment – Triển khai ứng dụng với IaC và CI/CD pipelines. Mỗi vòng lặp giúp AI học thêm và cải thiện chất lượng đầu ra.\nDemo 1 – Trải nghiệm trực quan AI DLC với Amazon Q Buổi demo minh họa cách áp dụng AI-DLC trong thực tế thông qua một dự án nhỏ:\nBắt đầu từ ý tưởng đơn giản → chuyển thành user story mô tả yêu cầu nghiệp vụ. AI hỗ trợ phân chia công việc (Units of Work) và lập kế hoạch chi tiết cho từng module. Người tham dự có thể điều khiển AI thông qua câu hỏi, checkbox và điều kiện logic, giúp AI hiểu rõ phạm vi công việc. AI tiếp tục sinh code, viết test, tạo cấu trúc dự án và triển khai thử nghiệm tự động. Demo thể hiện rõ cách AI và con người phối hợp nhịp nhàng: AI làm việc lặp đi lặp lại, con người định hướng và ra quyết định chiến lược. Giới Thiệu Về Kiro Triết Lý Của Kiro\nPhần tiếp theo của workshop giới thiệu Kiro, một môi trường phát triển thông minh được thiết kế xoay quanh triết lý “AI-native development” – nơi AI là một phần cốt lõi, không phải chỉ là công cụ hỗ trợ.\nTriết lý của Kiro tập trung vào ba yếu tố chính:\nTích hợp sâu với quy trình phát triển – AI không chỉ hỗ trợ viết code, mà còn tham gia lập kế hoạch, quản lý context, và phân tích tác động thay đổi. Hiểu ngữ cảnh dự án toàn diện – Kiro duy trì trạng thái hiểu biết liên tục về cấu trúc hệ thống, cho phép AI tương tác với toàn bộ project thay vì từng file riêng lẻ. Kiểm soát \u0026amp; cộng tác thông minh – Lập trình viên có thể hướng dẫn AI thông qua contextual commands, giúp đảm bảo rằng mỗi thay đổi đều có mục đích rõ ràng và nhất quán với hệ thống. Cấu Trúc Project Trong Kiro\nKhác với các text editor truyền thống như VSCode hay JetBrains, Kiro không chỉ là môi trường viết mã — nó là AI workspace có nhận thức cấu trúc.\nCấu trúc project trong Kiro bao gồm:\nContext Layer – Lưu trữ ngữ cảnh, domain model, và quan hệ giữa các module. Task Layer – Quản lý các đơn vị công việc (Units of Work) được AI theo dõi và hoàn thành dần. AI Agent Layer – Mỗi tác vụ (code, test, refactor, deploy) có agent riêng đảm nhận, tạo ra mô hình phát triển đa agent – hợp tác – song song. Human-in-the-Loop Control – Lập trình viên có thể can thiệp ở mọi bước: xác nhận, sửa đổi hoặc từ chối đầu ra của AI. Điều này giúp Kiro không chỉ là công cụ sinh code mà trở thành một hệ sinh thái phát triển hợp tác giữa người và AI.\nDemo 2: Kiro – Áp Dụng AI-DLC Trong phần trình diễn, diễn giả minh họa cách Kiro vận hành AI-DLC một cách liền mạch:\nNgười dùng nhập một yêu cầu nghiệp vụ cơ bản, ví dụ “xây dựng hệ thống quản lý sự kiện”. Kiro tự động phân tích intent, tạo domain model và chia nhỏ thành các user story. AI trong Kiro sinh ra các module, component và test case tương ứng. Developer có thể tương tác qua bảng kiểm (checkbox-based task control) để xác nhận từng phần việc. Cuối cùng, Kiro triển khai hệ thống hoàn chỉnh với IaC và kiểm thử tự động. Buổi demo cho thấy AI-DLC không chỉ là lý thuyết, mà có thể được triển khai thực tế ngay trong môi trường Kiro — nơi AI, con người, và quy trình phát triển hòa quyện thành một hệ thống thống nhất.\nTrải nghiệm trong event Tham gia buổi workshop “AI DLC x Kiro: Reinventing Developer Experience with AI” là một trải nghiệm vô cùng bổ ích, giúp tôi hiểu rõ hơn về cách AI được tích hợp sâu vào môi trường phát triển phần mềm và cách mà triết lý thiết kế của Kiro mang lại hướng tiếp cận mới cho developer.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đã chia sẻ về AI DLC – một nền tảng hỗ trợ phát triển phần mềm dựa trên AI, giúp tự động hóa nhiều quy trình trong SDLC. Ngoài ra, phần giới thiệu về Kiro Editor mang lại cái nhìn sâu sắc về cách xây dựng một text editor theo hướng AI-native thay vì chỉ “thêm plugin AI” vào môi trường cũ. Tôi đặc biệt ấn tượng với triết lý của Kiro: tối giản, hiệu năng cao, tập trung vào trải nghiệm người dùng và khả năng mở rộng theo module. Trải nghiệm kỹ thuật thực tế Trong học tập:\nÁp dụng AI-DLC structure cho personal projects Practice \u0026ldquo;Context Awareness\u0026rdquo; principle với AI assistants Build habit of writing clear requirements as user stories Cho career tương lai:\nUnderstand modular, extensible, maintainable system design như Kiro Master Amazon Q và AI tools khác hiệu quả Recognize importance of providing quality context cho AI Thay đổi mindset:\nApproach problems với \u0026ldquo;AI-augmented\u0026rdquo; thinking Consider building custom tools với deep AI integration Always ask: \u0026ldquo;How can AI assist better at this step?\u0026rdquo; Ứng dụng công cụ hiện đại Việc trải nghiệm AI DLC trên Kiro giúp tôi hiểu rõ hơn về khả năng tự động hóa quy trình phát triển, đặc biệt là ở các bước như code generation, documentation và debugging. Tôi nhận ra tiềm năng của việc xây dựng công cụ học tập và làm việc cá nhân có khả năng gợi ý thông minh, giúp rút ngắn thời gian phát triển và nâng cao chất lượng sản phẩm. Các khái niệm về modular design của Kiro cũng gợi ý cho tôi hướng đi trong việc thiết kế hệ thống linh hoạt, dễ mở rộng và dễ bảo trì. Kết nối và trao đổi Workshop tạo cơ hội để tôi giao lưu với các developer, nhà nghiên cứu AI và product designer, từ đó hiểu thêm về xu hướng AI-augmented development. Qua các cuộc thảo luận, tôi học được nhiều về cách AI có thể đóng vai trò cộng tác viên sáng tạo, giúp developer tập trung hơn vào logic và tư duy hệ thống thay vì những thao tác lặp lại. Bài học rút ra Tham gia workshop \u0026ldquo;AI DLC x Kiro\u0026rdquo; là một turning point trong cách tôi nhìn nhận về vai trò của AI trong software development.\nĐiều quan trọng nhất tôi học được không phải là các công cụ cụ thể, mà là mindset shift cần thiết:\nAI không phải là công cụ để code nhanh hơn AI là partner để tư duy và thiết kế hệ thống tốt hơn Structured process (như AI-DLC) quan trọng hơn là raw AI power Workshop cũng cho tôi thấy tương lai của development tools - nơi AI-first architecture như Kiro sẽ trở thành standard, và developers cần prepare cho paradigm shift này.\nNhững insights từ AWS Solution Architects và hands-on experience với Kiro đã trang bị cho tôi foundation vững chắc để áp dụng AI vào learning journey và future career trong software engineering.\nMột số hình ảnh khi tham gia sự kiện Hình nhóm check-in sau sự kiện\nĐây là khoảnh khắc check-in của nhóm sau khi kết thúc workshop. Sự kiện này mang lại nhiều insights quý giá về cách AI đang reshape development workflow.\nKhông gian sự kiện chuyên nghiệp\nWorkshop được tổ chức bài bản với đầy đủ demo stations và networking opportunities. Đây là một trong những sự kiện quan trọng giúp em hiểu sâu về AI-driven development.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Hiểu rõ AWS VPC: Nắm vững khái niệm cơ bản về VPC (Virtual Private Cloud) như một môi trường mạng logic cô lập, bao gồm các thành phần chính như Subnets (Public và Private), Route Tables, và ENI.\nKiểm soát lưu lượng và bảo mật: Học cách cấu hình các lớp bảo mật (Security Groups và NACLs) và kiểm soát đường đi của lưu lượng mạng ra/vào Internet (Internet Gateway và NAT Gateway).\nKết nối mạng phức tạp: Phân biệt và biết cách sử dụng các phương thức kết nối giữa các VPC (VPC Peering) và mô hình kết nối trung tâm (Transit Gateway).\nXây dựng môi trường Hybrid Cloud: Tìm hiểu các giải pháp kết nối mạng tại chỗ (on-premises) với AWS, bao gồm VPN (Site-to-Site) và kết nối riêng tư (AWS Direct Connect).\nPhân phối tải ứng dụng: Hiểu chức năng của Elastic Load Balancing (ELB) và phân biệt được các loại bộ cân bằng tải khác nhau (ALB, NLB, CLB, GLB) để đảm bảo tính sẵn sàng cao và khả năng mở rộng cho ứng dụng.\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Tìm hiểu về AWS Virtual Private Cloud (VPC)\n+ VPC là gì?\n+ Cấu trúc của VPC được hoạt động như thế nào?\n- Tìm hiểu về VPC-Subnets và kiến trúc của Subnet?\n- Tìm hiểu về VPC-Route Table?\n- Tìm hiểu về VPC-ENI và kiến trúc của VPC-ENI?\n- Tìm hiểu về VPC-Endpoint và kiến trúc của VPC-Endpoint?\n- Tìm hiểu về VPC-Internet Gateway và kiến trúc của VPC-Internet Gateway?\n- Tìm hiểu về VPC-NAT Gateway và kiến trúc của VPC-NAT Gateway?\n- Tìm hiểu về VPC-Security Group và kiến trúc của VPC-Security Group?\n- Tìm hiểu về VPC-NACL và kiên trúc của VPC-NACL?\n- Tìm hiểu về VPC-Flow Logs 15/09/2025 15/09/2025 Module 02 3 - Tìm hiểu về các dịch vụ mạng trên AWS?\n- Tìm hiểu về VPC Peering và kiến trúc của VPC Peering?\n- Tìm hiểu về Transit Gateway và kiến trúc của Transit Gateway?\n- Nắm rõ các khái niệm về dịch vụ VPN \u0026amp; Direct Connect?\n- VPN Site to Site là gì? Việc thiết lập nó như thế nào?\n- Tìm hiểu về VPN Client to Site?\n- AWS Direct Connect là gì? 16/09/2025 16/09/2025 Module 02 4 - Tìm hiểu về các khái niệm và tổng quan về Elastic Load Balancing? Và các loại ELB hiện nay?\n- Tìm hiểu về ELB - Application Load Balancer và kiến trúc của nó?\n- Tìm hiểu về ELB - Network Load Balancer và nắm rõ khái niệm?\n- Tìm hiểu về ELB - Classic Load Balancer và nắm rõ khái niệm?\n- Tìm hiểu về ELB - ELB - Gateway Load Balancer và kiến trúc của nó? 17/09/2025 17/09/2025 Module 02 5 - Lab 03 - Khởi tạo VPC\n1. Cấu hình tường lửa VPC\n2.Thực hành tạo 1 VPC\n3. Cấu hình Site to Site VPN\n- Lab 58 - System Manage - Session Manage\n1. Tạo kết nối đến máy chủ EC2\n2. Quản lí sessioin logs\n3. Sử tính năng Port Forwarding\n- Lab 19 - Thiết lập VPC Peering\n1. Cập nhật Network ACL\n2. Tạo kết nối Peering\n3. Cấu hình Route tables\n4. Kích hoạt Cross-Peer DNS 18/09/2025 18/09/2025 Module 02 6 - Lab 20 - Thiết lập Transit Gateway\n1. Thiết lập hạ tầng\n2. Tạo Transit Gateway -\u0026gt; Nối nhiều VPC lại với nhau\n3. Transit Gateway Attachments\n4. Tạo Route Table cho TGW\n5. Thêm Gateway vào Route Tables \u0026amp; Kiểm tra kết quả\n- Lab 10 - Hybrid DNS\n1. Thiết lập Hybrid DNS\n2. Tạo Outbound Endpoint\n3. Tạo Route 53 Resolver Rule\n4. Tạo Inbound Endpoint.\n- Nghiên cứu bổ sung về AWS Advanced Networking - Specialty Study Guid 19/09/2025 19/09/2025 Module 02 Research Link Kết quả đạt được tuần 2: Giải thích được VPC là gì, vai trò của nó trong AWS, và các thành phần cốt lõi của nó (Subnet, Route Table, ENI). Phân biệt rõ ràng giữa Public Subnet (có Internet Gateway) và Private Subnet (sử dụng NAT Gateway để truy cập Internet). So sánh và đối chiếu hai cơ chế tường lửa chính: Security Group (stateful, áp dụng cho ENI) và NACL (stateless, áp dụng cho Subnet). Trình bày được cách thức kết nối riêng tư từ VPC đến các dịch vụ AWS (như S3) mà không cần qua Internet bằng VPC Endpoint. Đánh giá được ưu nhược điểm giữa hai giải pháp kết nối VPC: VPC Peering (kết nối 1:1, không hỗ trợ bắc cầu) và Transit Gateway (mô hình hub-and-spoke, đơn giản hóa quản lý). Mô tả được các phương thức thiết lập kết nối hybrid cloud, bao gồm VPN Site-to-Site (qua Internet) và AWS Direct Connect (kết nối vật lý riêng). Phân loại và lựa chọn được loại Elastic Load Balancer phù hợp cho từng kịch bản cụ thể: Application Load Balancer (ALB): Cho lưu lượng HTTP/HTTPS (Layer 7), hỗ trợ path-based routing. Network Load Balancer (NLB): Cho lưu lượng TCP/TLS (Layer 4), cần hiệu suất cực cao và IP tĩnh. Gateway Load Balancer (GLB): Dùng để tích hợp các thiết bị mạng ảo (virtual appliances). Xác định được các bài thực hành (Lab) cần thiết để củng cố kiến thức đã học về VPC, Peering, Transit Gateway và các dịch vụ liên quan. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Ứng dụng quản lý tài chính cá nhân (Vicobi) Bạn có thể đọc toàn bộ proposal ở đây: Vicobi Proposal 1. Tóm tắt điều hành Dự án Vicobi (Personal Finance Management App) hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Vicobi đơn giản hóa việc quản lý tài chính qua 4 trụ cột chính:\nGhi chép thông minh (Smart Recording): Nhập liệu bằng giọng nói và quét hóa đơn, loại bỏ rào cản nhập liệu thủ công. Lập ngân sách theo mục tiêu (Goal-based Budgeting): Tự động hóa tạo và quản lý các hũ tiền (money jars) linh hoạt. Phân tích \u0026amp; Kiểm soát: Cung cấp báo cáo trực quan và hệ thống cảnh báo thông minh. Trợ lý tài chính (AI Chatbot): Tích hợp Chatbot AI đóng vai trò tư vấn viên, hỗ trợ giải đáp và nâng cao kiến thức tài chính. Về mặt công nghệ, Vicobi được xây dựng trên kiến trúc Microservices sử dụng .NET Aspire và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint trong giai đoạn phát triển chính), với mục tiêu hoàn thành MVP trong 2 tháng thực thi.\n2. Tuyên bố vấn đề Vấn đề hiện tại Trong thị trường năng động hiện nay, người dùng gặp khó khăn trong việc kiểm soát tài chính do \u0026ldquo;sức ỳ hành vi\u0026rdquo; — ngại ghi chép thủ công từng giao dịch. Các ứng dụng hiện có (như Money Lover, Misa Money Keeper) vẫn dựa nhiều vào nhập liệu bằng tay, gây ra tình trạng \u0026ldquo;mệt mỏi khi nhập liệu\u0026rdquo; (input fatigue) và tỷ lệ bỏ cuộc cao.\nGiải pháp Vicobi giải quyết vấn đề bằng cách tự động hóa cao độ quy trình nhập liệu thông qua AWS Cloud và Microservices:\nCông nghệ lõi: Tích hợp AI xử lý giọng nói tiếng Việt (Voice-to-Text) và nhận diện hóa đơn (OCR) chi tiết. Kiến trúc tối ưu: Sử dụng AWS ECS Fargate chạy mô hình Multi-container Task (gộp Backend .NET và AI Service) để giảm chi phí hạ tầng nhưng vẫn đảm bảo giao tiếp liền mạch. Frontend hiện đại: Sử dụng Next.js được lưu trữ trên Amazon S3 và phân phối toàn cầu qua Amazon CloudFront. Lợi ích và hoàn vốn đầu tư (ROI) Giải pháp mang lại lợi thế cạnh tranh rõ rệt:\nGiá trị người dùng: Giảm hơn 70% thao tác thủ công. Độ chính xác nhận diện giọng nói đạt 90% và trích xuất hóa đơn đạt 80%. Hiệu quả kinh tế: Tận dụng tối đa AWS Free Tier (S3, CloudFront, Cognito). Ngân sách vận hành tinh gọn khoảng ~$60/tháng cho hạ tầng và ~$15/tháng cho AI compute. Hoàn vốn: Dự kiến đạt ROI trong 6–12 tháng nhờ tiết kiệm thời gian và tăng hiệu suất. Khả năng mở rộng: Kiến trúc Microservices sẵn sàng cho việc tích hợp Mobile App hoặc Open Banking. 3. Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình Microservices phân tán, sử dụng API Gateway làm điểm nhập duy nhất.\nChi tiết Tech Stack: Thành phần Công nghệ Chi tiết Frontend Next.js 16 App Router, TypeScript, Tailwind CSS, Zustand, React Query. Backend Core .NET Aspire Điều phối Microservices (User, Wallet, Transaction, Report, Notification). AI Service FastAPI (Python) Xử lý Voice (PhoWhisper), OCR (Bedrock), Chatbot (RAG). Database Polyglot PostgreSQL, MongoDB, Elasticsearch, Qdrant (Vector DB). Messaging RabbitMQ Giao tiếp bất đồng bộ giữa các service. Luồng hoạt động trên AWS: Truy cập: Người dùng truy cập qua Route 53, được bảo vệ bởi AWS WAF và tăng tốc bởi CloudFront. Xác thực: Amazon Cognito quản lý định danh và cấp phát JWT Token. Xử lý API: Request đi qua API Gateway, kết nối an toàn qua AWS PrivateLink tới Application Load Balancer (ALB). Compute: ALB phân phối tải tới các container trong ECS Fargate (nằm trong Private Subnet). DevOps: Quy trình CI/CD tự động hóa hoàn toàn bằng GitLab, build image đẩy lên Amazon ECR và update task trên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai Dự án kéo dài 4 tháng (bao gồm thực tập):\nTháng 0 (Pre-internship): Lên ý tưởng và kế hoạch tổng thể. Tháng 1 (Foundation): Học AWS, nâng cấp kỹ năng .NET/Next.js/AI. Thiết lập VPC, IAM. Tháng 2 (Design): Thiết kế kiến trúc High-level \u0026amp; Detailed trên AWS. Tháng 3-4 (Realization): Coding, Integration Testing, Deploy lên AWS Production, thiết lập Monitoring. Sau tháng 5: Nghiên cứu phát triển Mobile App. Yêu cầu kỹ thuật chi tiết: Frontend: Triển khai Next.js 16 trên S3 + CloudFront. Sử dụng Origin Access Control (OAC) để bảo mật bucket. Backend: Sử dụng .NET Aspire để quản lý cấu hình Cloud-native. Database-per-service: PostgreSQL \u0026amp; MongoDB. Elasticsearch cho tìm kiếm giao dịch phức tạp. Background Jobs: Sử dụng Hangfire. AI Service Pipelines: Voice: Tiền xử lý bằng Pydub, Model PhoWhisper-small (VinAI) cho tiếng Việt. OCR: Amazon Bedrock (Claude 3.5 Sonnet Multimodal) để trích xuất thông tin hóa đơn chính xác. Chatbot (RAG): Knowledge Base lưu trong Qdrant, sinh câu trả lời qua Amazon Bedrock (Claude 3.5 Sonnet). Bảo mật: Mã hóa dữ liệu đường truyền (HTTPS/TLS 1.2+) và lưu trữ (AES-256). Quản lý bí mật (Secrets) chưa tích hợp sâu (đang ở mức MVP), sẽ nâng cấp lên AWS Secrets Manager trong tương lai. 5. Lộ trình \u0026amp; Mốc triển khai (Sprints) Giai đoạn thực thi chính được chia thành 4 Sprint:\nSprint 1: Core Foundation Xác thực (Cognito), Quản lý Ví (Wallets), Hũ chi tiêu (Spending Jars). Sprint 2: Core Features Giao dịch (CRUD), Xử lý giọng nói AI (Voice Processing). Sprint 3: Analytics Báo cáo/Biểu đồ, Hệ thống thông báo (SES), Message Broker. Sprint 4: Stabilization Kiểm thử tích hợp (Integration Testing), Tinh chỉnh UI, Deploy lên AWS ECS \u0026amp; CloudFront. Testing \u0026amp; Go-live: Cấu hình Domain, SSL, Monitoring Dashboard, UAT và bảo vệ đồ án. 6. Ước tính ngân sách Dựa trên bảng dự toán chi tiết cho giai đoạn MVP.\nBạn có thể xem chi tiết bảng dự toán chi phí bằng cách tải về các tệp sau: 📊 Tệp định dạng CSV 💾 Tệp định dạng JSON\nDịch vụ AWS Thành phần / Sử dụng Chi Phí (USD/tháng) Elastic Load Balancing Application Load Balancer $18.98 Amazon ECS Fargate (vCPU \u0026amp; Memory) $17.30 Amazon VPC VPC Endpoints \u0026amp; NAT $10.49 AWS WAF Web ACL \u0026amp; Requests $7.20 Amazon API Gateway API Calls \u0026amp; Data Transfer $2.50 Amazon CloudFront Data Transfer Out $2.00 Amazon ECR Storage $1.00 Amazon Route 53 Hosted Zones $0.54 Amazon S3 Standard Storage $0.34 TỔNG CHI PHÍ AWS ~$60.35 Chi phí khác:\nHạng mục Chi tiết Chi Phí (USD/tháng) AI Compute / Tooling Gemini API, Amazon Bedrock ~$15.00 TỔNG CỘNG DỰ ÁN ~$75.35 / tháng (Dựa trên giá On-Demand khu vực Singapore - ap-southeast-1)\n7. Đánh giá rủi ro Rủi ro chính: Lộ thông tin người dùng (Impact: High), Mất kết nối AWS Region (Impact: High), AI nhận diện sai (Impact: Medium). Chiến lược giảm thiểu: Bảo mật: Mã hóa AES-256, HTTPS, IAM Least Privilege, AWS WAF. High Availability: Triển khai Multi-AZ cho ECS và ALB. AI: Cải thiện model liên tục với dữ liệu thực tế. Resilience: Sử dụng RabbitMQ nội bộ để xử lý bất đồng bộ và retry. Kế hoạch dự phòng (Disaster Recovery): Sử dụng IaC (Infrastructure as Code) để khôi phục nhanh hạ tầng. 8. Kết quả kỳ vọng \u0026amp; Đội ngũ Kết quả mong đợi của dự án Nhập liệu tài chính tự động: Ứng dụng giúp người dùng tránh nhập liệu thủ công, chỉ cần chụp ảnh hóa đơn hoặc ghi âm giọng nói để hệ thống tự động phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo hàng tháng và nhận đề xuất tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối thiểu: Giao diện web thân thiện, thiết kế hiện đại, được tối ưu hóa cho thiết bị di động và phù hợp với người mới bắt đầu quản lý tài chính. Hệ thống ổn định, có khả năng mở rộng: Kiến trúc microservices giúp dễ dàng thêm các tính năng mới như nhắc nhở chi tiêu, phân tích dự đoán AI hoặc mở rộng sang ứng dụng di động. Nâng cao kỹ năng nhóm phát triển: Các thành viên dự án có quyền truy cập thực tế vào các quy trình DevOps, triển khai CI/CD và tối ưu hóa ứng dụng trên nền tảng đám mây. Hạn chế của dự án Mô hình AI Việt Nam còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay vẫn chưa đạt độ chính xác cao.\nKhông có ứng dụng di động riêng biệt: Phiên bản MVP chỉ hỗ trợ nền tảng web, không có ứng dụng di động gốc.\nĐội ngũ thực hiện (Team): Họ tên Vai trò Email Lê Vũ Phương Hòa Backend Developer (Leader) hoalvpse181951@fpt.edu.vn Nguyễn Văn Anh Duy AI Developer (Member) duynvase181823@fpt.edu.vn Uông Tuấn Vũ Frontend Developer (Member) vuutse180241@fpt.edu.vn Trần Nguyễn Bảo Minh AI Developer (Member) baominhbrthcs@gmail.com Mentor Support:\nNguyễn Gia Hưng - Head of Solution Architects Văn Hoàng Kha - Cloud Security Engineer "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.2-prerequiste/5.2.2-prepare-data/",
	"title": "Chuẩn bị dữ liệu nguồn",
	"tags": [],
	"description": "",
	"content": "Tổng quan Khởi tạo một kho lưu trữ đối tượng (S3 Bucket) để chứa các tài liệu gốc (PDF, Word, Text). Đây đóng vai trò là \u0026ldquo;nguồn sự thật\u0026rdquo; (Source of Truth) mà Knowledge Base sẽ truy cập để đọc hiểu, phân tích và đồng bộ hóa kiến thức cho AI. Bạn có thể lưu trữ kiến thức liên quan đến lĩnh vực của bạn sử dụng trong việc tạo trợ lý cá nhân hoặc Chatbot cho riêng bạn.\nChuẩn bị dữ liệu Chúng ta sẽ tạo một S3 Bucket để lưu trữ tài liệu gốc, đóng vai trò là nguồn tri thức cho Chatbot.\nBước 1. Tạo S3 Bucket\nTruy cập dịch vụ S3 từ thanh tìm kiếm. AWS Region: Chọn United States (N. Virginia us-east-1). Click Create bucket. Cấu hình thông tin Bucket: Bucket Type: Chọn General purpose Bucket name: Nhập rag-workshop-demo Object Ownership: Giữ mặc định ACLs disabled. Block Public Access settings: Giữ mặc định (Đã chọn Block all public access). Kéo xuống cuối trang, Click Create bucket. Kiểm tra tạo S3 Bucket thành công. Bước 2. Tải lên tài liệu mẫu\nĐây tài liệu mẫu, liên quan để tổng quan về kiến thức điện toán đám mây của AWS. Bạn có thể sử dụng để chạy demo hoặc upload dữ liệu của bạn. Tệp định dạng PDF\nTại danh sách Buckets, Click vào tên bucket bạn vừa tạo. Click Upload. Tại giao diện Upload: Click Add files. Chọn file tài liệu mẫu đính kèm ở phần trên hoặc file từ máy tính của bạn (Khuyên dùng file PDF hoặc Word có nhiều nội dung văn bản). Khi upload file xong, chọn file vừa upload, kéo xuống cuối trang, Click Upload. Khi thấy thông báo màu xanh \u0026ldquo;Upload succeeded\u0026rdquo;, Click Close. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.2-prerequiste/",
	"title": "Chuẩn bị môi trường",
	"tags": [],
	"description": "",
	"content": "1. Mục tiêu Trước khi bắt tay vào xây dựng ứng dụng, chúng ta cần thiết lập một nền tảng vững chắc. Giống như việc chuẩn bị nguyên liệu trước khi nấu ăn, phần này đảm bảo rằng tài khoản AWS của bạn đã sẵn sàng với đầy đủ quyền hạn và dữ liệu cần thiết.\nTrong phần này, chúng ta sẽ hoàn thành 3 mục tiêu khởi tạo quan trọng:\nChọn Region (Vùng): Thiết lập môi trường làm việc tại vùng United States N. Virginia (us-east-1) để tối ưu hóa tốc độ kết nối và đảm bảo tính sẵn sàng của dịch vụ. Kích hoạt Model (Model Access): Kiểm tra và đảm bảo tài khoản có quyền gọi model Anthropic Claude 3 – \u0026ldquo;bộ não\u0026rdquo; ngôn ngữ chính của hệ thống. Chuẩn bị Dữ liệu (Data Setup): Khởi tạo kho lưu trữ (S3 Bucket) và tải lên tài liệu nguồn để phục vụ cho quá trình nạp kiến thức (Ingestion) sau này. 2. Các thành phần chính Trong phần chuẩn bị này, chúng ta sẽ tương tác với các thành phần sau:\nAWS Management Console (Region Selector): Giao diện quản lý chung để chuyển đổi Region làm việc sang United States N. Virginia. Amazon Bedrock (Model Access \u0026amp; Playground): Nơi quản lý quyền truy cập các mô hình nền tảng (Foundation Models) và công cụ chat để kiểm tra nhanh khả năng phản hồi của AI. Amazon S3 (Simple Storage Service): Dịch vụ lưu trữ đối tượng, nơi chúng ta sẽ tạo Bucket để chứa các file tài liệu gốc (PDF, Word, Text). 3. Các bước triển khai Kiểm tra truy cập Model Chuẩn bị dữ liệu nguồn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/5.3.2-sync-data/",
	"title": "Kiểm tra Vector Store và Đồng bộ Dữ liệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Trước khi AI có thể trả lời, dữ liệu phải được nhập vào kho lưu trữ vector (Vector Store). Chúng ta sẽ thực hiện kiểm tra \u0026ldquo;Trước và Sau\u0026rdquo; để thấy rõ cách Bedrock tự động mã hóa và lưu trữ dữ liệu vào OpenSearch.\nCác Bước Thực hiện Bước 1: Kiểm tra Vector Store (Trạng thái Rỗng)\nChúng ta sẽ truy cập trực tiếp vào Amazon OpenSearch Serverless để xác nhận rằng chưa có dữ liệu nào tồn tại.\nTrong thanh tìm kiếm AWS Console, gõ Amazon OpenSearch Service và chọn Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Nhấp vào tên Collection mới được tạo bởi Bedrock (thường có tên dạng bedrock-knowledge-data...). Trên trang chi tiết Collection, nhấp vào nút Open Dashboard (nằm ở góc trên bên phải màn hình).\nLưu ý: Nếu được yêu cầu đăng nhập, hãy sử dụng thông tin đăng nhập AWS hiện tại của bạn. Trong giao diện OpenSearch Dashboard: Nhấp vào biểu tượng Menu (3 đường ngang) ở góc trên bên trái. Chọn Dev Tools (thường nằm ở cuối danh sách menu). Trong ngăn Console (bên trái), nhập lệnh sau để kiểm tra dữ liệu: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Nhấp vào nút Play (Run) (tam giác nhỏ bên cạnh dòng lệnh). Kết quả: Quan sát ngăn bên phải, hits -\u0026gt; total -\u0026gt; value là 0. Bước 2: Đồng bộ Dữ liệu\nBây giờ chúng ta sẽ kích hoạt Bedrock để đọc các file từ S3 và tải chúng vào OpenSearch.\nQuay lại tab Amazon Bedrock trên trình duyệt. Chọn Knowledge bases trong menu bên trái và nhấp vào tên KB bạn vừa tạo. Cuộn xuống phần Data source, đánh dấu vào ô (tick) bên cạnh tên nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Quá trình này sẽ mất 5 - 10 phút tùy thuộc vào kích thước tài liệu mẫu. Chờ cho đến khi cột Sync status chuyển từ Syncing sang Available. Bước 3: Kiểm tra lại Vector Store (Đã có Dữ liệu)\nSau khi Bedrock báo hoàn tất Sync, chúng ta quay lại kho lưu trữ để xác minh dữ liệu đã được nhập thành công.\nChuyển sang tab OpenSearch Dashboard (vẫn còn mở từ Bước 1). Trong Dev Tools, nhấp lại nút Play (Run) với lệnh cũ: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Kết quả: Phần hits -\u0026gt; total -\u0026gt; value sẽ lớn hơn 0 (ví dụ: 10, 20\u0026hellip; tùy thuộc vào số lượng đoạn văn bản). Bạn sẽ thấy chi tiết các vector (mảng số) và nội dung văn bản được lưu trữ trong trường _source. Chúc mừng! Bạn đã hoàn thành việc xây dựng \u0026ldquo;bộ não\u0026rdquo; cho AI. Dữ liệu đã được mã hóa và nằm an toàn trong Vector Database, sẵn sàng cho việc truy xuất.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch: WORKSHOP “KHOA HỌC DỮ LIỆU TRÊN NỀN TẢNG AWS” Mục Đích Của Sự Kiện Giới thiệu tổng quan hệ sinh thái các dịch vụ trí tuệ nhân tạo (AI) hiện có trên AWS. Hướng dẫn quy trình thực tế để xây dựng và huấn luyện mô hình AI sử dụng Amazon SageMaker. Minh họa cách thức đưa mô hình AI từ phòng thí nghiệm ra thực tế (deployment) và tích hợp vào ứng dụng thông qua API. Danh Sách Diễn Giả Anh Văn Hoàng Kha - Cloud Solutions Architect, Leader của AWS User Group (Chia sẻ góc nhìn kiến trúc giải pháp). Anh Bạch Doãn Vương - Cloud DevOps Engineer, AWS Community Builder (Chia sẻ góc nhìn vận hành và triển khai). Nội Dung Chuyên Sâu Tầm Quan Trọng Của Điện Toán Đám Mây Trong Data Science Phân tích vai trò cốt lõi của Cloud Computing: Không chỉ là nơi lưu trữ, Cloud cung cấp sức mạnh tính toán vô hạn để xử lý dữ liệu lớn (Big Data) và huấn luyện các mô hình AI phức tạp mà máy tính cá nhân khó đáp ứng.\nSo sánh hiệu quả giữa Cloud và On-premise (Máy chủ vật lý):\nCloud: Điểm mạnh nằm ở tính đàn hồi (Elasticity) — có thể tăng/giảm tài nguyên tức thì, triển khai cực nhanh, chuyển đổi chi phí đầu tư (CAPEX) thành chi phí vận hành (OPEX), và dễ dàng tích hợp các công nghệ mới. On-premise: Gặp rào cản lớn về chi phí phần cứng ban đầu, khó khăn trong việc mở rộng hạ tầng khi dữ liệu tăng đột biến và tốn kém nhân lực bảo trì. AWS đóng vai trò là xương sống cho toàn bộ Data Science pipeline: Cung cấp một quy trình khép kín từ lúc thu thập dữ liệu thô, làm sạch, huấn luyện đến khi mô hình được đưa vào sử dụng thực tế.\nPhân Tầng Kiến Trúc AI Trên AWS AWS phân loại các dịch vụ AI thành 3 tầng (layers) riêng biệt, được thiết kế để phù hợp với từng đối tượng người dùng có trình độ kỹ thuật và nhu cầu kiểm soát khác nhau:\n1. AI Services (Tầng Dịch Vụ Được Quản Lý Hoàn Toàn)\nGiải pháp \u0026ldquo;Mì ăn liền\u0026rdquo; dành cho Developer muốn tích hợp trí thông minh vào ứng dụng mà không cần am hiểu sâu về thuật toán ML.\nĐây là các mô hình đã được AWS huấn luyện sẵn (Pre-trained models) với hàng tỷ điểm dữ liệu.\nNgười dùng chỉ cần gửi dữ liệu qua API và nhận lại kết quả phân tích.\nCác dịch vụ tiêu biểu:\nAmazon Comprehend: Hiểu và phân tích ý nghĩa văn bản, cảm xúc người dùng (NLP). Amazon Translate: Xóa bỏ rào cản ngôn ngữ với khả năng dịch thuật tự động. Amazon Textract: \u0026ldquo;Đọc\u0026rdquo; tài liệu, bóc tách chữ viết và bảng biểu từ file scan/ảnh. Amazon Rekognition: Thị giác máy tính, nhận diện vật thể, khuôn mặt trong ảnh/video. Amazon Polly: Giọng đọc nhân tạo tự nhiên (Text-to-Speech). Amazon Bedrock: Cổng kết nối đến các mô hình ngôn ngữ lớn (LLMs) hàng đầu hiện nay. Lợi ích: Tốc độ đưa sản phẩm ra thị trường (Time-to-market) cực nhanh, không tốn công sức xây dựng mô hình từ số 0.\n2. ML Services (Tầng Bán Quản Lý)\nCông cụ đắc lực cho Data Scientist \u0026amp; ML Engineer cần môi trường chuyên nghiệp để tự xây dựng mô hình.\nAmazon SageMaker là trái tim của tầng này, cung cấp một nền tảng thống nhất để quản lý vòng đời của mô hình ML (ML Ops).\nCác module quan trọng:\nData Wrangler: Giảm thiểu thời gian chuẩn bị và làm sạch dữ liệu (vốn chiếm 80% thời gian dự án). Feature Store: Kho lưu trữ các đặc trưng dữ liệu để tái sử dụng, tránh lãng phí tài nguyên tính toán. AutoML (SageMaker Autopilot): Tự động thử nghiệm nhiều thuật toán để tìm ra mô hình tốt nhất mà không cần can thiệp thủ công. Model Registry \u0026amp; Monitoring: Quản lý phiên bản mô hình và giám sát độ chính xác của mô hình theo thời gian thực (tránh hiện tượng model drift). Lợi ích: Cân bằng hoàn hảo giữa tính tiện lợi và khả năng tùy biến sâu vào quy trình huấn luyện.\n3. AI Infrastructure (Tầng Hạ Tầng Tự Quản Lý)\nDành cho các chuyên gia nghiên cứu (Researchers) cần can thiệp sâu vào phần cứng và tối ưu hóa ở mức thấp nhất.\nCung cấp \u0026ldquo;gạch nền\u0026rdquo; để tự xây dựng hệ thống AI tùy chỉnh:\nAmazon EC2 P5/G6/Inferentia: Các máy ảo gắn chip chuyên dụng (GPU/ASIC) cho hiệu suất tính toán cực cao. Amazon EKS / ECS: Quản lý container cho các ứng dụng ML quy mô lớn. AWS Lambda: Chạy code suy luận (inference) dạng serverless, tiết kiệm chi phí cho các tác vụ nhỏ. Amazon S3 / EFS: Hệ thống lưu trữ \u0026ldquo;hồ dữ liệu\u0026rdquo; (Data Lake) khổng lồ. Lợi ích: Không bị giới hạn bởi khuôn mẫu, tối ưu hóa chi phí triệt để cho các hệ thống siêu lớn, nhưng đòi hỏi kỹ năng DevOps cao.\nCác Dịch Vụ AI Phổ Biến Hỗ Trợ Sinh Viên \u0026amp; Nhà Nghiên Cứu 1. Amazon SageMaker\nLà một IDE (Môi trường phát triển tích hợp) dành riêng cho ML trên mây:\nTích hợp mọi công đoạn từ xử lý dữ liệu thô đến tinh chỉnh tham số (hyperparameter tuning). Cung cấp khả năng CI/CD cho Machine Learning, giúp tự động hóa quy trình train và deploy. Hỗ trợ Notebooks (Jupyter) quen thuộc với sinh viên. 2. Amazon Comprehend\nMang lại khả năng \u0026ldquo;đọc hiểu\u0026rdquo; cho ứng dụng:\nPhân tích cảm xúc: Biết khách hàng đang vui, giận hay hài lòng qua email/comment. Nhận dạng thực thể: Tự động phát hiện tên người, địa điểm, tổ chức trong văn bản. Bảo mật: Tự động tìm và che giấu thông tin cá nhân (PII) trong dữ liệu. 3. Amazon Translate\nDịch thuật chất lượng cao dựa trên Deep Learning (Neural Network). Khả năng tùy chỉnh từ vựng chuyên ngành (ví dụ: dịch đúng các thuật ngữ y khoa hoặc kỹ thuật). Giúp mở rộng phạm vi người dùng cho ứng dụng ra toàn cầu. 4. Amazon Textract\nVượt xa công nghệ OCR truyền thống nhờ khả năng hiểu cấu trúc tài liệu. Giữ nguyên định dạng bảng biểu, form mẫu khi trích xuất, giúp số hóa giấy tờ hành chính nhanh chóng và chính xác. Quy Trình Data Science Tiêu Chuẩn Trên AWS Ingest \u0026amp; Store: Thu thập dữ liệu từ nhiều nguồn vào \u0026ldquo;kho chứa\u0026rdquo; Amazon S3. Prepare: Làm sạch và chuẩn hóa dữ liệu bằng AWS Glue hoặc Lambda. Train \u0026amp; Tune: Sử dụng SageMaker để huấn luyện và tối ưu hóa thuật toán. Deploy: Đóng gói mô hình thành API Endpoint hoặc tích hợp vào ứng dụng. Monitor: Sử dụng CloudWatch để theo dõi sức khỏe hệ thống và chất lượng dự đoán của mô hình. Demo 1: Tối Ưu Hóa Workflow Với Low-Code/No-Code Mục tiêu: Chứng minh rằng rào cản kỹ thuật trong AI đang dần được xóa bỏ nhờ các công cụ trực quan.\nCông cụ: Amazon SageMaker Canvas (Giao diện kéo thả).\nQuy trình thực hiện:\nUpload bộ dữ liệu thô lên S3. Sử dụng giao diện đồ họa để định nghĩa luồng xử lý: Input -\u0026gt; Xử lý thiếu dữ liệu -\u0026gt; Chọn target column -\u0026gt; Train. Hệ thống tự động chạy thử nghiệm và trả về các chỉ số đánh giá (Accuracy, F1-score\u0026hellip;) dưới dạng biểu đồ dễ hiểu. Ý nghĩa: Giúp sinh viên và Business Analyst có thể tạo ra giá trị từ dữ liệu ngay lập tức mà không cần viết hàng ngàn dòng code Python.\nDemo 2: Từ Mô Hình Đến Ứng Dụng Thực Tế (Deployment) Mục tiêu: Minh họa \u0026ldquo;cây cầu\u0026rdquo; nối giữa mô hình toán học và người dùng cuối.\nCông cụ: SageMaker Endpoint kết hợp với API Gateway và Lambda.\nQuy trình thực hiện:\nBiến mô hình đã train thành một HTTP Endpoint (địa chỉ mạng). Thiết lập API Gateway để nhận yêu cầu từ bên ngoài (ví dụ: từ mobile app). Xử lý logic trung gian bằng AWS Lambda (serverless) để gọi model và trả kết quả về cho người dùng. Ý nghĩa: Cho thấy bức tranh toàn cảnh của việc làm sản phẩm AI: Model chỉ là một phần, việc tích hợp và phục vụ (serving) model mới tạo ra sản phẩm hoàn chỉnh.\nBảng So Sánh: Cloud vs. On-premise (Góc nhìn Hiệu Năng \u0026amp; Kinh Tế) Tiêu chí Cloud (AWS) On-premise (Máy chủ riêng) Khả năng mở rộng Vô hạn \u0026amp; Tức thì: Tự động scale theo lượng traffic thực tế. Cứng nhắc: Bị giới hạn bởi số lượng phần cứng hiện có. Mô hình chi phí OPEX (Chi phí vận hành): Dùng bao nhiêu trả bấy nhiêu, không lãng phí. CAPEX (Chi phí vốn): Phải bỏ tiền cục lớn mua máy móc, rủi ro khấu hao. Tốc độ triển khai Phút: Chỉ cần vài click chuột để có server. Tuần/Tháng: Phải đặt hàng, lắp đặt, cài đặt OS. Bảo trì hệ thống AWS lo: Tập trung hoàn toàn vào phát triển ứng dụng. Tự làm: Tốn nhân sự IT để vận hành điện, lạnh, phần cứng. Phù hợp với sinh viên Cao: Tận dụng gói Free Tier để học tập miễn phí. Thấp: Yêu cầu máy cấu hình cao đắt tiền. Kết Luận Chung AWS cung cấp một hệ sinh thái toàn diện và liền mạch, xóa nhòa khoảng cách giữa việc học thuật và ứng dụng thực tế. Dù là người mới bắt đầu hay doanh nghiệp lớn, AWS đều có bộ công cụ (Layer) phù hợp để giải quyết bài toán dữ liệu. Cảm Nhận Cá Nhân Sau Sự Kiện Buổi workshop “AI Services on AWS for Data Science” không chỉ cung cấp kiến thức lý thuyết mà còn mở ra tư duy mới về cách tiếp cận công nghệ, giúp tôi định hình rõ hơn con đường từ nghiên cứu dữ liệu đến xây dựng sản phẩm.\nMở rộng tư duy nhờ các chuyên gia Hiểu rõ lý do tại sao thế giới đang dịch chuyển lên Cloud: Đó là sự giải phóng khỏi gánh nặng hạ tầng để tập trung vào giá trị cốt lõi là dữ liệu. Nắm bắt được bức tranh tổng thể về 3 tầng AI, từ đó biết cách lựa chọn dịch vụ phù hợp cho từng giai đoạn của dự án cá nhân. Trực quan hóa kiến thức qua Demo Demo 1 (Canvas): Ấn tượng với khả năng \u0026ldquo;bình dân hóa\u0026rdquo; AI. Việc train model giờ đây trực quan như lắp ghép lego, giúp kiểm chứng ý tưởng cực nhanh. Demo 2 (Deployment): Đây là mảnh ghép tôi thường thiếu sót. Hiểu được cách tạo ra một API để người khác có thể dùng model của mình là bước ngoặt từ việc \u0026ldquo;làm bài tập\u0026rdquo; sang \u0026ldquo;làm sản phẩm\u0026rdquo;. Tiếp cận công nghệ tiên tiến Các dịch vụ như Comprehend hay Textract cho thấy sức mạnh của Pre-trained models. Chúng giúp giải quyết các bài toán khó (như đọc hóa đơn, phân tích sentiment) chỉ trong tích tắc mà không cần tự build model phức tạp. Giá trị kết nối Cơ hội thảo luận về bài toán chi phí (Cost optimization) là rất thực tế, giúp sinh viên như tôi biết cách dùng Cloud mà không \u0026ldquo;cháy túi\u0026rdquo;. Mạng lưới networking với các anh chị trong ngành giúp tôi có thêm động lực và định hướng nghề nghiệp rõ ràng hơn. Bài học cốt lõi Cloud First: Tư duy đưa mọi thứ lên mây là xu hướng tất yếu của Data Science hiện đại. Tính thực tiễn: Một mô hình AI chỉ có giá trị khi nó được deploy và giải quyết vấn đề cho người dùng cuối. Hệ sinh thái AWS: Là kho công cụ khổng lồ mà tôi cần tiếp tục khai phá để nâng cao năng lực bản thân. Một số hình ảnh ghi lại tại sự kiện Hình ảnh sự truyền đạt kiến thức từ 2 anh đến từ AWS\nHình ảnh đội FPTers check-in sau sự kiện\nĐây là khoảnh khắc check-in của toàn bộ các bạn đang thực tập tại AWS sau khi kết thúc workshop.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Hiểu kiến thức toàn diện về các dịch vụ máy chủ ảo (Compute VM) trên AWS. Tập trung vào dịch vụ cốt lõi là Amazon EC2, bao gồm cách lựa chọn cấu hình (Instance Types), các loại lưu trữ (EBS, Instance Store), và cách tự động hóa (User data, Auto Scaling). Tìm hiểu về các các dịch vụ liên quan như Amazon Lightsail (dịch vụ chi phí thấp), các giải pháp lưu trữ file chia sẻ (EFS cho Linux và FSx cho Windows/Linux), và dịch vụ di dời ứng dụng AWS MGN để chuyển máy chủ lên AWS hoặc xây dựng Disaster Recovery. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Amazon Elastic Compute Cloud (EC2)\n- Học về kiến trúc của Amazon EC2, một dịch vụ máy chủ ảo linh hoạt, có khả năng khởi tạo nhanh và co giãn tài nguyên mạnh mẽ.\n- Tìm hiểu về kĩ thuật lựa chọn cấu hình máy chủ thông qua EC2 Instance Type, yếu tố quyết định các yếu tố như CPU, Memory, Network và Storage.\n- Học về cách sử dụng AMI (Amazon Machine Image) để khởi tạo (provision) một hoặc nhiều EC2 Instances và dùng Key Pair (public và private key) để mã hóa thông tin đăng nhập.\n- Tìm hiểu về kĩ thuật lưu trữ khối EBS (Elastic Block Store), vốn hoạt động độc lập, được replicate dữ liệu (nhân 3) để đảm bảo độ sẵn sàng và kết nối với EC2 qua mạng.\n- Phân biệt EBS với Instance Store, là vùng đĩa NVME tốc độ cực cao nhưng dữ liệu sẽ bị xóa hết khi stop EC2.\n- Học về kĩ thuật tự động hóa User Data, một đoạn script (bash shell hoặc powershell) chạy một lần khi khởi tạo EC2.\n- Tìm hiểu về Meta Data, các thông tin liên quan đến EC2 (như IP, Hostname) có thể được truy cập từ chính máy chủ đó, thường dùng cho tự động hóa.\n- Tìm hiểu về kĩ thuật EC2 Auto Scaling để tự động tăng (scale-out) hoặc giảm (scale-in) số lượng EC2 Instance dựa theo các điều kiện (scaling policy).\n- Học về các EC2 Pricing Option (On-demand, Reserved Instance, Saving Plans, Spot Instance) để tối ưu chi phí. 22/09/2025 22/09/2025 Module 03 3 Amazon Lightsail\n- Học về dịch vụ Amazon Lightsail, một giải pháp máy chủ ảo chi phí thấp (từ 3,5$/tháng) phù hợp cho các workload nhẹ, môi trường test/dev.\n- Tìm hiểu về kĩ thuật kết nối Lightsail (nằm trong VPC đặc biệt) với VPC thông thường qua VPC Peering (chỉ bằng 1 click).\nAmazon EFS/FSX\n- Học về EFS (Elastic File System), dịch vụ lưu trữ file mạng (NFSv4) cho phép nhiều EC2 Instance (chỉ hỗ trợ Linux) mount vào cùng lúc, tính phí theo dung lượng sử dụng.\n- Học về Amazon FSx, dịch vụ cho phép tạo NTFS volume (giao thức SMB) để gán vào nhiều EC2 Instance (hỗ trợ Windows và Linux).\n- Tìm hiểu về kĩ thuật deduplication của FSx giúp giảm trùng lặp dữ liệu và giảm chi phí lưu trữ.\nAWS Application Migration Service (MGN)\n- Học về dịch vụ AWS MGN dùng để migrate (di dời) và replicate máy chủ (thật hoặc ảo) từ on-premise lên môi trường AWS.\n- Tìm hiểu về kĩ thuật sao chép (replication) của MGN để phục vụ mục đích xây dựng Disaster Recovery Site với chi phí thấp (sử dụng các máy staging cấu hình nhỏ). 23/09/2025 23/09/2025 Module 03 4 Lab: 000004 - Thao tác EC2 cơ bản.\n- Tạo máy chủ EC2\n- Thực hiện snapshot EC2 Instance\n- Cài đặt ứng dụng trên EC2\nLab: 000027 - Quản lí tài nguyên bằng Tag và Resource Group\n- Sử dụng Tag\n- Sử dụng Resource Group 24/09/2025 24/09/2025 Module 03 5 Lab: 000008 - Quản lí tài nguyên với Amazon Cloud Watch\n- CloudWatch Agent\n- Tạo CloudWatch Dashboard\nLab: 000006 - Triển khai Autoscaling Group\n- Khởi tạo Launch Template\n- Khởi tạo Target Group\n- Khởi tạo Load Balancer\n- Khởi tạo Auto Scaling Group\n- Kiểm tra kết quả. 25/09/2025 25/09/2025 Module 03 6 Lab: 000045 - Bắt đầu với Amazon Lightsail\n- Chuẩn bị\n- Kiểm tra ứng dụng trên Lightsail\n- Sử dụng Lightsail Loadbalancer\n- Sử dụng RDS\n- Dịch chuyển sang EC2.\n[Nghiên cứu bổ sung] - Microsoft Workloads on AWS\n- Series các bài thực hành bố sung dành cho việc chạy các máy chủ và ứng dụng của Microsoft trên AWS\n- Bổ sung kiến thức về hệ điều hành\n- Bổ sung các kiến thức về hệ điều hành Linux như LBI1, LBI2\n- Bổ sung các kiến thức về hệ điều hành Window học thêm về hệ thống quản trị Bundo. Tham khảo các series thực hành 26/09/2025 26/09/2025 Module 03 Research Link Kết quả đạt được tuần 3: Dịch vụ EC2: Hiểu rõ EC2 là dịch vụ máy chủ ảo cốt lõi của AWS. Kĩ thuật cấu hình EC2: Biết cách lựa chọn Instance Type (cấu hình CPU, RAM, Network) và sử dụng AMI để khởi tạo hệ điều hành cho máy chủ. Kĩ thuật bảo mật EC2: Nắm được cách dùng Key Pair (public/private key) để mã hóa thông tin đăng nhập, thay vì dùng mật khẩu. Dịch vụ lưu trữ (Storage): Phân biệt rõ ràng 2 loại lưu trữ đĩa chính cho EC2: EBS (Elastic Block Store): Là ổ đĩa mạng, hoạt động độc lập, dữ liệu được replicate x3 trong 1 AZ (độ sẵn sàng 99.999%), có thể backup bằng snapshot. Instance Store: Là ổ đĩa vật lý (NVME) tốc độ cực cao, nhưng dữ liệu là tạm thời (sẽ bị xóa khi stop EC2), thường dùng cho cache/buffer hoặc swap. Kĩ thuật tự động hóa (Automation): Biết cách dùng User Data để chạy script 1 lần khi máy chủ khởi động (ví dụ: cài đặt web server). Hiểu Meta Data là gì và cách dùng nó để lấy thông tin (IP, hostname) của máy chủ từ bên trong chính nó, phục vụ cho các script tự động hóa. Kĩ thuật co giãn (Scaling): Nắm vững khái niệm EC2 Auto Scaling để tự động tăng (scale-out) hoặc giảm (scale-in) số lượng máy chủ theo tải (ví dụ: khi ActiveConnectionCount cao hoặc thấp). Kĩ thuật tối ưu chi phí (Pricing): Nhận biết 4 mô hình giá EC2: On-demand (theo giờ/giây, đắt nhất), Reserved Instance (cam kết 1-3 năm), Saving Plans (cam kết 1-3 năm, linh hoạt hơn), và Spot Instance (giá rẻ, tận dụng tài nguyên dư nhưng có thể bị đòi lại). Dịch vụ Lightsail: Hiểu Amazon Lightsail là dịch vụ VM chi phí thấp, đơn giản hóa, phù hợp cho workload nhẹ, và biết cách peering nó với VPC. Dịch vụ lưu trữ file (File Storage): Phân biệt 2 dịch vụ lưu trữ file chia sẻ cho nhiều máy chủ: EFS (Elastic File System): Dùng cho Linux (giao thức NFSv4), tính phí theo dung lượng sử dụng. FSx: Dùng cho Windows/Linux (giao thức SMB), hỗ trợ tính năng deduplication để giảm chi phí. Dịch vụ di dời (Migration): Hiểu AWS MGN là dịch vụ để di dời máy chủ từ on-premise lên AWS hoặc dùng để xây dựng hệ thống Disaster Recovery (DR) với chi phí thấp thông qua staging area. Thực hành: Nắm được các bước thực hành cơ bản với EC2 (tạo, snapshot), triển khai một cụm Auto Scaling Group hoàn chỉnh (với Load Balancer), và làm quen với Lightsail. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Chuyển hướng lưu lượng ra Internet thông qua một transparent forward proxy Blog này giải thích cách triển khai giải pháp transparent forward proxy để kiểm tra tập trung lưu lượng truy cập Internet ra ngoài trên AWS. Bạn sẽ tìm hiểu tại sao transparent proxy quan trọng đối với các tổ chức cần kiểm tra toàn bộ lưu lượng ra ngoài mà không cần cấu hình cài đặt proxy tường minh trên từng thiết bị client, cách sử dụng Web Cache Communication Protocol (WCCP) để chuyển hướng lưu lượng một cách liền mạch thông qua các proxy server, và cách tích hợp giải pháp này với AWS Transit Gateway, AWS Network Firewall, và các thiết bị ảo của bên thứ ba. Bài viết hướng dẫn bạn qua thiết kế kiến trúc, cấu hình định tuyến, phân tích luồng gói tin, và cung cấp các trường hợp sử dụng thực tế cho truy cập Internet an toàn, phòng chống mất mát dữ liệu, và các yêu cầu tuân thủ quy định.\nBlog 2 - Xây dựng ứng dụng multi-Region Serverless có khả năng phục hồi trên AWS Blog này giải thích cách xây dựng các ứng dụng serverless đa vùng có khả năng phục hồi trên AWS để đảm bảo tính khả dụng cao cho các dịch vụ quan trọng. Bạn sẽ tìm hiểu tại sao kiến trúc đa vùng là cần thiết cho các ứng dụng không thể chịu được sự gián đoạn ở cấp vùng (như hệ thống xác thực, bộ xử lý thanh toán, và các tính năng game thời gian thực), cách lựa chọn giữa các mô hình triển khai Active-Passive và Active-Active dựa trên mục tiêu thời gian phục hồi và ràng buộc ngân sách của bạn, và cách các dịch vụ serverless AWS với mô hình định giá pay-for-value làm cho triển khai đa vùng tiết kiệm chi phí hơn so với các phương pháp truyền thống. Bài viết hướng dẫn bạn triển khai một bộ authorizer serverless đa vùng sử dụng Amazon API Gateway, AWS Lambda, Amazon Route 53, và DynamoDB Global Tables, đồng thời đề cập đến các phương pháp hay nhất cho chiến lược failover, giám sát sức khỏe, khả năng quan sát, và kiểm thử chaos engineering.\nBlog 3 - Tóm tắt hàng tuần về AWS: AWS Transform, Amazon Neptune, và nhiều hơn nữa (Ngày 08 tháng 09 năm 2025) Blog này cung cấp bản tóm tắt hàng tuần về các thông báo mới nhất của AWS và các sự kiện sắp tới trong tuần ngày 8 tháng 9 năm 2025. Bạn sẽ tìm hiểu về các dịch vụ AWS mới được ra mắt bao gồm khả năng đánh giá mở rộng của AWS Transform cho việc di chuyển detached storage, hỗ trợ global cross-region inference của Amazon Bedrock cho Anthropic Claude Sonnet 4, tính năng public endpoints mới của Amazon Neptune để đơn giản hóa việc truy cập cơ sở dữ liệu, tích hợp ECS Exec vào AWS Management Console để khắc phục sự cố container dễ dàng hơn, và cấu hình thông báo tổ chức của AWS User Notifications cho quản lý cảnh báo tập trung. Bài viết cũng nêu bật các sự kiện AWS sắp tới bao gồm AWS Summits ở nhiều thành phố khác nhau, AWS re:Invent 2025 tại Las Vegas, và các AWS Community Days do cộng đồng tổ chức trên khắp thế giới.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/",
	"title": "Tạo và Cấu hình Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Sau khi hoàn thành việc chuẩn bị môi trường và dữ liệu, bước tiếp theo là thiết lập thành phần cốt lõi của kiến trúc RAG. Trong phần này, chúng ta sẽ khởi tạo Knowledge Base, đóng vai trò là cơ chế trung gian thông minh kết nối các nguồn dữ liệu phi cấu trúc với khả năng suy luận của các foundation models.\nChúng ta sẽ thực hiện 3 mục tiêu kỹ thuật chính:\nThiết lập Pipeline Tự động: Cấu hình Knowledge Base để tự động hóa toàn bộ quy trình xử lý dữ liệu RAG (bao gồm trích xuất, phân đoạn văn bản và tạo vector) nhằm loại bỏ các tác vụ xử lý thủ công. Khởi tạo Vector Store: Triển khai một collection trên Amazon OpenSearch Serverless để lưu trữ các vector ngữ nghĩa, phục vụ việc truy xuất thông tin chính xác và hiệu quả. Đồng bộ hóa Dữ liệu (Data Ingestion): Thực hiện quy trình nhập dữ liệu ban đầu, chuyển đổi các tài liệu tĩnh từ S3 thành các vector có thể tìm kiếm trong hệ thống. Các Thành phần Chính Trong quá trình cấu hình này, chúng ta sẽ tương tác và kết nối các dịch vụ sau:\nKnowledge Bases for Amazon Bedrock: Dịch vụ được quản lý đóng vai trò là bộ điều phối luồng dữ liệu, kết nối các nguồn thông tin và thực thi các truy vấn ngữ nghĩa. Amazon Titan Embeddings G1 - Text v2: Mô hình chuyên dụng để chuyển đổi dữ liệu văn bản thành các vector số (Embeddings) với độ chính xác cao và hỗ trợ đa ngôn ngữ. Amazon OpenSearch Serverless: Cơ sở dữ liệu vector được quản lý hoàn toàn, chịu trách nhiệm lưu trữ và thực thi các thuật toán tìm kiếm tương đồng (k-NN). Các Bước Thực hiện Khởi tạo Knowledge Base Kiểm tra Vector Store và Đồng bộ Dữ liệu "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI” Mục Đích Của Sự Kiện Làm chủ kỹ thuật Prompt Engineering để tối ưu hóa đầu vào, giúp mô hình hiểu và thực hiện chính xác ý định của người dùng. Tận dụng sức mạnh của các Pretrained AI Services trên AWS để tích hợp tính năng thông minh nhanh chóng mà không cần xây dựng mô hình từ đầu. Hiểu sâu về kiến trúc RAG (Retrieval-Augmented Generation) để giải quyết vấn đề ảo giác và cập nhật dữ liệu riêng cho AI. Nắm bắt làn sóng công nghệ tiếp theo: Agentic AI và cách sử dụng Amazon Bedrock AgentCore để chuyển đổi AI Agent từ bản thử nghiệm (POC) sang môi trường thực tế (Production). Tiếp cận Pipecat Framework để xây dựng các trợ lý ảo giao tiếp bằng giọng nói với độ trễ thấp (Real-time). Danh Sách Diễn Giả Anh Lâm Tuấn Kiệt - Sr DevOps Engineer (FPT Software) - Chuyên gia về vận hành và triển khai hệ thống. Bạn Danh Hoàng Hiếu Nghị - AI Engineer (Renova Cloud) - Chuyên gia về các giải pháp trí tuệ nhân tạo. Anh Đinh Lê Hoàng Anh - Cloud Engineer Trainee (First Cloud AI Journey) - Chia sẻ góc nhìn từ người mới bắt đầu hành trình Cloud AI. Nội Dung Nổi Bật 1. Prompt Engineering \u0026amp; Foundation Models (Nền Tảng Cốt Lõi) Trước khi đi sâu vào các hệ thống phức tạp, sự kiện khẳng định rằng \u0026ldquo;chất lượng đầu vào quyết định chất lượng đầu ra\u0026rdquo;. Việc giao tiếp hiệu quả với các mô hình nền tảng (Foundation Models) trên Amazon Bedrock là bước đầu tiên:\nZero-shot / Few-shot Prompting: Kỹ thuật điều hướng mô hình bằng cách ra lệnh trực tiếp hoặc cung cấp một vài ví dụ mẫu (context) để AI học theo mẫu đó và trả về kết quả mong muốn. Chain of Thought (CoT): Một kỹ thuật nâng cao giúp AI xử lý các tác vụ suy luận phức tạp bằng cách yêu cầu nó \u0026ldquo;giải trình từng bước\u0026rdquo;. Điều này giúp giảm sai sót logic trong câu trả lời. 2. Các Dịch Vụ AI Được Huấn Luyện Trước (AWS AI Services) Đây là tầng ứng dụng giúp các lập trình viên không chuyên về Machine Learning vẫn có thể tích hợp AI vào sản phẩm thông qua API:\nThị giác máy tính: Amazon Rekognition giúp phân tích hình ảnh/video, nhận diện vật thể và kiểm duyệt nội dung. Xử lý ngôn ngữ tự nhiên: Bộ ba Amazon Translate (dịch thuật), Comprehend (phân tích cảm xúc/ngữ nghĩa), và Textract (OCR thông minh - trích xuất văn bản từ tài liệu). Xử lý âm thanh: Amazon Polly (chuyển văn bản thành giọng nói tự nhiên) và Transcribe (chuyển giọng nói thành văn bản). 3. RAG - Retrieval Augmented Generation RAG là giải pháp cầu nối giúp AI \u0026ldquo;học\u0026rdquo; được dữ liệu riêng của doanh nghiệp mà không cần huấn luyện lại (fine-tuning), giải quyết vấn đề mô hình bị lỗi thời hoặc \u0026ldquo;bịa\u0026rdquo; thông tin (hallucination):\nEmbeddings (Vector hóa): Sử dụng model như Amazon Titan Text Embeddings V2 để chuyển đổi văn bản thành các vector số học, giúp hệ thống hiểu và tìm kiếm dựa trên ngữ nghĩa (semantic search) thay vì chỉ khớp từ khóa. Knowledge Bases for Amazon Bedrock: Dịch vụ quản lý toàn trình (end-to-end), tự động hóa các khâu phức tạp: Cắt nhỏ tài liệu (Chunking) -\u0026gt; Lưu vào Vector Store -\u0026gt; Truy xuất dữ liệu liên quan (Retrieval) -\u0026gt; Tổng hợp câu trả lời (Generation). 4. Sự Tiến Hóa Lên Agentic AI (Kỷ Nguyên AI Tác Vụ) GenAI đang chuyển dịch từ việc chỉ \u0026ldquo;trả lời câu hỏi\u0026rdquo; sang \u0026ldquo;thực hiện hành động\u0026rdquo;. Sự kiện phân loại rõ lộ trình phát triển:\nGenAI Assistants: Trợ lý ảo thực hiện các tác vụ đơn lẻ, lặp lại dựa trên quy tắc có sẵn. GenAI Agents: AI hướng mục tiêu (Goal-oriented), có khả năng suy luận để chọn công cụ phù hợp nhằm hoàn thành một chuỗi công việc. Agentic AI Systems: Hệ sinh thái đa tác nhân (Multi-agent), hoạt động tự chủ cao (Autonomous), có thể tự phối hợp với nhau dưới sự giám sát tối thiểu của con người. Thách thức \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; (The Prototype to Production Chasm): Tại sao nhiều bản demo Agent rất hay nhưng thất bại khi đưa ra thực tế?\nHiệu năng \u0026amp; Mở rộng: Agent hoạt động chậm khi xử lý luồng suy luận dài. An toàn \u0026amp; Quản trị: Rủi ro khi Agent tự ý thực hiện hành động sai (ví dụ: xóa nhầm database) hoặc truy cập dữ liệu nhạy cảm. Độ phức tạp: Khó khăn trong việc duy trì bộ nhớ ngữ cảnh (Memory) qua các phiên làm việc dài. 5. Amazon Bedrock AgentCore: Giải Pháp Đưa Agent Ra Thị Trường AgentCore được giới thiệu như một nền tảng hạ tầng hoàn chỉnh để giải quyết các bài toán trên, giúp doanh nghiệp an tâm triển khai Agent:\nCác thành phần cốt lõi: Runtime \u0026amp; Memory: Cung cấp môi trường thực thi ổn định và khả năng \u0026ldquo;ghi nhớ\u0026rdquo; dài hạn các tương tác quá khứ. Identity \u0026amp; Gateway: Quản lý định danh chặt chẽ, đảm bảo Agent chỉ thực hiện đúng quyền hạn được cấp. Code Interpreter: Một \u0026ldquo;sandbox\u0026rdquo; an toàn cho phép Agent tự viết và chạy code Python để xử lý tính toán số liệu hoặc vẽ biểu đồ chính xác (thay vì tự đoán số liệu). Observability: Công cụ giám sát giúp con người theo dõi từng bước suy luận (Trace) của Agent để debug và tối ưu. Lợi ích: Giúp Developer tập trung vào logic nghiệp vụ, giảm gánh nặng xây dựng hạ tầng phụ trợ. 6. Pipecat: Framework Cho AI Voice Thời Gian Thực Giới thiệu một Framework mã nguồn mở giúp xây dựng các ứng dụng giao tiếp người-máy tự nhiên (Multimodal):\nĐặc điểm: Tối ưu hóa độ trễ (Latency) cực thấp, yếu tố sống còn trong giao tiếp thoại. Cơ chế Pipeline: WebRTC Input: Nhận luồng âm thanh trực tiếp từ trình duyệt/app. STT (Speech-to-Text): Dịch giọng nói sang văn bản tức thì. LLM Processing: AI suy nghĩ và sinh câu trả lời dưới dạng text. TTS (Text-to-Speech): Chuyển câu trả lời thành giọng nói. Output: Phát lại cho người dùng. Điểm mấu chốt là các bước này diễn ra gần như song song (streaming) để tạo cảm giác hội thoại liền mạch. Trải nghiệm chi tiết trong Event Buổi workshop đã giúp tôi hệ thống hóa lại kiến thức và nhìn thấy bức tranh lớn hơn về tương lai của AI.\n1. Sự chuyển dịch từ \u0026ldquo;Hỏi - Đáp\u0026rdquo; sang \u0026ldquo;Hành động\u0026rdquo; (Agentic AI) Điều làm tôi ấn tượng nhất là tư duy về Agentic AI. Trước đây, tôi chỉ xem AI như một công cụ tra cứu thông minh. Nhưng với AgentCore, AI trở thành một \u0026ldquo;nhân viên kỹ thuật số\u0026rdquo; có khả năng tự lập kế hoạch và sử dụng công cụ (API, Code, Search) để giải quyết vấn đề trọn vẹn. Đây là bước nhảy vọt về giá trị sử dụng.\n2. Giải quyết bài toán \u0026ldquo;Production\u0026rdquo; Phần chia sẻ về \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; rất thực tế. Nó giải thích tại sao nhiều dự án AI chết yểu. Việc AWS cung cấp các lớp bảo mật (Identity) và giám sát (Observability) trong Bedrock Agent là chìa khóa để doanh nghiệp dám tin tưởng giao quyền cho AI tác động vào hệ thống thực.\n3. Tiềm năng của Voice AI với Pipecat Demo về Pipecat cho thấy tương lai của giao tiếp không chạm. Việc kết hợp WebRTC và LLM để tạo ra hội thoại thời gian thực mở ra vô vàn ứng dụng: từ Tổng đài CSKH tự động, Luyện thi IELTS ảo, đến Trợ lý phỏng vấn.\nKết Luận Workshop “Generative AI \u0026amp; Agentic AI on AWS” đã phác thảo rõ lộ trình phát triển năng lực AI:\nHiện tại: Chúng ta dùng RAG và Prompt Engineering để khai thác dữ liệu hiệu quả. Tương lai gần: Chúng ta chuyển sang Agentic AI, nơi các hệ thống tự chủ (Autonomous Agents) sẽ thay con người vận hành các quy trình phức tạp. Công cụ: Với hệ sinh thái toàn diện của AWS (Bedrock, AgentCore) và cộng đồng Open Source (Pipecat, LangChain), rào cản kỹ thuật đã giảm đi đáng kể, nhường chỗ cho sự sáng tạo về giải pháp nghiệp vụ. Một số hình ảnh khi tham gia sự kiện Hình ảnh hơn 400 bạn tham dự buổi Event AWS Cloud Mastery Series #1\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Tìm hiểu kiến thức toàn diện về các dịch vụ lưu trữ đa dạng trên AWS. Tập trung sâu vào dịch vụ cốt lõi là Amazon S3 (Simple Storage Service), một dịch vụ lưu trữ đối tượng, bao gồm các đặc tính (như độ bền 11 số 9, nhân bản 3 AZ), các lớp lưu trữ (Storage Classes). Học về các tính năng quan trọng như quản lý vòng đời (Lifecycle Management), Versioning (lập phiên bản), và Static Website Hosting. Các giải pháp di dời dữ liệu quy mô lớn (dòng Snow Family), giải pháp lưu trữ hybrid kết nối on-premise với cloud (Storage Gateway), dịch vụ quản lý sao lưu tập trung (AWS Backup), và các khái niệm, chiến lược cơ bản về Disaster Recovery (DR). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Amazon Simple Storage Service - S3\n- Học về kiến trúc của Amazon S3, một dịch vụ lưu trữ dạng đối tượng (object), phù hợp với dữ liệu ghi một lần đọc nhiều lần (WORM).\n- Tìm hiểu về kĩ thuật nhân bản dữ liệu tự động trên 3 AZ trong 1 Region để đảm bảo độ sẵn sàng cao.\n- Tìm hiểu về độ bền (durability) của S3 được thiết kế lên đến 99.999999999% (11 số 9).\n- Tìm hiểu về kĩ thuật upload (HTTP PUT) và truy cập (HTTP GET) dữ liệu S3 thông qua REST API.\n- Học về kiến trúc của các lớp lưu trữ (Storage Class), bao gồm S3 Standard, S3 Standard IA, S3 Intelligent Tiering, S3 One Zone IA, và Amazon Glacier/Deep Archive.\n- Tìm hiểu về kĩ thuật quản lý vòng đời (Object Life Cycle Management) để tự động di chuyển object giữa các lớp lưu trữ theo thời gian.\n- Tìm hiểu về kĩ thuật host Static Website (phù hợp cho Single Page Application) và cấu hình CORS (Cross-origin resource sharing).\n- Tìm hiểu về kĩ thuật kiểm soát truy cập (Control Access) bằng S3 Access Control List (ACL) (gắn vào bucket/object) và S3 Bucket Policy (dễ quản lý hơn).\n- Học về kiến trúc của S3 Endpoint, cho phép truy cập S3 bucket thông qua mạng riêng của AWS mà không cần Internet.\n- Tìm hiểu về kĩ thuật Versioning (lập phiên bản) để khôi phục đối tượng sau khi vô tình xóa hay ghi đè, và hỗ trợ chống ransomware.\n- Tìm hiểu về kĩ thuật tối ưu hiệu năng (performance) S3 bằng cách dùng random prefix (tiền tố ngẫu nhiên) cho object key, giúp S3 lưu trữ object trên nhiều partition.\n- Học về kiến trúc của S3 Glacier, dịch vụ lưu trữ chi phí thấp, dài hạn, yêu cầu phải retrieve (truy xuất) dữ liệu (Expedited, Standard, Bulk) về S3 Bucket trước khi sử dụng. 29/09/2025 29/09/2025 Module 04 3 Snow Family\n- Học về các dịch vụ Snow Family (Snowball, Snowball Edge, Snowmobile) dùng để di dời (migrate) dữ liệu quy mô PetaByte (PB) đến Exabyte (EB) từ on-premise lên AWS (S3 hoặc Glacier).\n- Tìm hiểu về kĩ thuật của Snowball Edge là thiết bị đặc biệt có sẵn tài nguyên tính toán (compute) để xử lý dữ liệu local.\nAmazon Storage Gateway\n- Học về kiến trúc của AWS Storage Gateway, một giải pháp lưu trữ Hybrid kết hợp dung lượng lưu trữ trên AWS với on-premise.\n- Tìm hiểu về kĩ thuật của ba loại gateway:\n+ File Gateway: Cho phép lưu trữ file lên S3 qua giao thức NFS và SMB.\n+ Volume Gateway: Cung cấp lưu trữ dạng khối (block storage) qua iSCSI, dữ liệu được lưu trên S3.\n+ Tape Gateway: Cung cấp thư viện băng từ ảo (VTL) iSCSI, lưu dữ liệu tape ảo vào S3 hoặc Glacier. 30/09/2025 30/09/2025 Module 04 4 Disaster Recovery on AWS\n- Tìm hiểu về kĩ thuật\u0026hellip; thiết kế Disaster Recovery (DR) dựa trên hai chỉ số chính:\n+ RTO (Recovery Time Objective): Thời gian cần thiết để phục hồi dịch vụ.\n+ RPO (Recovery Point Objective): Khoảng thời gian tối đa mà dữ liệu có thể bị mất.\n- Học về 4 chiến lược DR trên AWS: Sao lưu và khôi phục, Pilot Light, Low Capacity Active-Active, và Full Capacity Active-Active.\nAWS Backup\n- Học về dịch vụ AWS Backup, một dịch vụ quản lý tập trung, cho phép cấu hình và lập lịch (schedule), chính sách lưu giữ (retention) cho việc sao lưu nhiều tài nguyên AWS (EBS, EC2, RDS, EFS, Storage Gateway\u0026hellip;). 01/10/2025 01/10/2025 Module 04 5 Lab: 000057 - Khởi đầu với Amazon S3\n- Tạo S3 Bucket\n- Upload dữ liệu trên S3\n- Host static website trên S3\nLab: 000013 - AWS Backup\n- Chuẩn bị hạ tầng\n- Khởi tạo Backup Plan\n- Thiết lập Notification\n- Kiểm tra hoạt động\nLab: 000014 - AWS Import/Export\n- Chuẩn bị máy ảo\n- Import máy ảo lên AWS\n- Export máy ảo từ AWS 02/10/2025 02/10/2025 Module 04 6 Lab: 000024 - Storage Gateway\n- Khởi tạo Storage Gateway\n- Khởi tạo File Sharing\n- Kết nối File Share với máy\nLab: 000025 - FSX\n- AWS Managed MS AD\n- Triển khai Instance\n- Thiết lập và sử dụng FSx\n[Nghiên cứu bổ sung] - AWS Skill Builder\n- Series các bài lý thuyết chuyên sâu cho chuyên gia lưu trữ trên AWS.\n- Storage Learning Plan: Block Storage\n- Storage Learning Plan: Object Storage 03/10/2025 03/10/2025 Module 04 Kết quả đạt được tuần 4: Dịch vụ S3 (Cơ bản): Hiểu rõ Amazon S3 là dịch vụ lưu trữ đối tượng (object storage), không phải lưu trữ khối, hoạt động theo mô hình WORM (Ghi 1 lần, đọc nhiều lần). Bài học về Độ bền (Durability): Nắm được S3 được thiết kế cho độ bền 11 số 9 (99.999999999%) bằng cách tự động nhân bản dữ liệu trên 3 Availability Zone (AZ). Kĩ thuật Tối ưu chi phí S3: Phân biệt được các lớp lưu trữ (Storage Classes) như S3 Standard (truy cập thường xuyên), S3 Standard IA (không thường xuyên), và S3 Glacier (lưu trữ dài hạn, chi phí thấp, phải retrieve). Kĩ thuật Tự động hóa S3: Biết cách dùng Object Life Cycle Management để tự động chuyển dữ liệu xuống các lớp rẻ hơn (ví dụ: từ Standard sang Glacier) theo thời gian. Hiểu về Trigger Event (ví dụ: kích hoạt serverless function khi upload file). Kĩ thuật Bảo mật S3: Phân biệt hai cơ chế kiểm soát truy cập: S3 ACL (cơ chế cũ) và S3 Bucket Policy (dễ dàng xác định quyền truy cập hơn). Bài học về Bảo vệ Dữ liệu (S3): Hiểu rõ tính năng Versioning (lập phiên bản) cho phép khôi phục lại các phiên bản cũ của file, giúp chống xóa nhầm hoặc tấn công ransomware. Kĩ thuật Mạng S3: Nắm được cách dùng S3 Endpoint để truy cập S3 từ trong VPC qua mạng riêng của AWS mà không cần Internet. Biết cách host Static Website trên S3 và cấu hình CORS. Dịch vụ Di dời Dữ liệu (Migration): Nhận biết dòng Snow Family (Snowball, Snowmobile) là giải pháp di dời dữ liệu vật lý quy mô lớn (Petabyte, Exabyte) từ on-premise. Dịch vụ Lưu trữ Hybrid: Hiểu Storage Gateway là giải pháp lưu trữ lai, cho phép các ứng dụng on-premise sử dụng các giao thức (NFS, SMB, iSCSI) để lưu trữ dữ liệu lên S3/Glacier. Bài học về Disaster Recovery (DR): Nắm được 2 khái niệm cơ bản để thiết kế DR là RTO (thời gian phục hồi) và RPO (lượng dữ liệu chấp nhận mất). Dịch vụ Sao lưu (Backup): Biết AWS Backup là dịch vụ quản lý tập trung, giúp tự động hóa việc sao lưu (schedule, retention) cho nhiều tài nguyên AWS (EBS, RDS, EFS\u0026hellip;). Thực hành: Nắm được các bước thực hành tạo S3 bucket, host website tĩnh, và cấu hình AWS Backup. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong suốt kỳ thực tập, em đã có cơ hội tham dự 6 sự kiện chuyên ngành khác nhau. Mỗi sự kiện không chỉ là một cơ hội quý báu để trau dồi những kiến thức mới mẻ và thiết thực, mà còn để lại những dấu ấn khó quên với những phần quà ý nghĩa cùng nhiều khoảnh khắc trải nghiệm tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Đại học FPT, Đường D1, Khu Công nghệ cao, Phường Tăng Nhơn Phú, TP. Hồ Chí Minh.\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #1\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.4-test-chatbox/",
	"title": "Kiểm thử Chatbot (RAG)",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Sau khi đã nhập dữ liệu thành công vào Vector Store, đã đến lúc xác minh kết quả. Trong phần này, bạn sẽ đóng vai trò là người dùng cuối, đặt câu hỏi cho Chatbot trực tiếp trong giao diện AWS Console để quan sát cách hệ thống RAG hoạt động.\nChúng ta sẽ tập trung vào 2 yếu tố:\nĐộ chính xác: AI có trả lời đúng dựa trên tài liệu không? Tính minh bạch: AI có thể trích dẫn nguồn (Citation) của thông tin không? Các Bước Thực hiện Bước 1: Cấu hình cửa sổ kiểm thử\nĐể bắt đầu trò chuyện, chúng ta cần chọn một Foundation Model sẽ đóng vai trò là \u0026ldquo;người trả lời\u0026rdquo;.\nTrong giao diện chi tiết Knowledge Base của bạn, hãy xem bảng điều khiển bên phải có tiêu đề Test knowledge base. Nhấp vào nút Select model.\nTrong bảng điều khiển lựa chọn xuất hiện: Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet / Haiku tùy thuộc vào model bạn đã kích hoạt). Throughput: Giữ nguyên On-demand. Nhấp Apply. Bước 2: Tiến hành hội thoại (Chat)\nBây giờ, hãy thử đặt một câu hỏi liên quan đến nội dung tài liệu bạn đã tải lên.\nTrong ô nhập liệu (Message input), gõ câu hỏi của bạn. Ví dụ: Nếu bạn đã tải lên tài liệu \u0026ldquo;Tổng quan về AWS\u0026rdquo;, hãy hỏi: \u0026ldquo;Bạn có thể giải thích cho tôi EC2 là gì không?\u0026rdquo;. Nhấp Run. Quan sát kết quả: AI sẽ suy nghĩ trong vài giây (truy vấn Vector Store). Sau đó, nó sẽ trả lời bằng ngôn ngữ tự nhiên, tóm tắt thông tin tìm được. Bước 3: Xác minh nguồn dữ liệu\nĐây là tính năng quan trọng nhất của RAG giúp phân biệt với ChatGPT thông thường: khả năng chứng minh nguồn thông tin.\nTrong câu trả lời của AI, hãy chú ý đến các số nhỏ (chú thích) hoặc văn bản Show source details. Nhấp vào các số đó hoặc nút chi tiết. Một cửa sổ Source details sẽ xuất hiện, hiển thị: Source chunk: Đoạn văn bản gốc chính xác mà AI tìm thấy trong tài liệu. Score: Điểm tương đồng (mức độ liên quan). S3 Location: Đường dẫn đến file gốc. Việc nhìn thấy đoạn văn bản gốc này chứng minh rằng AI không \u0026ldquo;ảo tưởng\u0026rdquo; mà đang thực sự đọc tài liệu của bạn.\nBước 4: Kiểm thử với câu hỏi không liên quan (Tùy chọn)\nĐể xem hệ thống phản ứng như thế nào khi không tìm thấy thông tin.\nĐặt một câu hỏi hoàn toàn không liên quan đến tài liệu. Ví dụ: \u0026ldquo;Hãy giải thích cho tôi một số kiến thức về tài chính cá nhân?\u0026rdquo; (Trong khi tài liệu của bạn là về Điện toán đám mây). Kết quả mong đợi: AI có thể trả lời dựa trên kiến thức tổng quát của nó (nếu không bị hạn chế). HOẶC AI sẽ trả lời \u0026ldquo;Xin lỗi, tôi không thể trả lời câu hỏi của bạn dựa trên dữ liệu truy xuất được\u0026rdquo; - Đây là hành vi lý tưởng cho một ứng dụng RAG doanh nghiệp. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch: “AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability” Mục Đích Của Sự Kiện Tái định hình tư duy (Mindset Transformation): Hiểu sâu sắc về Vòng đời Giá trị (Value Cycle) và cách văn hóa DevOps giúp doanh nghiệp cân bằng giữa tốc độ phát triển và sự ổn định của hệ thống. Cách mạng hóa hạ tầng (Modern Infrastructure): Chuyển đổi từ phương thức quản trị thủ công rủi ro (ClickOps) sang quản trị bằng mã nguồn (Infrastructure as Code - IaC) với bộ ba công cụ: CloudFormation, Terraform và CDK. Chiến lược Container hóa (Container Strategy): Phân tích kiến trúc và đưa ra quyết định lựa chọn nền tảng điều phối phù hợp nhất với nhu cầu: Từ đơn giản (App Runner), tích hợp sâu (ECS) đến mở rộng linh hoạt (EKS). Giám sát và Thấu hiểu (Deep Observability): Thiết lập hệ thống giám sát chủ động, không chỉ để báo lỗi mà còn để thấu hiểu hành vi hệ thống và tối ưu trải nghiệm người dùng bằng CloudWatch và X-Ray. Danh Sách Diễn Giả Đội ngũ chuyên gia AWS \u0026amp; Cloud Engineers: Mang đến góc nhìn kiến trúc tổng thể, chiến lược Platform Engineering và các bài demo thực chiến. Anh Trần Vĩ: FCJer 2024 - Chia sẻ kinh nghiệm thực tế từ cộng đồng. Anh Long Quy Nghiêm: FCJer 2024 - Chia sẻ góc nhìn từ người mới tiếp cận và phát triển kỹ năng Cloud. Nội Dung Chi Tiết 1. DevOps Mindset \u0026amp; CI/CD Pipeline (Nền Tảng Tư Duy) Sự kiện nhấn mạnh rằng DevOps không phải là một chức danh hay công cụ, mà là triết lý tập trung vào việc tối ưu hóa dòng chảy giá trị từ ý tưởng đến người dùng cuối.\nThe Value Cycle (Vòng Đời Giá Trị):\nLà một chu trình khép kín gồm 5 giai đoạn: Insights \u0026amp; Analysis (Phân tích nhu cầu) -\u0026gt; Portfolio \u0026amp; Backlog (Lập kế hoạch) -\u0026gt; Continuous Integration (Tích hợp) -\u0026gt; Continuous Testing (Kiểm thử) -\u0026gt; Continuous Delivery (Chuyển giao). Mục tiêu cốt lõi: Giải quyết bài toán kinh điển \u0026ldquo;Speed vs. Stability\u0026rdquo;. DevOps chứng minh rằng chúng ta có thể tăng tốc độ ra mắt tính năng mới (Speed) mà không cần đánh đổi sự an toàn của hệ thống (Stability) nhờ vào tự động hóa. Định nghĩa lại các khái niệm CI/CD:\nContinuous Integration (CI): Là văn hóa cam kết code thường xuyên (hàng ngày). Mọi thay đổi code đều kích hoạt quy trình Build và Test tự động nhằm phát hiện lỗi ngay lập tức (Fail fast), tránh tích tụ nợ kỹ thuật. Continuous Delivery (Chuyển giao liên tục): Code sau khi qua CI sẽ tự động được deploy lên môi trường Staging. Tuy nhiên, bước deploy ra Production là một quyết định kinh doanh, cần một cái \u0026ldquo;gật đầu\u0026rdquo; xác nhận từ con người (Manual Approval). Continuous Deployment (Triển khai liên tục): Mức độ tự động hóa cao nhất. Nếu code vượt qua mọi bài test, nó sẽ đi thẳng ra Production mà không có bất kỳ sự can thiệp nào của con người. Chiến lược Pipeline hiệu quả:\nCentralized CI: Đội ngũ Platform xây dựng các pipeline chuẩn, đảm bảo tính bảo mật và tuân thủ (Compliance), nhưng trao quyền cho Developer tự sử dụng (Self-service) để không tạo ra nút thắt cổ chai. Artifact Management (Quản lý thành phẩm): Tuân thủ nguyên tắc bất biến \u0026ldquo;Build Once, Deploy Anywhere\u0026rdquo;. Mã nguồn chỉ được đóng gói một lần duy nhất thành Binary/Docker Image (Artifact). Các môi trường Test, Staging hay Prod đều dùng chung Artifact này để đảm bảo những gì đã test chính là những gì sẽ chạy thật. Cơ chế phản hồi nhanh (Fail Fast): Pipeline phải được thiết kế để dừng ngay lập tức khi có vấn đề (Lỗi biên dịch, Code xấu, Lỗ hổng bảo mật, Test chậm). Thà dừng quy trình sớm còn hơn để lỗi lọt xuống các bước sau tốn kém hơn. Đo lường hiệu quả (Metrics):\nSử dụng Heatmap để trực quan hóa hiệu suất của toàn bộ tổ chức. Tập trung vào 4 chỉ số vàng (DORA Metrics): Tần suất triển khai, Thời gian thay đổi (Lead time), Tỷ lệ lỗi khi thay đổi (Change Failure Rate), và Thời gian khôi phục dịch vụ (MTTR). 2. Infrastructure as Code (IaC) - Từ ClickOps Đến Code Phần này phân tích sự dịch chuyển bắt buộc từ quản trị thủ công sang tự động hóa hạ tầng.\nVấn đề của \u0026ldquo;ClickOps\u0026rdquo;: Việc click chuột trên AWS Console tuy trực quan nhưng tiềm ẩn rủi ro lớn: Sai sót do con người (quên cấu hình), không thể tái tạo lại môi trường y hệt (Inconsistent), và cực kỳ khó khăn khi cần mở rộng quy mô. Giải pháp IaC: Biến hạ tầng thành Code để hưởng các lợi ích của phát triển phần mềm: Có Version Control (Git), có Code Review, có thể Test và Tái sử dụng. Phân tích chi tiết 3 công cụ IaC hàng đầu:\n1. AWS CloudFormation (Native Tool):\nCông cụ \u0026ldquo;chính chủ\u0026rdquo; của AWS, sử dụng YAML/JSON để khai báo trạng thái mong muốn (Declarative). Template Anatomy: Cấu trúc gồm Parameters (Đầu vào linh hoạt), Mappings (Ánh xạ giá trị theo vùng/môi trường), và Resources (Tài nguyên AWS cụ thể). Stack Management: Quản lý tài nguyên theo nhóm (Stack). Khi xóa Stack, mọi tài nguyên liên quan sẽ được dọn dẹp sạch sẽ, tránh rác tài nguyên. 2. Terraform (Multi-Cloud Powerhouse):\nCông cụ mã nguồn mở, sử dụng ngôn ngữ HCL. Là lựa chọn số 1 cho chiến lược Đa đám mây (Multi-cloud). Quy trình an toàn: Write -\u0026gt; Plan -\u0026gt; Apply. Bước Plan cho phép xem trước các thay đổi sẽ tác động thế nào đến hạ tầng thực tế trước khi áp dụng, giúp tránh các sai lầm tai hại. State File: Là \u0026ldquo;bộ nhớ\u0026rdquo; của Terraform, lưu giữ trạng thái thực của hạ tầng để so sánh và đồng bộ hóa. 3. AWS CDK (Cloud Development Kit):\nTiếp cận hạ tầng bằng ngôn ngữ lập trình hiện đại (Python, TS, Java\u0026hellip;), tận dụng được sức mạnh của vòng lặp, điều kiện, và hướng đối tượng. Sức mạnh của Abstraction (Constructs): L1: Cấu hình thô (tương đương CloudFormation). L2: Các Class có sẵn cấu hình mặc định an toàn (Best practices). L3: Các mẫu thiết kế (Patterns) dựng sẵn cả một hệ thống phức tạp (VPC + Cluster + LB) chỉ với vài dòng code. Drift Detection: Tính năng giúp phát hiện \u0026ldquo;sự trôi dạt\u0026rdquo; cấu hình - tức là sự khác biệt giữa Code (IaC) và thực tế (do ai đó sửa tay). Đây là công cụ quan trọng để duy trì kỷ luật vận hành.\n3. Containerization - Chiến Lược Chạy Ứng Dụng Đi sâu vào các mô hình điều phối (Orchestration) để chọn giải pháp tối ưu:\nKubernetes (K8s):\nHệ thống tiêu chuẩn của thế giới Container. Kiến trúc phức tạp gồm Control Plane (não bộ) và Worker Nodes (cơ bắp). Phù hợp cho các hệ thống cực lớn, cần tùy chỉnh sâu, nhưng đòi hỏi đội ngũ vận hành có kỹ năng cao. So sánh Amazon ECS vs. Amazon EKS:\nAmazon ECS: \u0026ldquo;Đơn giản hóa\u0026rdquo;. Được AWS thiết kế để tích hợp liền mạch với các dịch vụ khác (ALB, IAM). Phù hợp cho team muốn tập trung vào ứng dụng, bớt lo về vận hành cụm cluster. Amazon EKS: \u0026ldquo;Chuẩn mở\u0026rdquo;. Là phiên bản Managed Kubernetes của AWS. Phù hợp cho doanh nghiệp cần hệ sinh thái công cụ của K8s hoặc chạy Hybrid-cloud. Mô hình tính toán (Compute Options):\nEC2 Launch Type: Bạn quản lý máy ảo (Servers). Kiểm soát tối đa nhưng phải lo việc vá lỗi OS, update agent. AWS Fargate (Serverless): Bạn chỉ quản lý Container. AWS lo toàn bộ hạ tầng máy chủ bên dưới. Loại bỏ gánh nặng bảo trì OS. AWS App Runner:\nGiải pháp \u0026ldquo;Zero-ops\u0026rdquo;. Dành cho Developer muốn deploy Web App/API nhanh nhất có thể. Tự động hóa toàn bộ từ Source Code -\u0026gt; Build -\u0026gt; Deploy -\u0026gt; Load Balancer -\u0026gt; HTTPS URL. 4. Observability - Giám Sát \u0026amp; Tối Ưu Hóa Chuyển từ \u0026ldquo;Monitoring\u0026rdquo; (Hệ thống có sống không?) sang \u0026ldquo;Observability\u0026rdquo; (Tại sao hệ thống chạy chậm?).\nAmazon CloudWatch (Trung tâm giám sát):\nMetrics: Các chỉ số đo lường định lượng (CPU cao, RAM đầy). Logs: Nhật ký hoạt động chi tiết. Logs Insights giúp truy vấn và phân tích hàng triệu dòng log trong vài giây. Alarms: Cơ chế phản ứng tự động. Khi chỉ số vượt ngưỡng -\u0026gt; Gửi cảnh báo hoặc Tự động scale hệ thống. AWS X-Ray (Truy vết phân tán):\nGiải quyết bài toán \u0026ldquo;hộp đen\u0026rdquo; trong Microservices. Distributed Tracing: Vẽ lại bản đồ đường đi của một request qua hàng chục service khác nhau. Giúp xác định chính xác service nào đang gây chậm (Latency) hoặc gây lỗi (Error) để xử lý tận gốc. AWS Observability Best Practices:\nTham khảo AWS Observability Recipes để áp dụng các mẫu giám sát chuẩn. Phân biệt rõ vai trò: Logs cho biết chi tiết sự kiện, Traces cho biết ngữ cảnh và luồng đi của sự kiện đó. Trải nghiệm chi tiết trong Event Buổi chuyên đề đã giúp tôi thay đổi hoàn toàn cách nhìn nhận về việc vận hành hệ thống phần mềm:\n1. Sự chuyển dịch từ \u0026ldquo;Ops\u0026rdquo; sang \u0026ldquo;Platform Engineering\u0026rdquo; Tôi nhận ra vai trò của người làm DevOps hiện đại không phải là \u0026ldquo;người trực server\u0026rdquo; hay \u0026ldquo;người deploy thuê\u0026rdquo;. DevOps là người xây dựng nền tảng (Platform Builders). Nhiệm vụ là tạo ra một \u0026ldquo;đường cao tốc\u0026rdquo; (Pipeline \u0026amp; Infrastructure) an toàn và tự động, giúp Developer có thể tự mình đưa code ra thị trường (Self-service) mà không cần chờ đợi, nhưng vẫn đảm bảo các quy tắc an toàn.\n2. Kỷ luật trong vận hành (Operational Discipline) Khái niệm Immutability (Bất biến) trong quản lý Artifact và Drift Detection trong IaC thực sự đắt giá. Trong môi trường doanh nghiệp, \u0026ldquo;chạy được\u0026rdquo; là chưa đủ, mà phải là \u0026ldquo;chạy ổn định và nhất quán\u0026rdquo;. Việc cấm sửa tay (ClickOps) và tuân thủ quy trình \u0026ldquo;Code -\u0026gt; Build -\u0026gt; Deploy\u0026rdquo; là yếu tố sống còn để tránh những lỗi ngớ ngẩn do con người gây ra.\n3. Chiến lược lựa chọn công cụ thông minh Bài học lớn nhất là không có công cụ \u0026ldquo;xịn nhất\u0026rdquo;, chỉ có công cụ \u0026ldquo;phù hợp nhất với ngữ cảnh\u0026rdquo;:\nCần sự ổn định tuyệt đối và hỗ trợ tính năng AWS mới nhất? Chọn CloudFormation. Doanh nghiệp dùng nhiều Cloud (Multicloud)? Chọn Terraform. Team mạnh về lập trình, muốn viết ít code mà được hạ tầng lớn? Chọn AWS CDK. Muốn chạy Web App đơn giản mà không muốn tốn người quản trị K8s? App Runner là chân ái. Kết Luận Chuyên đề \u0026ldquo;DevOps \u0026amp; IaC Mastery\u0026rdquo; đã vẽ nên một lộ trình trưởng thành về công nghệ:\nVề Tư duy: Chuyển từ làm việc cảm tính, thủ công sang tư duy hệ thống, tự động hóa và đo lường bằng dữ liệu. Về Hạ tầng: Kiểm soát hạ tầng bằng Code (IaC) để đạt được sự linh hoạt và khả năng mở rộng vô hạn. Về Vận hành: Kết hợp sức mạnh của Container với khả năng thấu hiểu hệ thống (Observability) để đảm bảo dịch vụ luôn sẵn sàng và tối ưu. Đây chính là nền tảng kiến thức vững chắc để tôi tự tin bước vào xây dựng các hệ thống quy mô lớn trên AWS.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Tìm hiểu kiến thức nền tảng và các dịch vụ cốt lõi về bảo mật trên AWS, xoay quanh triết lý \u0026ldquo;Security is job zero\u0026rdquo;. Bắt đầu với khái niệm cơ bản nhất là Mô hình chia sẻ trách nhiệm (Share Responsibility Model). Tập trung sâu vào việc quản lý định danh và quyền truy cập (Identify and Access Management - IAM), bao gồm các thành phần: User, Group, Policy, và Role. Mở rộng tìm hiểu thêm các dịch vụ quản lý định danh ở quy mô lớn hơn như AWS Organizations (quản lý nhiều tài khoản), AWS Identity Center (SSO) (đăng nhập một lần), và Amazon Cognito (quản lý người dùng cho ứng dụng web/di động). Nắm rõ kiến thức về bảo vệ dữ liệu thông qua mã hóa với AWS KMS và giám sát, kiểm tra tuân thủ với AWS Security Hub. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Share Responsibility Model\n- Học về Mô hình chia sẻ trách nhiệm, trong đó AWS chịu trách nhiệm bảo mật của đám mây (hạ tầng vật lý, software nền tảng) và khách hàng chịu trách nhiệm bảo mật trong đám mây (cấu hình, dữ liệu, ứng dụng).\n- Tìm hiểu về sự thay đổi trách nhiệm bảo mật tùy thuộc vào loại hình dịch vụ (hạ tầng, quản lý kết hợp, hay quản lý hoàn toàn).\nAWS Identify and Access Management (IAM)\n- Tìm hiểu về Root Account, tài khoản có toàn quyền tuyệt đối, và các best practice để bảo vệ nó (tạo IAM Admin User để dùng thay thế, khóa root credentials).\n- Học về IAM User, một thực thể (principal) dùng để tương tác với AWS, khi mới tạo mặc định không có bất cứ quyền gì.\n- Tìm hiểu về kĩ thuật quản lý user hiệu quả bằng cách gom nhiều IAM User vào chung một IAM Group.\n- Học về IAM Policy, một văn bản JSON định nghĩa quyền hạn, bao gồm 2 loại:\n+ Identity-based Policy: Gán trực tiếp cho một IAM Principal (User, Group, Role).\n+ Resource-based Policy: Gán trực tiếp vào một tài nguyên (ví dụ: S3 Bucket Policy).\n- Tìm hiểu về kĩ thuật đánh giá quyền của IAM, trong đó một Deny tường minh (explicit deny) luôn luôn được ưu tiên, bất kể có policy Allow nào khác.\n- Học về kiến trúc của IAM Role, một tập hợp quyền (policy) mà không đi kèm credentials (mật khẩu/access key) vĩnh viễn.\n- Tìm hiểu về kĩ thuật Assume Role: Một IAM User (hoặc Service) sử dụng dịch vụ AWS STS (Security Token Service) để tạm thời \u0026ldquo;đảm nhận\u0026rdquo; quyền của IAM Role và nhận về thông tin chứng thực tạm thời.\n- Tìm hiểu về ứng dụng thực tế của IAM Role, ví dụ cấp quyền cho dịch vụ EC2 truy cập vào S3 mà không cần lưu trữ access key trên máy chủ. 06/10/2025 06/10/2025 Module 05 3 Amazon Cognito\n- Học về Amazon Cognito, dịch vụ quản lý xác thực (đăng nhập, đăng ký) và cấp phép cho người dùng cuối của các ứng dụng web và di động (khác với IAM User là người quản trị AWS).\n- Tìm hiểu về hai thành phần chính của Cognito:\n+ User Pool: Thư mục quản lý người dùng, hỗ trợ đăng nhập trực tiếp hoặc qua các bên thứ ba (Facebook, Google).\n+ Identity Pool: Cấp cho người dùng ứng dụng quyền truy cập (thường là tạm thời) vào các dịch vụ AWS khác.\nAWS Organization\n- Học về AWS Organizations, dịch vụ giúp quản lý và điều hành tập trung nhiều tài khoản AWS.\n- Tìm hiểu về kĩ thuật Consolidated Billing (thanh toán tập trung) cho tất cả tài khoản.\n- Tìm hiểu về kĩ thuật gom các tài khoản vào OU (Organization Unit) và áp dụng Service Control Policies (SCP) để giới hạn quyền tối đa mà các IAM User/Role trong tài khoản đó có thể thực hiện (kể cả deny-based).\nAWS Identify Center (SSO)\n- Học về AWS Identity Center (SSO), dịch vụ giúp quản lý quyền truy cập tập trung (đăng nhập một lần) vào tất cả các tài khoản AWS trong Organization và các ứng dụng bên ngoài.\n- Tìm hiểu về kĩ thuật sử dụng Permission Set (một bộ quyền được lưu trữ trong Identity Center) để gán cho User/Group. Khi user truy cập 1 tài khoản, Permission Set sẽ được cấp dưới dạng một IAM Role trong tài khoản đó. 07/10/2025 07/10/2025 Module 05 4 AWS Key Management Service (KMS)\n- Học về AWS KMS, dịch vụ tạo và quản lý các khóa mã hóa (encryption key) để bảo vệ dữ liệu ở trạng thái nghỉ (Encryption at rest).\n- Tìm hiểu về\u0026hellip; CMK (Customer Managed Key) (khóa chính nằm trong KMS) và Data Key (khóa dùng để mã hóa/giải mã dữ liệu thực tế, được tạo ra bởi CMK).\nAWS Security Hub\n- Học về AWS Security Hub, dịch vụ kiểm tra bảo mật liên tục, dựa trên các best practices của AWS và tiêu chuẩn ngành (như PCIDSS).\n- Tìm hiểu về cách Security Hub cung cấp kết quả dưới dạng điểm số và xác định các tài nguyên cần chú ý.\nLab: 000002 - Bắt đầu với IAM và IAM Role\n- IAM Group và IAM User\n- Tạo IAM Role\n- Assume Role\nLab: 000044 - IAM Role và Condition\n- Giới thiệu về IAM\n- Tạo User quản trị EC2\n- Tạo User quản trị RDS\n- Tạo Group quản trị-Cấu hình IAM Role Condition\n- Tạo IAM Role có quyền Admin 5.2 Tạo IAM User 5.3 Cấu hình Switch role 5.4 Giới hạn IP 5.5 Giới hạn theo thời gian.\n08/10/2025 08/10/2025 Module 05 5 Lab: 000048 - IAM Role và Application\n- Sử dụng access key\n- IAM Role trên EC2\nLab: 000030 - IAM Permission Boundary\n- Giới thiệu IAM Permission Boundary\n- Tạo Policy giới hạn\n- Tạo IAM User giới hạn quyền\n- Kiểm tra User bị giới hạn\nLab: 000027 - Tag và Resource Groups\n- Sử dụng thẻ\n- Sử dụng thẻ bằng Console\n- Hiển thị các thẻ\n- Thêm hoặc xóa thẻ\n- Gắn thẻ cho một máy ảo\n- Lọc tài nguyên theo thẻ\n- Sử dụng thẻ bằng CLI\n- Resource Group\nLab: 000028 - Quản lý EC2 qua Resource Tag\n- Tạo IAM Policy\n- Tạo IAM Role\n- Kiểm tra IAM Role 09/10/2025 09/10/2025 Module 05 6 Lab: 000018 - Sử dụng AWS Security Hub\n- Các tiêu chuẩn bảo mật\n- Kích hoạt Security HUb\n- Điểm từng bộ tiêu chuẩn\nLab: 000012 - Sử dụng AWS SSO\n- Các bước chuẩn bị\n- Tạo AWS Account trong AWS Organizations\n- Thiết lập Organization Unit\n- Thiết lập AWS SSO\n- Kiểm tra\nLab: 000033 - KMS Workshop\n- Thiết lập môi trường\n- Bắt đầu với AWS KMS\n- Mã hóa với AWS KMS\n- Key Policy và các best practices\n- Giám sát việc sử dụng AWS KMS.\n[Nghiên cứu bổ sung] - AWS Certified Security Special All-in-One-Exam Guide (Exam SCS-C01)\n- Tài liệu học để thi chúng chỉ Security Specialty 10/10/2025 10/10/2025 Module 05\nResearch Link Kết quả đạt được tuần 5: Bài học Nền tảng: Nắm vững Mô hình chia sẻ trách nhiệm (Share Responsibility Model), hiểu rõ đâu là trách nhiệm của AWS và đâu là của khách hàng. Dịch vụ IAM (Cốt lõi): Phân biệt rõ ràng Root Account (toàn quyền, cần khóa lại) và IAM User (dùng hàng ngày, mặc định không có quyền). Nắm vững 3 thành phần chính để cấp quyền: IAM User (đối tượng), IAM Policy (giấy phép - viết bằng JSON), và IAM Group (nhóm các đối tượng). Hiểu rõ IAM Role: một cơ chế cấp quyền tạm thời (không có credentials vĩnh viễn) cho cả User và Service (như EC2). Kĩ thuật IAM (Quan trọng): Biết cách một User/Service \u0026ldquo;nhận\u0026rdquo; quyền của Role thông qua kĩ thuật Assume Role (sử dụng dịch vụ STS). Hiểu quy tắc đánh giá quyền: Explicit Deny (Deny tường minh) luôn thắng mọi quyền Allow. Dịch vụ Quản lý Định danh (Identity Services): Phân biệt rõ IAM (quản lý người quản trị AWS) và Amazon Cognito (quản lý người dùng cuối của ứng dụng web/mobile). Biết Cognito User Pool là thư mục người dùng (có thể login bằng Facebook, Google) và Identity Pool là nơi cấp quyền cho user đó truy cập tài nguyên AWS. Dịch vụ Quản lý Đa tài khoản (Multi-Account): Hiểu AWS Organizations dùng để quản lý tập trung nhiều tài khoản, cho phép Consolidated Billing (thanh toán gộp). Biết dùng Service Control Policies (SCP) trong Organization để giới hạn quyền tối đa của các tài khoản con. Nắm được AWS Identity Center (SSO) là giải pháp đăng nhập một lần, sử dụng Permission Set để cấp quyền vào các tài khoản trong Organization. Dịch vụ Mã hóa (Encryption): Biết AWS KMS là dịch vụ để tạo và quản lý khóa mã hóa. Hiểu cơ chế mã hóa Encryption at rest và phân biệt được CMK (khóa chính trong KMS) với Data Key (khóa dùng để mã hóa dữ liệu thực tế). Dịch vụ Giám sát Bảo mật (Monitoring): Biết AWS Security Hub là dịch vụ quét và chấm điểm bảo mật, giúp kiểm tra tuân thủ (compliance) theo các tiêu chuẩn (như PCIDSS). Thực hành: Thực hành tạo và quản lý User, Group, Policy, Role. Thực hành triển khai SSO và KMS. Thực hành sử dụng các tính năng nâng cao của IAM như Conditions và Permission Boundary. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.5-client-integration/",
	"title": "Tích hợp ứng dụng Client (Tùy chọn)",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Bạn sẽ biến dòng code Python thành một Giao diện Web Chatbot (GUI) chuyên nghiệp, thân thiện với người dùng cuối (tương tự như giao diện ChatGPT) chỉ trong vài phút.\nChúng ta sử dụng:\nBackend: Python. Frontend: Streamlit. AI Model: Claude 3.5 Sonnet. Các Bước Thực hiện Phần I: Cấu hình AWS Credentials\nBước 1: Cài đặt AWS CLI\nMở Terminal trên máy tính của bạn.\n# macOS brew install awscli # Linux curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Bước 2: Cấu hình credentials\naws configure Nhập thông tin khi được hỏi:\nAWS Access Key ID: YOUR_ACCESS_KEY AWS Secret Access Key: YOUR_SECRET_KEY Default region name: us-east-1 Default output format: json Bước 3: Kiểm tra cấu hình\n# Kiểm tra credentials aws sts get-caller-identity # Kiểm tra kết nối Bedrock aws bedrock-agent-runtime list-knowledge-bases --region ap-southeast-1 Lưu ý bảo mật:\nKHÔNG commit credentials vào Git KHÔNG share credentials với người khác Sử dụng IAM roles khi có thể Rotate credentials định kỳ Permissions cần thiết:\nIAM User cần có các quyền sau:\nbedrock:InvokeModel bedrock:RetrieveAndGenerate bedrock:Retrieve s3:GetObject (cho Knowledge Base) Troubleshooting:\nLỗi \u0026ldquo;Unable to locate credentials\u0026rdquo;:\nKiểm tra file ~/.aws/credentials tồn tại Kiểm tra format file đúng Thử chạy aws configure lại Lỗi \u0026ldquo;AccessDeniedException\u0026rdquo;:\nKiểm tra IAM permissions Đảm bảo region đúng (ap-southeast-1) Kiểm tra Knowledge Base ID đúng Lỗi \u0026ldquo;ExpiredToken\u0026rdquo;:\nCredentials đã hết hạn Cần tạo credentials mới từ AWS Console Phần II: Clone Project từ GitHub đã tạo sẵn\nBước 1: Truy cập vào link GitHub sau\nBạn hãy tải về và mở folder trên bằng Visual Studio Code:\nhttps://github.com/DazielNguyen/chatbot_with_bedrock.git\nBước 2: Tải các thư viện và môi trường Python\nTải môi trường:\nMacOS: python3 -m venv .venv Win: python -m venv .venv Kích hoạt môi trường:\nMacOS: source .venv/bin/activate Win: .venv\\Scripts\\activate Tải thư viện:\nMacOS/ Win: pip install -r requirements.txt Bước 3: Lấy ID của Knowledge Base đã tạo\nTruy cập Amazon Bedrock -\u0026gt; Knowledge Base -\u0026gt; knowledge-base-demo Cập nhật \u0026ldquo;KB_ID=\u0026ldquo;YOUR_KNOWLEDGE_BASE_ID\u0026rdquo;\u0026rdquo; Bước 4: Chạy Streamlit - UI của Chatbot và Trải nghiệm\nRun Terminal: streamlit run start.py Khi chạy xong lệnh sẽ xuất hiện trang sau: Hãy thử hỏi một số câu hỏi bạn đã upload lên Knowledge Base trước đó. Kết quả Chabot đã trả về kết quả dựa trên file dữ liệu mà bạn đã cung cấp, có trích nguồn của dữ liệu của bạn. Kết luận Chúc mừng bạn đã xây dựng thành công một Web Chatbot được xây dựng từ Amazon Bedrock\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Xây dựng ứng dụng RAG sử dụng Knowledge Bases cho Amazon Bedrock Tổng quan Knowledge Bases for Amazon Bedrock là một tính năng được quản lý hoàn toàn giúp bạn triển khai kỹ thuật RAG (Retrieval-Augmented Generation) bằng cách kết nối các Foundation Models với nguồn dữ liệu nội bộ của bạn để cung cấp các phản hồi chính xác, có trích dẫn và phù hợp với ngữ cảnh.\nRAG là một kỹ thuật để tối ưu hóa đầu ra của Large Language Model (LLM) bằng cách truy xuất thông tin từ cơ sở dữ liệu bên ngoài đáng tin cậy (Retrieval) và thêm nó vào ngữ cảnh (Augmentation) trước khi tạo ra câu trả lời (Generation). Phương pháp này giúp khắc phục những hạn chế về dữ liệu huấn luyện lỗi thời và đảm bảo AI trả lời dựa trên thông tin thực tế được cung cấp.\nTrong bài lab này, chúng ta sẽ học cách xây dựng một trợ lý AI có khả năng \u0026ldquo;đọc và hiểu\u0026rdquo; các tài liệu doanh nghiệp độc quyền. Bạn sẽ thực hiện quy trình từ việc nhập dữ liệu và tạo chỉ mục vector đến cấu hình mô hình để trả lời câu hỏi dựa trên những tài liệu đó mà không cần quản lý bất kỳ máy chủ nào.\nChúng ta sẽ sử dụng ba thành phần chính để thiết lập quy trình xử lý RAG hoàn chỉnh:\nNguồn dữ liệu (Amazon S3) - Đóng vai trò là kho lưu trữ \u0026ldquo;sự thật\u0026rdquo;. Bạn sẽ tải các tài liệu (PDF, Word, Text) lên một S3 bucket. Knowledge Base sẽ sử dụng nguồn này để đồng bộ hóa dữ liệu. Vector Store (OpenSearch Serverless) - Nơi lưu trữ các embeddings vector (dữ liệu được mã hóa bằng số). Khi người dùng đặt câu hỏi, hệ thống sẽ thực hiện tìm kiếm ngữ nghĩa tại đây để trích xuất các đoạn văn bản liên quan nhất thay vì tìm kiếm từ khóa tiêu chuẩn. Foundation Model (Claude 3) - Large Language Model đóng vai trò là bộ não xử lý. Nó nhận câu hỏi của người dùng cùng với thông tin tìm thấy từ Vector Store, sau đó tổng hợp và tạo ra câu trả lời tự nhiên, chính xác kèm theo trích dẫn nguồn. Kết quả đạt được Khi kết thúc workshop, bạn sẽ có một hệ thống Chatbot thực tế, hoạt động với các tính năng sau:\nTrò chuyện hỏi đáp về nội dung tài liệu độc quyền. Câu trả lời chính xác, không có ảo giác (hallucinations). Trích dẫn nguồn (biết chính xác câu trả lời đến từ trang nào). Triển khai nhanh chóng mà không cần viết mã xử lý dữ liệu phức tạp. Nội dung Tổng quan về Workshop Chuẩn bị môi trường Tạo và cấu hình Knowledge Base Kiểm tra Chatbot (RAG) Tích hợp ứng dụng Client (Tùy chọn) Cập nhật dữ liệu Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.6-event6/",
	"title": "Event 6",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch: “AWS Cloud Mastery Series #3” Mục Đích Của Chuỗi Chuyên Đề Sự kiện không dừng lại ở việc hướng dẫn sử dụng công cụ, mà tập trung vào việc hình thành Tư duy Hệ thống (System Thinking). Mục tiêu là giúp người tham dự chuyển đổi từ tư duy bảo mật thụ động sang mô hình Cloud-Native Security chủ động và toàn diện:\nXây dựng cộng đồng (Community): Tạo môi trường kết nối bền vững, lan tỏa tri thức thông qua mạng lưới AWS Cloud Clubs. Quản trị định hướng (Governance): Thiết lập nền tảng quản lý cho tổ chức quy mô lớn (hàng trăm tài khoản) đảm bảo sự đồng bộ và tuân thủ tuyệt đối. Phòng thủ chiều sâu (Defense in Depth): Chiến lược bảo mật đa lớp (Identity - Network - Data), đảm bảo nếu một lớp bị xuyên thủng, hệ thống vẫn an toàn. Phản ứng tự động (Automated Response): Chuyển từ việc xử lý sự cố thủ công (tốn thời gian) sang các quy trình tự động hóa (tức thì) để giảm thiểu thiệt hại. Danh Sách Diễn Giả Chương trình quy tụ đội ngũ chuyên gia dày dặn kinh nghiệm, là những gương mặt tiêu biểu trong cộng đồng kỹ thuật AWS tại Việt Nam:\nĐại diện AWS Cloud Clubs: Các thủ lĩnh (Captains) đến từ các trường đại học lớn: HCMUTE, SGU, PTIT, HUFLIT (Lê Vũ Xuân An, Trần Đức Anh, Trần Đoàn Công Lý, Danh Hoàng Hiếu Nghị). Chuyên gia Identity \u0026amp; Governance: Anh Huỳnh Hoàng Long, Đinh Lê Hoàng Anh (AWS Community Builders) - Chia sẻ về quản lý định danh. Chuyên gia Detection \u0026amp; Monitoring: Anh Trần Đức Anh, Nguyễn Tuấn Thịnh, Nguyễn Đỗ Thành Đạt - Tập trung vào giám sát và phát hiện mối đe dọa. Chuyên gia Network Security: Anh Kha Văn (Cloud Security Engineer | AWS Community Builder) - Chuyên sâu về an ninh mạng lưới. Chuyên gia Data Protection: Anh Thịnh Lâm, Việt Nguyễn - Chia sẻ chiến lược bảo vệ dữ liệu. Chuyên gia Incident Response: Anh Mendel Grabski (Long) - cựu Head of Security \u0026amp; DevOps, và anh Tinh Truong - Platform Engineer - Chia sẻ kinh nghiệm ứng phó sự cố thực chiến. Nội Dung Chi Tiết PHẦN 1: KHỞI ĐỘNG - AWS CLOUD CLUBS \u0026amp; CƠ HỘI PHÁT TRIỂN Phần mở đầu giới thiệu về hệ sinh thái AWS Cloud Clubs - bệ phóng cho nhân lực Cloud tương lai.\n1. Tầm nhìn (Vision):\nKhông chỉ là nơi học tập, đây là môi trường để sinh viên thực hành vai trò lãnh đạo và kết nối với mạng lưới nhân sự Cloud toàn cầu. 2. Lợi ích cốt lõi (Benefits):\nBuild Skills: Học đi đôi với hành qua các dự án thực tế, tài trợ chi phí thi chứng chỉ và tài khoản học tập chuyên sâu. Build Community: Rút ngắn khoảng cách giữa sinh viên và chuyên gia đầu ngành. Build Opportunities: Cơ hội làm đẹp CV, nhận tài trợ AWS Credits để thử nghiệm ý tưởng và kết nối việc làm. 3. The Badging Journey:\nLộ trình thăng tiến được thiết kế dạng Game hóa (Gamification) để thúc đẩy động lực. Các cấp bậc danh hiệu: Bronze \u0026gt; Silver \u0026gt; Gold \u0026gt; Platinum \u0026gt; Diamond. Giá trị nhận được: Không chỉ là swag (quà tặng) hay Credits ($200+), mà là sự công nhận năng lực để ưu tiên tham gia các sự kiện lớn như Student Community Day. PHẦN 2: NỀN TẢNG ĐỊNH DANH VÀ QUẢN TRỊ (IDENTITY \u0026amp; GOVERNANCE) Khẳng định nguyên lý: Trên Cloud, biên giới mạng không còn là tường lửa duy nhất, mà chính là Định danh (Identity).\n1. Tư duy IAM hiện đại:\nIdentity First: Coi định danh là tuyến phòng thủ đầu tiên và quan trọng nhất. Credential Spectrum (Phổ thông tin xác thực): Loại bỏ thói quen dùng Long-term Credentials (Access Key cố định - rủi ro lộ lọt cao) và chuyển sang Short-term Credentials (STS tokens - tự động hết hạn sau phiên làm việc). Least Privilege (Quyền tối thiểu): Nguyên tắc \u0026ldquo;chỉ cấp những gì thực sự cần\u0026rdquo;. Tuyệt đối tránh thói quen cấp quyền admin (*) cho tiện, vì đây là lỗ hổng chết người. 2. Quản trị quy mô lớn với AWS Organizations:\nKiến trúc phân tầng: Tổ chức tài khoản theo chức năng (OUs) như Security (chứa log, audit), Shared Services (hạ tầng chung), Workloads (chạy ứng dụng) để cô lập rủi ro. Nếu một OU bị tấn công, các OU khác vẫn an toàn. Service Control Policies (SCPs): Được ví như \u0026ldquo;Hiến pháp\u0026rdquo; của hệ thống. SCP tạo ra các vành đai bảo vệ cứng (Guardrails) - ví dụ: cấm user xóa log CloudTrail, cấm tạo server ở region lạ - mà ngay cả tài khoản Root của từng account con cũng không thể vi phạm. PHẦN 3: KHẢ NĂNG QUAN SÁT VÀ PHÁT HIỆN (VISIBILITY \u0026amp; DETECTION) Chiến lược: \u0026ldquo;Bạn không thể bảo vệ những gì bạn không nhìn thấy\u0026rdquo;.\n1. Amazon GuardDuty - Trinh sát thông minh:\nHệ thống phát hiện xâm nhập thông minh sử dụng AI/ML để phân tích 3 luồng dữ liệu gốc: CloudTrail (Ai làm gì?), VPC Flow Logs (Traffic đi đâu?), và DNS Logs (Truy cập web nào?). Runtime Monitoring: Tính năng nâng cao, cài agent nhẹ vào máy chủ để giám sát sâu bên trong hệ điều hành (OS Level), phát hiện các tiến trình lạ (malware processes) hoặc hành vi leo thang đặc quyền mà log mạng bên ngoài không thấy được. 2. AWS Security Hub - Trung tâm chỉ huy:\nGiải quyết vấn đề phân mảnh thông tin bằng chuẩn ASFF (AWS Security Finding Format). Mọi cảnh báo từ GuardDuty, Inspector, Macie đều được quy về một định dạng chung. Đóng vai trò CSPM (Cloud Security Posture Management): Tự động rà soát hệ thống 24/7 để chấm điểm tuân thủ theo các tiêu chuẩn quốc tế (CIS, PCI-DSS) và báo cáo các cấu hình sai lệch. PHẦN 4: BẢO MẬT MẠNG LƯỚI (NETWORK SECURITY) Xây dựng \u0026ldquo;Pháo đài số\u0026rdquo; với tư duy Zero Trust (Không tin ai cả, kể cả mạng nội bộ).\n1. Kiểm soát cơ bản (VPC Fundamentals):\nSecurity Groups (Stateful): Áp dụng Micro-segmentation. Thay vì whitelist IP (vốn hay thay đổi trên Cloud), ta dùng cơ chế Reference ID (Server App chỉ được nhận traffic từ Server Web). Vì là Stateful, nó tự động cho phép traffic phản hồi đi ra. NACLs (Stateless): Lớp bảo vệ thô ở cấp độ Subnet. Dùng để chặn cứng (Deny) các dải IP đen hoặc các subnet không tin cậy. 2. Phòng thủ nâng cao (Advanced Filtering):\nDNS Firewall (Route 53 Resolver): Ngăn chặn malware kết nối về máy chủ điều khiển (C2) của hacker. Ngay cả khi máy bị nhiễm, nó cũng không thể \u0026ldquo;gọi điện về nhà\u0026rdquo; để nhận lệnh. AWS Network Firewall: Tường lửa thế hệ mới với khả năng kiểm tra sâu gói tin (Deep Packet Inspection): Stateless Engine: Xử lý cực nhanh dựa trên IP/Port. Stateful Engine: Sử dụng bộ luật Suricata (Open Source IPS) để phân tích nội dung gói tin, chặn các cuộc tấn công phức tạp hoặc lọc tên miền (FQDN) cho traffic đi ra Internet. 3. Kiến trúc mạng hiện đại:\nSử dụng AWS Transit Gateway để đơn giản hóa việc kết nối nhiều VPC, tích hợp sẵn Network Firewall để kiểm tra traffic tập trung (Centralized Inspection). Active Threat Defense: Tự động hóa quy trình phòng thủ: GuardDuty phát hiện IP độc hại -\u0026gt; Tự động cập nhật luật cho Network Firewall để chặn IP đó trên toàn hệ thống. PHẦN 5: BẢO VỆ DỮ LIỆU (DATA PROTECTION) Bảo vệ tài sản cốt lõi bằng các lớp mã hóa thông minh.\n1. Mã hóa bao thư (Envelope Encryption):\nCơ chế tối ưu hiệu năng của AWS KMS: Thay vì dùng khóa chính để mã hóa cục dữ liệu lớn (rất chậm), KMS dùng khóa chính (Master Key) để mã hóa một khóa dữ liệu nhỏ (Data Key). Khóa dữ liệu này mới dùng để mã hóa file. Vừa an toàn, vừa nhanh. 2. Quản lý bí mật (Secrets Management):\nVấn đề: Hardcode user/pass DB trong code là tử huyệt bảo mật. Giải pháp: Dùng AWS Secrets Manager. Điểm mạnh nhất không chỉ là lưu trữ, mà là khả năng Automatic Rotation. Nó tự động đổi pass DB định kỳ và cập nhật cho ứng dụng, khiến hacker dù có trộm được pass cũ cũng vô dụng. 3. Hạ tầng mã hóa phần cứng:\nAWS Nitro System: Các tác vụ mã hóa/giải mã nặng nhọc được chuyển xuống chip phần cứng chuyên biệt (Nitro Cards). Điều này đảm bảo Server được mã hóa toàn diện nhưng không hề bị chậm đi (Zero Performance Impact). PHẦN 6: ỨNG PHÓ SỰ CỐ (INCIDENT RESPONSE) Khi phòng thủ thất bại, tốc độ phản ứng là yếu tố sinh tồn.\n1. Chiến lược phòng ngừa (Prevention - Sleep Better):\nNguyên tắc: \u0026ldquo;Phòng bệnh hơn chữa bệnh\u0026rdquo;. Loại bỏ SSH key vĩnh viễn, chặn S3 Public Access ở mức Account, dùng Private Subnet mặc định. Infrastructure as Code (IaC): Bảo mật bắt đầu từ Code. Dùng Terraform/CDK giúp kiểm soát thay đổi, review được cấu hình trước khi deploy, loại bỏ hoàn toàn lỗi cấu hình do sửa tay (ClickOps). 2. Quy trình 5 bước chuẩn mực:\nChuẩn bị (Preparation): \u0026ldquo;Thao trường đổ mồ hôi, chiến trường bớt đổ máu\u0026rdquo;. Phải có sẵn công cụ, log và kịch bản (Playbook). Phát hiện (Detection): Dựa vào tín hiệu từ CloudTrail, GuardDuty. Cô lập (Containment): Bước quan trọng nhất để ngăn lây lan. Ví dụ: Dùng Lambda tự động gắn Security Group \u0026ldquo;cách ly\u0026rdquo; vào EC2 bị nhiễm. Diệt trừ \u0026amp; Phục hồi (Eradication \u0026amp; Recovery): Xóa bỏ nguyên nhân, khôi phục từ bản backup sạch gần nhất. Hậu sự cố (Post-Incident): Phân tích nguyên nhân gốc rễ (RCA) để cải tiến quy trình. 3. Tự động hóa (Automation is King):\nHacker dùng tool tự động, ta không thể chống lại bằng tay. Sử dụng EventBridge bắt sự kiện rủi ro và kích hoạt Lambda để xử lý ngay lập tức (ví dụ: tự động đóng S3 bucket bị public trong tích tắc). Kết Luận Chuỗi chuyên đề \u0026ldquo;Cloud Security \u0026amp; Operations Mastery\u0026rdquo; là cẩm nang toàn diện để kiến tạo một hệ thống Cloud vững chắc:\nIdentity \u0026amp; Governance: Là nền móng. Quản lý chặt ai được vào nhà và họ được làm gì. Network \u0026amp; Detection: Là hệ thống báo động và tường rào. Quan sát mọi ngóc ngách và phát hiện kẻ gian ngay khi chúng xuất hiện. Data \u0026amp; Response: Là két sắt và đội bảo vệ. Mã hóa dữ liệu nhiều lớp và sẵn sàng phản ứng tự động để dập tắt nguy cơ ngay lập tức. Một số hình ảnh khi tham gia sự kiện Hình ảnh hơn 400 bạn tham dự buổi Event AWS Cloud Mastery Series #3\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Ôn tập các khái niệm cơ sở dữ liệu (CSDL) nền tảng, bao gồm RDBMS (khóa chính, khóa ngoại), các kỹ thuật tối ưu (Index, Partition), và các khái niệm về vận hành (Database Log, Buffer). Phân biệt rõ hai loại hệ thống CSDL chính: OLTP (Online Transaction Processing - xử lý giao dịch) và OLAP (Online Analytical Processing - xử lý phân tích hay Kho dữ liệu). Hiểu rõ dịch vụ CSDL quan hệ được quản lý Amazon RDS, bao gồm các tính năng cốt lõi như Multi-AZ (cho tính sẵn sàng cao) và Read Replicas (cho hiệu năng đọc). Tìm hiểu về Amazon Aurora, dịch vụ CSDL cloud-native của AWS, với kiến trúc lưu trữ chia sẻ độc đáo, hiệu năng cao và các tính năng vượt trội như Zero Replication Lag. Tìm hiểu về Amazon Redshift, dịch vụ kho dữ liệu (Data Warehouse) quy mô petabyte, được thiết kế cho OLAP, và hiểu rõ kiến trúc MPP cùng kỹ thuật Columnar Storage. Hiểu về vai trò của Amazon ElastiCache (Redis, Memcached) như một lớp bộ nhớ đệm (caching) tốc độ cao để giảm tải cho CSDL chính. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Database Concepts\n- Bài học: Ôn tập các khái niệm CSDL căn bản như Database (hệ thống thông tin có cấu trúc) và Session (phiên làm việc).\n- Học về kiến trúc: CSDL Quan hệ (RDBMS), bao gồm Primary Key (Khóa chính) để xác định duy nhất một hàng và Foreign Key (Khóa ngoại) để tạo liên kết giữa các bảng.\n- Tìm hiểu về kĩ thuật: Normalization (Chuẩn hóa), là kỹ thuật chia dữ liệu ra nhiều bảng (sử dụng khóa) để chống trùng lặp dữ liệu.\n- Tìm hiểu về kĩ thuật: Tối ưu hiệu năng:\n+ Index (Chỉ mục): Một cấu trúc dữ liệu giúp tăng tốc độ truy xuất (đọc), nhưng làm tăng chi phí ghi.\n+ Partition (Phân vùng): Chia một bảng lớn thành nhiều phần nhỏ để tăng tốc độ truy vấn.\n+ Execution Plan (Kế hoạch thực thi): Là tập hợp các bước mà CSDL quyết định dùng để truy cập dữ liệu (ví dụ: có dùng Index hay không).\n- Tìm hiểu về kĩ thuật: Đảm bảo toàn vẹn và tốc độ:\n+ Database Log (Nhật ký CSDL): Ghi lại tất cả thay đổi, quan trọng cho việc khôi phục (recovery) và đồng bộ hóa (replication).\n+ Buffer (Bộ nhớ đệm): Vùng lưu trữ tạm thời trong RAM, giúp tăng tốc độ đọc vì đọc từ RAM nhanh hơn đọc từ ổ cứng.\n- Bài học: Phân loại CSDL:\n+ RDBMS (ACID): Cấu trúc cố định (Schema), tối ưu lưu trữ (Normalization), mở rộng theo chiều dọc (Vertical Scaling).\n+ NoSQL (BASE): Cấu trúc linh hoạt (Dynamic Schema), tối ưu hiệu năng (Denormalization), mở rộng theo chiều ngang (Horizontal Scaling).\n- Bài học: Phân loại hệ thống:\n+ OLTP (Online Transaction Processing): Hệ thống xử lý giao dịch (ngân hàng, đặt hàng), cần xử lý nhanh các thao tác đọc/ghi/cập nhật và đảm bảo toàn vẹn (roll back).\n+ OLAP (Online Analytical Processing): Hệ thống kho dữ liệu (Data Warehouse), lưu trữ dữ liệu lịch sử để phân tích phức tạp (báo cáo, tìm xu hướng). 13/10/2025 13/10/2025 Module 06 3 Amazon RDS\n- Học về dịch vụ: Amazon RDS (Relational Database Service), một dịch vụ CSDL quan hệ được quản lý hoàn toàn (managed service), hỗ trợ các engine phổ biến (MySQL, PostgreSQL, Oracle, v.v.).\n- Bài học: Mục tiêu của RDS là tự động hóa các tác vụ quản trị (cập nhật, sao lưu) để người dùng tập trung vào ứng dụng.\n- Tìm hiểu về kĩ thuật: Automated Backups (Sao lưu tự động) CSDL và transaction log, cho phép Point-in-Time Recovery (phục hồi tại một thời điểm) trong vòng 35 ngày.\n- Học về kiến trúc: Multi-AZ (High Availability)\n+ Tự động tạo một bản sao standby (dự phòng) ở một AZ khác.\n+ Sử dụng Synchronous Replication (sao chép đồng bộ).\n+ Hỗ trợ Automatic Failover (tự động chuyển đổi) nếu CSDL chính gặp sự cố.\n- Học về kiến trúc: Read Replicas (Tối ưu Hiệu năng Đọc)\n+ Tạo ra các bản sao chỉ đọc để giảm tải cho CSDL chính (ví dụ: cho các tác vụ báo cáo).\n+ Sử dụng Asynchronous Replication (sao chép bất đồng bộ), có thể gây ra \u0026ldquo;replication lag\u0026rdquo; (độ trễ).\n- Bài học: RDS thường được sử dụng cho các ứng dụng OLTP và được bảo vệ bằng Security Group. 14/10/2025 14/10/2025 Module 06 4 Amazon Aurora\n- Học về dịch vụ: Amazon Aurora, một CSDL do AWS phát triển, tương thích MySQL/PostgreSQL, thuộc dịch vụ RDS nhưng có hiệu năng cao hơn (gấp 3-5 lần).\n- Học về kiến trúc: Khác biệt lớn nhất của Aurora là tái thiết kế lại tầng lưu trữ.\n- Học về kiến trúc: Một \u0026ldquo;Cluster\u0026rdquo; Aurora bao gồm 1 Writer (bản ghi) và tối đa 15 Readers (bản đọc), tất cả cùng chia sẻ một phân vùng lưu trữ (Cluster Volume) duy nhất.\n- Tìm hiểu về kĩ thuật: Dữ liệu trên Cluster Volume được nhân bản 6 lần qua 3 AZ để đảm bảo độ bền.\n- Bài học: Ưu điểm vượt trội của Aurora là Zero Replication Lag (không có độ trễ sao chép) vì các bản Readers đọc chung volume với Writer.\n- Tìm hiểu về kĩ thuật: Các tính năng doanh nghiệp như Backtrack (tua ngược CSDL mà không cần restore) và Global Database (tạo bản sao chỉ đọc ở các Region khác nhau). 15/10/2025 15/10/2025 Module 06 5 Amazon Redshift\n- Học về dịch vụ: Amazon Redshift, một dịch vụ Data Warehouse (Kho dữ liệu) quy mô petabyte, được tối ưu cho OLAP.\n- Học về kiến trúc: Massively Parallel Processing (MPP) (Xử lý song song hàng loạt).\n+ Leader Node (Nút Lãnh đạo): Tiếp nhận, phân tích và điều phối truy vấn.\n+ Compute Nodes (Nút Tính toán): Lưu trữ và thực thi các phần công việc song song.\n- Tìm hiểu về kĩ thuật: Columnar Storage (Lưu trữ dạng Cột).\n+ Khác với OLTP (lưu theo hàng), Redshift lưu dữ liệu của cùng một cột gần nhau.\n+ Kỹ thuật này cực kỳ hiệu quả cho các truy vấn phân tích (OLAP) (ví dụ: Tính tuổi trung bình chỉ cần đọc cột Tuổi).\n- Tìm hiểu về kĩ thuật: Redshift Spectrum, cho phép chạy truy vấn SQL trực tiếp trên dữ liệu nằm trong Amazon S3 mà không cần tải về.\nAmazon ElastiCache\n- Học về dịch vụ: Amazon ElastiCache, một dịch vụ bộ nhớ đệm (caching) trong bộ nhớ RAM tốc độ cao.\n- Mục tiêu: Tăng tốc độ ứng dụng và giảm tải cho cơ sở dữ liệu chính (như RDS).\n- Tìm hiểu về các engine hỗ trợ: Redis (hỗ trợ nhiều kiểu dữ liệu, thường được ưu tiên) và Memcached.\n- Bài học: Trách nhiệm của người dùng là phải tự viết và quản lý Caching Logic (logic quyết định cái gì và khi nào cần cache) trong ứng dụng của mình. 16/10/2025 16/10/2025 Module 06 6 Lab: 000005 - Bắt đầu với Amazon RDS\n1. Tạo cơ sở dữ liệu (database) trên Amazon RDS\n2. Kết nối ứng dụng vào CSDL\n3. Sao lưu và Phục hồi\nLab: 000043 - Dịch chuyển CSDL với DMS và SCT\n1. Các bước chuẩn bị\n2. Oracle sang Amazon Aurora (PostgreSQL)\n2.1 Chuyển dổi Schema\n2.2 Dịch chuyển cơ sở dữ liệu. [Nghiên cứu bổ sung] - Database Internals\n- Tài liệu tìm hiểu cách thức vận hành bên trong của cơ sở dữ liệu. Database Internals Deep Distributed Systems\n[Nghiên cứu bổ sung] - The Data Warehouse Toolkit\n- Tài liệu tìm hiểu cách thức thiết kế và các kỹ thuật được sử dụng trong việc xây dựng Data-warehouse\nData Warehouse Toolkit Definitive Dimensional 17/10/2025 17/10/2025 Module 06 Kết quả đạt được tuần 6: Bài học (Nền tảng): Phân biệt rõ ràng hai mô hình hệ thống: OLTP (Online Transaction Processing - xử lý giao dịch) và OLAP (Online Analytical Processing - xử lý phân tích, kho dữ liệu). Nắm vững các kỹ thuật tối ưu CSDL cơ bản: Index (tăng tốc độ đọc) và Partition (chia nhỏ bảng). Hiểu vai trò của Database Log (để khôi phục/đồng bộ) và Buffer (dùng RAM để tăng tốc). Dịch vụ (RDS): Biết Amazon RDS là dịch vụ CSDL quan hệ (OLTP) được quản lý. Phân biệt rõ 2 tính năng chính của RDS: Multi-AZ (dùng cho tính Sẵn sàng cao - HA) và Read Replicas (dùng để tăng hiệu năng đọc). Kĩ thuật (Replication): Phân biệt Synchronous Replication (Sao chép đồng bộ - dùng cho RDS Multi-AZ) và Asynchronous Replication (Sao chép bất đồng bộ - dùng cho RDS Read Replicas, có thể bị trễ). Dịch vụ (Aurora): Biết Amazon Aurora là CSDL hiệu năng cao, cloud-native. Hiểu kiến trúc lưu trữ chia sẻ (Cluster Volume) của Aurora và lợi ích vượt trội là Zero Replication Lag (không có độ trễ). Nắm được các tính năng cao cấp như Backtrack và Global Database. Dịch vụ (Redshift): Biết Amazon Redshift là dịch vụ kho dữ liệu (OLAP). Hiểu kiến trúc MPP (Massively Parallel Processing) (gồm Leader Node và Compute Nodes). Nắm vững kỹ thuật cốt lõi của OLAP: Columnar Storage (Lưu trữ dạng Cột), giúp tăng tốc các truy vấn phân tích. Dịch vụ (ElastiCache): Biết Amazon ElastiCache (Redis/Memcached) là dịch vụ caching trong RAM. Hiểu vai trò của caching là giảm tải cho CSDL chính. Nhận thức được trách nhiệm phải tự viết Caching Logic trong ứng dụng. Thực hành: Biết cách tạo và vận hành (backup/restore) một CSDL RDS. Biết cách sử dụng dịch vụ DMS và SCT để dịch chuyển (migrate) CSDL từ Oracle sang Aurora. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.6-update-data/",
	"title": "Cập nhật dữ liệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Một trong những lợi thế lớn nhất của RAG so với Fine-tuning (huấn luyện lại) mô hình là khả năng cập nhật dữ liệu nhanh chóng. Khi doanh nghiệp có quy định mới, bạn chỉ cần nhập chúng vào Knowledge Base, và AI sẽ \u0026ldquo;học\u0026rdquo; chúng ngay lập tức.\nTrong phần này, chúng ta sẽ mô phỏng kịch bản sau:\nHỏi AI về một thông tin không tồn tại (AI sẽ trả lời là không biết). Cung cấp thông tin đó cho hệ thống bằng cách tải lên file mới. Hỏi lại câu hỏi tương tự để chứng kiến AI trả lời đúng ngay lập tức. Các Bước Thực hiện Bước 1: Xác minh \u0026ldquo;thiếu kiến thức\u0026rdquo; ban đầu\nChúng ta cần xác nhận rằng AI hiện tại không biết gì về thông tin bí mật mà chúng ta sắp tạo.\nQuay lại giao diện Streamlit Chatbot (được tạo trong Phần 5) hoặc sử dụng cửa sổ Test Knowledge Base trên Console. Đặt một câu hỏi về thông tin giả định không có thật. Ví dụ: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Quan sát kết quả: AI sẽ trả lời rằng không thể tìm thấy thông tin trong các tài liệu được cung cấp hoặc sẽ cố gắng đưa ra câu trả lời chung chung (nếu không bị hạn chế). Bước 2: Tạo dữ liệu mới\nChúng ta sẽ tạo một file văn bản chứa \u0026ldquo;bí mật\u0026rdquo; này để nhập vào hệ thống.\nTrên máy tính của bạn, mở Notepad (Windows) hoặc TextEdit (Mac). Sao chép và dán nội dung sau vào file: THÔNG BÁO MẬT: Dự án Omega bí mật chính thức khởi động vào ngày 01/12/2025. Mã kích hoạt là: \u0026#34;AWS-ROCKS-2025-SINGAPORE\u0026#34;. Người Quản lý Dự án là Ông Robot. Vui lòng giữ thông tin này tuyệt đối bí mật. Lưu file với tên: secret-project.txt. Bạn có thể tải file tại đây: Tệp định dạng TXT\nBước 3: Tải lên và Đồng bộ\nBây giờ, chúng ta sẽ cung cấp kiến thức mới này vào \u0026ldquo;bộ não\u0026rdquo; của AI.\nTruy cập S3 Console, điều hướng đến bucket cũ của bạn (rag-workshop-demo).\nNhấp Upload -\u0026gt; Add files -\u0026gt; Chọn file secret-project.txt -\u0026gt; Upload.\nChuyển sang Amazon Bedrock Console -\u0026gt; Chọn Knowledge bases từ menu bên trái. Nhấp vào tên Knowledge Base của bạn. Cuộn xuống phần Data source, chọn nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Chờ khoảng 30 giây đến 1 phút cho đến khi cột Status chuyển từ Syncing sang Available. Bước 4: Xác minh lại (Khoảnh khắc \u0026ldquo;Wow\u0026rdquo;)\nHệ thống hiện đã có kiến thức mới. Hãy thách thức AI một lần nữa.\nQuay lại giao diện Streamlit Chatbot (Không cần tải lại trang hoặc khởi động lại server). Hỏi chính xác câu hỏi tương tự như trước: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Kết quả mong đợi: AI trả lời chính xác: \u0026ldquo;Mã kích hoạt là AWS-ROCKS-2025-SINGAPORE\u0026rdquo;. AI trích dẫn nguồn là file secret-project.txt. Kết luận Bạn vừa chứng kiến sức mạnh thực sự của RAG!\nKhông cần chỉnh sửa code. Không cần huấn luyện lại mô hình. Chỉ cần Sync dữ liệu. Chatbot của bạn đã trở nên thông minh hơn và cập nhật với thông tin mới nhất chỉ trong vài bước đơn giản. Đây chính là lý do tại sao các doanh nghiệp chọn giải pháp này để xây dựng trợ lý ảo nội bộ.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Học và nghiên cứu thêm những kiến thức về Cloud Hoàn thành các Mooc trong Skil Builder ôn chứng chỉ Certificate Cloud Practicioner Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Học về Domain 1: Cloud Concept và Tìm ra được các lợi ích của AWS Cloud\n- Học lại về 5 tiêu chí của điện toán đám mây\n- Hạ tầng\n- Phân biệt được Khả năng sẵn có so với Khả năng chịu đựng so với Khả năng phục hồi\n- Phân biệt Scaling và Elastic\n- Xác định các nguyên tắc thiết kế của AWS Cloud\n- AWS Well-Architected Framework\n- General Design Principles\n- 6 trụ cột chính 20/10/2025 20/10/2025 Domain 1 3 Học về Domain 1: Cloud Concept và Tìm ra được các lợi ích của AWS Cloud\n- Hiểu được lợi ích và chiến lược di chuyển lên Đám mây AWS\n- AWS Cloud Adoption Framework\n- Cloud Adoption Stages\n- 7 Migration Strategies (The 7 R\u0026rsquo;s)\n- Migration Services \u0026amp; Scenarios\n- Hiểu về Thanh toán, Giá cả và Hỗ trợ (Cloud Econmics, TCO, Reduce Cost, ..) 21/10/2025 21/10/2025 Domain 1 4 Học về Domain 2: Bảo mật và tuân thủ\n- 2.1 Hiểu mô hình trách nhiệm chung của AWS ( AWS is responsible for, Customer is responsible in, Trách nhiệm THAY ĐỔI Dựa trên Dịch vụ)\n- 2.2 Hiểu các khái niệm về bảo mật, quản trị và tuân thủ của AWS Cloud (AWS Security, Gorvernance and Compliance)\n- 2.3 Xác định khả năng quản lý truy cập AWS(roor, IAM, Cognito, IAM Policies, )\n- 2.4 Xác định các thành phần và tài nguyên cho bảo mật ( Security Group, NACL, WAF) 22/10/2025 22/10/2025 Domain 2 5 Học về Domain 3: Công nghệ và dịch vụ đám mây\n- 3.1 Định nghĩa các phương pháp của deloying và operation trong AWS Cloud\n+ Phương pháp của Deploy và Operating\n+ Các loại Cloud hiện nay?\n+ So sánh dịch vụ Public và Private\n+ Các lựa chọn kết nối\n- 3.2 Xác định cơ sở hạ tầng toàn cầu của AWS\n+ Tìm hiểu về hạ tầng của AWS\n+ Tiện ích mở rộng khu vực\n+ Dịch vụ Edge: CloudFront so với Global Accelerator\n+ Các khái niệm chính về AZ và DR\n- 3.3 Xác định tài nguyên tính toán AWS\n+ Amazon EC2\n+ Lưu trữ trên EC2\n+ Các loại EC2 Instance\n+ Cấu hình EC2\n+ Containers\n+ Tính toán không máy chủ\n+ So sánh High Availability vs. Scalability\n- 3.4 Xác định tài nguyên tính toán AWS\n+ Tìm hiểu về Amazon RDS\n+ Tìm hiểu về Amazon Aurora\n+ Tìm hiểu về Amazon DynamoDB\n+ Cơ sở dữ liệu trong bộ nhớ (Amazon ElastiCache, Amazon DynamoDB Accelerator - DAX)\n+ Tìm hiểu về Amazon RedShift\n+ Tìm hiểu về Migration Database ( AWS Snow Family, AWS DMS, AWS DataSync) 23/10/2025 23/10/2025 Domain 3 6 Học về Domain 3: Công nghệ và dịch vụ đám mây\n- 3.5 Xác định tài nguyên mạng AWS\n+ Tìm hiểu về Amazon VPC\n+ Các loại VPC\n+ Các thành phần cốt lõi của VPC\n+ Bảo mật VPC\n+ VPC Gateways\n+ VPC \u0026amp; Hybrid Connectivity\n+ DNS \u0026amp; Routing\n- 3.6 Xác định tài nguyên lưu trữ AWS\n+ Các loại lưu trữ đám mây\n+ Tìm hiểu lưu trữ đối tượng: Amazon S3\n+ Tìm hiểu về lưu trữ tệp : EFS vs. FSx\n+ Lưu trữ khối: EBS so với Lưu trữ phiên bản\n+ Các loại khối lượng EBS\n+ Lưu trữ kết hợp: AWS Storage Gateway\n+ Tìm hiểu về Backup\n- 3.7 Xác định các dịch vụ trí tuệ nhân tạo và máy học của AWS cũng như các dịch vụ phân tích\n+ Tìm hiểu cơ bản về AI/ML\n+ 3 cấp độ của AWS ML ( AI Service, ML Services, ML Frameworks \u0026amp; Infrastructure)\n+ Các dịch vụ phân tích dữ liệu ( Amazon Athena, Amazon Macie, Amazon Redshift, Amazon Kinesis, Amazon Glue, Amazon QuickSight, Amazon EMR)\n- 3.8 Xác định các dịch vụ từ các danh mục dịch vụ AWS khác trong phạm vi\n+ Giám sát \u0026amp; Khả năng quan sát (CloudWatch, X-ray, EventBridge)\n+ Tìm hiểu về các dịch vụ tích hợp ứng dụng ( Amazon SQS, Amazon SNS)\n+ Sự khác nhau của Dịch vụ kinh doanh và khách hàng (Amazon Connect, Amazon SES, AWS Activate, AWS IQ,\u0026hellip;)\n+ Các công cụ cho người phát triển và DevOps (AWS Code Commit, AWS CodeBuild, AWS CodeDeploy,\u0026hellip;..)\n+ Tính toán End-User (Amazon AppStream 2.0, Amazon WorkSpaces, Amazon WorkSpacesWeb)\n+ Tim hiểu về dịch vụ cho Frontend Wed và Mobile ( AWS Amplify, AWS AppSync)\n+ Dịch vụ hỗ trợ IOT (AWS IoT Core, AWS IoT Greengrass) 24/10/2025 24/10/2025 Domain 3\nQuestion \u0026amp; Practice Kết quả đạt được tuần 7: 1. Domain 1: Cloud Concepts - Lợi ích của AWS Cloud Điện toán đám mây cơ bản:\nNắm vững 5 tiêu chí của điện toán đám mây (On-demand self-service, Broad network access, Resource pooling, Rapid elasticity, Measured service) Hiểu rõ về hạ tầng đám mây AWS Phân biệt rõ các khái niệm: Availability (Khả năng sẵn có): Hệ thống luôn hoạt động và có thể truy cập được Durability (Khả năng chịu đựng): Dữ liệu được bảo vệ khỏi mất mát Resilience (Khả năng phục hồi): Hệ thống có thể phục hồi nhanh sau sự cố Hiểu khác biệt giữa Scaling (Mở rộng quy mô) và Elasticity (Tính đàn hồi) AWS Well-Architected Framework:\nNắm vững các nguyên tắc thiết kế chung (General Design Principles) Hiểu rõ 6 trụ cột chính: Operational Excellence (Xuất sắc hoạt động) Security (Bảo mật) Reliability (Độ tin cậy) Performance Efficiency (Hiệu suất) Cost Optimization (Tối ưu chi phí) Sustainability (Tính bền vững) Di chuyển lên AWS Cloud:\nHiểu về AWS Cloud Adoption Framework (CAF) với 6 perspectives Nắm vững các giai đoạn chấp nhận đám mây (Cloud Adoption Stages) Học thuộc 7 chiến lược di chuyển (7 R\u0026rsquo;s): Rehost (Lift and Shift) Replatform (Lift, Tinker, and Shift) Repurchase (Drop and Shop) Refactor/Re-architect Retire Retain Relocate Hiểu về các dịch vụ và kịch bản di chuyển Cloud Economics:\nHiểu về Total Cost of Ownership (TCO) Các phương pháp giảm chi phí trên AWS Mô hình thanh toán và giá cả của AWS 2. Domain 2: Security and Compliance AWS Shared Responsibility Model:\nTrách nhiệm của AWS (Security OF the Cloud) Trách nhiệm của khách hàng (Security IN the Cloud) Trách nhiệm thay đổi dựa trên loại dịch vụ (IaaS, PaaS, SaaS) Security, Governance \u0026amp; Compliance:\nCác khái niệm bảo mật cơ bản của AWS Quản trị và tuân thủ trên AWS Cloud Các dịch vụ và công cụ bảo mật Access Management:\nAWS Root User và best practices AWS IAM (Identity and Access Management) Amazon Cognito IAM Policies và cách hoạt động Least Privilege Principle Security Components:\nSecurity Groups: Firewall ở tầng instance Network ACLs (NACLs): Firewall ở tầng subnet AWS WAF (Web Application Firewall): Bảo vệ ứng dụng web 3. Domain 3: Cloud Technology and Services (Phần 1) 3.1 Deployment và Operating Methods:\nCác phương pháp triển khai và vận hành Các loại Cloud: Public, Private, Hybrid So sánh dịch vụ Public vs Private Các tùy chọn kết nối 3.2 AWS Global Infrastructure:\nCấu trúc hạ tầng toàn cầu AWS (Regions, Availability Zones) Tiện ích mở rộng khu vực (Local Zones, Wavelength Zones) Edge Services: CloudFront vs Global Accelerator Khái niệm về Availability Zones và Disaster Recovery 3.3 AWS Compute Resources:\nAmazon EC2: Các loại instance, AMI, cấu hình EC2 Storage: EBS, Instance Store Containers: ECS, EKS, Fargate Serverless Computing: AWS Lambda So sánh High Availability vs Scalability 3.4 AWS Database Resources:\nAmazon RDS: Managed relational database Amazon Aurora: MySQL/PostgreSQL compatible Amazon DynamoDB: NoSQL database In-Memory Databases: ElastiCache, DynamoDB Accelerator (DAX) Amazon Redshift: Data warehouse Migration Services: AWS Snow Family, AWS DMS, AWS DataSync 4. Domain 3: Cloud Technology and Services (Phần 2) 3.5 AWS Network Resources:\nAmazon VPC và các thành phần cốt lõi: Subnets (Public/Private) Route Tables Internet Gateway NAT Gateway VPC Security: Security Groups, NACLs VPC Gateways: Internet Gateway, NAT Gateway, Virtual Private Gateway VPC \u0026amp; Hybrid Connectivity: VPN, Direct Connect DNS \u0026amp; Routing: Route 53 3.6 AWS Storage Resources:\nCác loại lưu trữ đám mây: Object, Block, File Amazon S3: Object storage, storage classes File Storage: EFS vs FSx Block Storage: EBS vs Instance Store EBS Volume Types: gp2, gp3, io1, io2, st1, sc1 AWS Storage Gateway: Hybrid storage Backup Solutions: AWS Backup 3.7 AI/ML và Analytics Services:\nCơ bản về AI/ML 3 cấp độ AWS ML: AI Services (Rekognition, Comprehend, etc.) ML Services (SageMaker) ML Frameworks \u0026amp; Infrastructure Analytics Services: Amazon Athena: Query S3 data Amazon Macie: Data security Amazon Redshift: Data warehouse Amazon Kinesis: Real-time data streaming Amazon Glue: ETL service Amazon QuickSight: BI tool Amazon EMR: Big data processing 3.8 Các Dịch Vụ AWS Khác:\nMonitoring \u0026amp; Observability: CloudWatch, X-Ray, EventBridge Application Integration: SQS, SNS Business \u0026amp; Customer Services: Amazon Connect, SES, AWS Activate, AWS IQ Developer \u0026amp; DevOps Tools: CodeCommit, CodeBuild, CodeDeploy, CodePipeline End-User Computing: AppStream 2.0, WorkSpaces, WorkSpaces Web Frontend \u0026amp; Mobile: AWS Amplify, AWS AppSync IoT Services: AWS IoT Core, AWS IoT Greengrass Tổng kết: Tuần 7 đã hoàn thành việc học tập toàn diện về 3 domains chính cho chứng chỉ AWS Cloud Practitioner. Nắm vững các khái niệm cloud computing cơ bản, hiểu rõ về bảo mật và tuân thủ trên AWS, cũng như làm quen với hầu hết các dịch vụ AWS quan trọng. Đã có nền tảng kiến thức vững chắc để chuẩn bị cho kỳ thi chứng chỉ.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.7-cleanup/",
	"title": "Dọn dẹp Tài nguyên",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành bài thực hành, chúng ta cần xóa các tài nguyên đã tạo.\n⚠️ CẢNH BÁO: Xóa Knowledge Base KHÔNG tự động xóa Vector Store (OpenSearch Serverless). Bạn phải xóa thủ công OpenSearch Serverless Collection vì đây là dịch vụ tốn chi phí nhất trong Lab này.\nCác Bước Thực hiện Bước 1: Xóa Knowledge Base\nTruy cập Amazon Bedrock Console -\u0026gt; Knowledge bases.\nChọn nút radio bên cạnh tên Knowledge Base của bạn.\nNhấp vào nút Delete.\nHộp thoại xuất hiện, nhập tên Knowledge Base để xác nhận (hoặc gõ delete).\nNhấp Delete. Quá trình này mất 10-15 phút mới xóa thành công. Nên bạn thư giản nhé\nBước 2: Xóa Vector Store\nTruy cập Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Bạn sẽ thấy một Collection có tên dạng bedrock-knowledge-base-.... Chọn nút radio bên cạnh tên Collection đó. Nhấp vào nút Delete. Gõ confirm hoặc tên collection để xác nhận xóa. Nhấp Delete. Bước 3: Xóa Dữ liệu trên S3\nTruy cập dịch vụ Amazon S3. Chọn bucket rag-workshop-demo. Nhấp vào nút Empty trước tiên. Gõ permanently delete để xác nhận xóa tất cả các file bên trong. Sau khi bucket rỗng, quay lại danh sách Buckets. Chọn lại bucket đó và nhấp vào nút Delete. Nhập tên bucket để xác nhận. Hoàn thành Chúc mừng bạn đã hoàn thành đầy đủ Workshop \u0026ldquo;Xây dựng Ứng dụng RAG với Amazon Bedrock\u0026rdquo;. Hệ thống của bạn đã được dọn dẹp và an toàn!\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Hoàn thành các khóa học về NLP (Natural Language Processing) Tìm hiểu thêm về FastAPI để chuẩn bị cho dự án sắp tới. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Hoàn thành Module 01 - Xử lý ngôn ngữ tự nhiên với phân loại và không gian vectơ\n- Week 01: Phân tích tình cảm với hồi quy logistic\n- Week 02: Phân tích tình cảm với Naive Bayes\n- Week 03: Mô hình không gian Vector\n- Week 04: Dịch máy và Tìm kiếm tài liệu 27/10/2025 27/10/2025 Module 01 - Week 01\nModule 01 - Week 02\nModule 01 - Week 03\nModule 01 - Week 04 3 Hoàn thành Module 02 - Xử lý ngôn ngữ tự nhiên với mô hình xác suất\n- Week 01: Tự động sửa lỗi và Khoảng cách chỉnh sửa tối thiểu\n- Week 02: Gắn thẻ từ loại và mô hình Markov ẩn\n- Week 03: Autocomplete and Language Models\n- Week 04: Word Embeddings with Neural Network 28/10/2025 28/10/2025 Module 02 - Week 01\nModule 02 - Week 02\nModule 02 - Week 03\nModule 02 - Week 04 4 Hoàn thành Module 03 - Xử lý ngôn ngữ tự nhiên với mô hình chuỗi\n- Week 01: Recurrent Neural Network cho Language Modeling\n- Week 02: LSTMs và Named Entity Recognition\n- Week 03: Siamese Networks 29/10/2025 29/10/2025 Module 03 - Week 01\nModule 03 - Week 02\nModule 03 - Week 03 5 Hoàn thành Module 04 - Xử lý ngôn ngữ tự nhiên với các mô hình chú ý\n- Week 01: Neural Machine Translation\n- Week 02: Tóm tắt văn bản\n- Week 03: Question Answering 30/10/2025 30/10/2025 Module 04 - Week 01\nModule 04 - Week 02\nModule 04 - Week 03 6 - Học cách triển khai một một hình ML thành API\n- Thử xây dựng một ứng dụng với CRUD dùng hoàn toàn bằng FastAPI 31/10/2025 31/10/2025 Machine_Learning_Model_AS_API\nFastAPI_Built_Application_CRUD Kết quả đạt được tuần 8: 1. Module 01 - Xử Lý Ngôn Ngữ Tự Nhiên với Phân Loại và Không Gian Vectơ Week 01: Phân Tích Tình Cảm với Hồi Quy Logistic\nHiểu về binary classification cho sentiment analysis Xây dựng model logistic regression từ đầu Feature extraction với Bag of Words Preprocessing: tokenization, stemming, stop words removal Đánh giá model với accuracy, precision, recall Week 02: Phân Tích Tình Cảm với Naive Bayes\nHiểu về Bayes\u0026rsquo; Theorem và conditional probability Xây dựng Naive Bayes classifier So sánh performance với Logistic Regression Hiểu về independence assumption Laplacian smoothing để xử lý zero probability Week 03: Mô Hình Không Gian Vector\nVector space models và word representations Cosine similarity để đo độ tương đồng PCA (Principal Component Analysis) để giảm chiều Visualize word embeddings Euclidean distance vs Cosine similarity Week 04: Dịch Máy và Tìm Kiếm Tài Liệu\nWord alignment cho machine translation Hash tables và locality sensitive hashing Document search và information retrieval K-nearest neighbors trong NLP Transformation matrices cho word translation 2. Module 02 - Xử Lý Ngôn Ngữ Tự Nhiên với Mô Hình Xác Suất Week 01: Tự Động Sửa Lỗi và Khoảng Cách Chỉnh Sửa Tối Thiểu\nEdit distance (Levenshtein distance) Dynamic programming cho minimum edit distance Spelling correction algorithms Probability-based error correction N-gram models cho spell checking Week 02: Gắn Thẻ Từ Loại và Mô Hình Markov Ẩn\nPart-of-Speech (POS) tagging Hidden Markov Models (HMMs) Viterbi algorithm cho sequence labeling Transition và emission probabilities Training HMMs với tagged corpus Week 03: Autocomplete và Language Models\nN-gram language models (unigram, bigram, trigram) Perplexity để đánh giá language models Smoothing techniques (Laplace, Add-k) Backoff và interpolation Building autocomplete systems Week 04: Word Embeddings với Neural Networks\nContinuous Bag of Words (CBOW) Skip-gram model Word2Vec architecture Training word embeddings Negative sampling Evaluating word embeddings 3. Module 03 - Xử Lý Ngôn Ngữ Tự Nhiên với Mô Hình Chuỗi Week 01: Recurrent Neural Networks cho Language Modeling\nRNN architecture và forward propagation Backpropagation through time (BPTT) Vanishing và exploding gradient problems Language modeling với RNNs Text generation với RNNs GRU (Gated Recurrent Units) Week 02: LSTMs và Named Entity Recognition\nLong Short-Term Memory (LSTM) architecture Cell state, forget gate, input gate, output gate Named Entity Recognition (NER) task Bidirectional LSTMs Training LSTMs cho sequence labeling Evaluating NER systems Week 03: Siamese Networks\nSiamese network architecture Triplet loss function One-shot learning Similarity learning Applications: question duplicate detection, semantic similarity Cosine similarity trong neural networks 4. Module 04 - Xử Lý Ngôn Ngữ Tự Nhiên với Các Mô Hình Chú Ý Week 01: Neural Machine Translation\nSequence-to-sequence (Seq2Seq) models Encoder-decoder architecture Attention mechanism Teacher forcing BLEU score cho machine translation Beam search decoding Week 02: Tóm Tắt Văn Bản\nExtractive vs Abstractive summarization Seq2Seq với attention cho summarization ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L) Coverage mechanism Pointer-generator networks Handling long documents Week 03: Question Answering\nQuestion answering systems Context-based QA Attention mechanisms cho QA SQuAD dataset Extractive QA models End-to-end trainable QA systems 5. FastAPI và Triển Khai Machine Learning Models Machine Learning Model as API:\nSetup FastAPI project structure Load và serve ML models Request/Response schemas với Pydantic Input validation và error handling Preprocessing pipelines trong API Testing API endpoints Dockerize ML API FastAPI CRUD Application:\nRESTful API design principles CRUD operations (Create, Read, Update, Delete) Database integration (SQLAlchemy) Async/await operations Authentication và authorization API documentation với Swagger/OpenAPI Dependency injection trong FastAPI File structure best practices: app/main.py: Entry point app/routers/: API routes app/models/: Database models app/schemas/: Pydantic schemas app/crud/: Database operations app/db/: Database configuration FastAPI Key Features Mastered:\nPath parameters và query parameters Request body validation Response models Background tasks Middleware CORS configuration Environment variables Testing với pytest Tổng kết: Tuần 8 đã hoàn thành toàn bộ chương trình học về NLP từ cơ bản đến nâng cao, bao gồm 4 modules với các chủ đề từ classification, probabilistic models, sequence models đến attention mechanisms. Nắm vững các kỹ thuật từ traditional methods (Naive Bayes, HMM) đến modern deep learning approaches (RNN, LSTM, Attention). Đồng thời thành thạo FastAPI framework để triển khai ML models thành production-ready APIs với đầy đủ CRUD operations, validation, và best practices. Đã sẵn sàng áp dụng kiến thức NLP và FastAPI vào dự án thực tế.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Dự án FastAPI với MongoDB Thư viện STT tiếng Việt được lựa chọn và tích hợp Thư viện OCR tiếng Việt được lựa chọn và thử nghiệm Trích xuất NLP: số lượng, danh mục, ngày tháng, phát hiện jar (REQ-027) Phát hiện nhiều giao dịch (REQ-027) Xuất bản sự kiện lên RabbitMQ Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Thiết lập dự án - Tạo cấu trúc dự án FastAPI (/app, /models, /services, /utils, /routers, /schemas, /ai-models)\n- Thiết lập môi trường ảo (Python 3.11 trở lên)\n- Cài đặt FastAPI, Uvicorn, Pydantic\n- Cài đặt MongoDB cục bộ (Docker)\n- Tạo cơ sở dữ liệu: ai_service_db (được cấu hình trong docker-compose.yml)\n- Thu thập bộ dữ liệu: Bills, Voices (sử dụng mô hình MongoEngine)\n- Thiết lập kết nối MongoDB với MongoEngine\n- Kiểm tra kết nối (quản lý vòng đời trong database.py)\nNghiên cứu công nghệ - Về phần Bill: Thử các loại mô hình OCR giải quyết được vấn đề triết xuất tiếng Việt tốt nhất. - Về phần Voice: Tìm kiếm các loại mô hình Speech-to-Text, bằng ngôn ngữ Tiếng Việt. 03/11/2025 03/11/2025 Sprint 01 - Day 01 3 Cấu trúc API cốt lõi và điểm cuối\n- Cơ sở hạ tầng API dùng chung\n- Thiết lập các API của Voice và Bill\n- Tạo cấu trúc điểm cuối API cơ bản\n- Thiết lập mô hình Pydantic cho yêu cầu/phản hồi\n- Thêm phần mềm trung gian CORS\n- Thêm phần mềm trung gian xử lý lỗi\n- Tạo điểm cuối kiểm tra tình trạng (GET /health)\n- Thiết lập ghi nhật ký (structlog) 04/11/2025 04/11/2025 Sprint 01 - Day 02 4 Quy trình Xử lý Giọng nói\n- Cài đặt Thư viện STT tiếng Việt\n- Tiền xử lý âm thanh\n- Tích hợp Giọng nói thành Văn bản\n- Triển khai chức năng STT\n- Kiểm tra Voice Model\nChuẩn bị OCR cho extract Bill\n- Cài đặt thư viện OCR đã chọn từ Ngày 1\n- Nghiên cứu các kỹ thuật tiền xử lý ảnh\n- Tạo quy trình tiền xử lý mẫu\n- Thử nghiệm với hình ảnh bill 05/11/2025 05/11/2025 Sprint 01 - Day 03 5 Xử lý Text cho ngôn ngữ Tiếng Việt\n- Test độ chính xác của mô hình, và chọn mô hình phù hợp, và nhóm dùng mô hình PhoWhisper của VinAI\n- Kiểm tra detect của mô hình, có nhận được giọng nói và trả về Text hay không. - Chỉnh sửa Endpoint của kết quả cuối có trả về đúng các category mà nhóm đưa ra hay không. - Thử nghiệm xử lý nhiều giao dịch cùng lúc, mô hình có nhận được không. - Thiết lập detect được thời gian của người nói về giao dịch\n- Tạo đối tượng giao dịch\nTiền xử lý OCR\n- Xử lý ảnh khi người dùng nhập vào và xử lý hóa đơn đó. Tạo cho ảnh đó đạt chất lượng tốt nhất trước khi đưa cho mô hình OCR xử lý. - Thu thập các hóa đơn ở Việt Nam như ( hóa đơn điện, hóa đơn các trung tâm thương mại, hóa đơn các quán ăn, hóa đơn các cửa hàng tiện lợi, hóa đơn các quán cà phê, \u0026hellip;) 06/11/2025 06/11/2025 Sprint 01 - Day 04 6 Tích hợp và Kiểm thử\n- Xử lý các công việc nền của Voice và Bill\n- Thiết lập xuất bản sự kiện\nSpeech to Text\n- Kiểm thử đầu cuối của Voice\n- Các quy trình chạy như Ghi âm -\u0026gt; Xử lý -\u0026gt; Trả Endpoint, kiểm tra và cải thiện độ chính xác của xử lý Voice đã ổn chưa\nBill Detection\n- Triển khai nghiệm thử các mô hình OCR, teseract, easyOCR,\u0026hellip; 07/11/2025 07/11/2025 Sprint 01 - Day 05 Kết quả đạt được tuần 9: 1. Thiết lập Dự án và Hạ tầng Hoàn thành cấu trúc dự án FastAPI với các thư mục chuẩn (/app, /models, /services, /utils, /routers, /schemas, /ai-models) Thiết lập môi trường Python 3.11+ với môi trường ảo Cài đặt và cấu hình MongoDB cục bộ sử dụng Docker Tạo cơ sở dữ liệu ai_service_db và thu thập bộ dữ liệu Bills và Voices Thiết lập kết nối MongoDB với MongoEngine và quản lý vòng đời kết nối 2. Cấu trúc API và Middleware Thiết lập các API endpoint cho Voice và Bill processing Tạo mô hình Pydantic cho request/response validation Cấu hình CORS middleware và error handling middleware Triển khai health check endpoint (GET /health) Tích hợp structlog cho logging system 3. Xử lý Giọng nói (Speech-to-Text) Nghiên cứu và lựa chọn mô hình PhoWhisper của VinAI cho STT tiếng Việt Triển khai tiền xử lý âm thanh và tích hợp Voice-to-Text Kiểm tra độ chính xác của mô hình và khả năng detect giọng nói Cấu hình endpoint trả về đúng các category đã định nghĩa Thử nghiệm xử lý nhiều giao dịch cùng lúc Thiết lập phát hiện thời gian giao dịch từ giọng nói Tạo đối tượng giao dịch từ dữ liệu voice 4. Xử lý Hóa đơn (OCR) Nghiên cứu và lựa chọn thư viện OCR phù hợp (Tesseract, EasyOCR) Triển khai tiền xử lý ảnh để tối ưu chất lượng trước khi OCR Thu thập bộ dữ liệu hóa đơn Việt Nam đa dạng (điện, siêu thị, quán ăn, cửa hàng tiện lợi, cà phê) Thử nghiệm các mô hình OCR với hóa đơn thực tế 5. Trích xuất NLP và Xử lý Dữ liệu Triển khai trích xuất thông tin: số lượng, danh mục, ngày tháng (REQ-027) Phát hiện jar detection Xử lý phát hiện nhiều giao dịch trong một request 6. Tích hợp RabbitMQ Thiết lập xuất bản sự kiện lên RabbitMQ Xử lý các công việc nền (background tasks) cho Voice và Bill 7. Testing và Quality Assurance Kiểm thử end-to-end cho Voice processing pipeline (Ghi âm → Xử lý → Trả Endpoint) Đánh giá và cải thiện độ chính xác của xử lý Voice Kiểm thử các mô hình OCR với dataset thực tế Tổng kết: Tuần 9 đã hoàn thành đầy đủ các mục tiêu đề ra, bao gồm thiết lập hạ tầng dự án FastAPI-MongoDB, tích hợp mô hình PhoWhisper cho STT tiếng Việt, triển khai OCR cho xử lý hóa đơn, và thiết lập hệ thống event publishing với RabbitMQ. Các chức năng NLP cho trích xuất thông tin giao dịch đã được triển khai và kiểm thử thành công.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Cải tiến và tối ưu hóa mô hình OCR cho nhiều loại hóa đơn Nâng cao chất lượng xử lý Voice với số tiếng Việt và cụm từ ghép Triển khai hệ thống Confidence Scoring cho cả Voice và Bill Phát hiện danh mục thông minh và nhận dạng ngữ cảnh Xử lý lỗi toàn diện và tối ưu hiệu suất Kiểm thử đa chiều với các trường hợp edge cases Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Tham gia Cloud Mastery Series #2\nCải tiến thêm đôi chút về OCR - Phát hiện và trích xuất mục hàng đúng định dạng Json\n- Trích xuất đa mục hàng hóa trong hóa đơn\n- Tính số lượng các thành phần có trong hóa đơn đó\n- Kiểm tra thử với nhiều dạng bill khác nhau. Cải thiện về chất lượng của mô hình Voice\n- Xử Lý Số Tiếng Việt như (hai mươi hai thành 22)\n- Nhận dạng các cụm từ ghép\n- Sửa lỗi chính tả và xử lý tiếng ồn\n- Cải tiến định dạng phản hồi về file Json\n- Kiểm thử 10/11/2025 10/11/2025 Sprint 02 - Day 06 3 Kiểm tra điểm tin cậy của mô hình OCR\n- Tính toán Độ tin cậy Cấp trường\n- Tính điểm tin cậy cho từng trường được trích xuất:\n- Độ tin cậy Số tiền/Tổng:\n- Độ tin cậy ngày:\n- Độ rõ nét của văn bản\n- Phân tách dòng rõ ràng\n- Căn chỉnh giá\n- Phát hiện số lượng\n- Thuật toán độ tin cậy tổng thể\n- Tính Low Confidence Threshold\n- Kiểm tra hơn 30 bills\nKiểm tra Confidence Scoring của Voice\n- Kiểm thử điểm số tin cậy nhiều lớp\n- Kiểm thử thuật toán độ tin cậy tổng thể\n- Kiểm thử Low Confidence Threholds của Voice\n- Kiểm tra hiệu suất (hơn 50 mẫu, \u0026lt;4 giây)\nKiểm tra toàn bộ và testing hệ thống Voice và Bill 11/11/2025 11/11/2025 Sprint 02 - Day 07 4 Phát hiện danh mục thông minh và nhận dạng các ngữ cảnh trong Voice\n- Phát hiện danh mục nâng cao như phân tích tên người bán, triết xuất keyword dựa vào các danh mục\n- Xác định ngữ cảnh - Kiểm thử\nTriết xuất các loại hóa đơn mới\n- Thử nghiệm hóa đơn siêu thị - Thử nghiệm trên hóa đơn nhà hàng\n- Thử nghiệm trên hóa đơn cà phê, các quán nước,\u0026hellip;\n- Quy tắc trích xuất theo từng loại cụ thể\n- Cải thiện phần trả về endpoint Json của phần Bill\nTích hợp và chạy thử với Backend\n- Tích hợp các chức năng giao dịch\n- Xử lý lỗi - Trả về giá trị Json đúng 12/11/2025 12/11/2025 Sprint 02 - Day 08 5 Error Handling, Optimization \u0026amp; Monitoring\nTối ưu hóa việc xử lý Voice\n- Tối ưu hóa hiệu suất của model Voice\nXử lý Lỗi \u0026amp; Khả năng Phục hồi\n- Xử lý Âm thanh Hỏng:\n- Xác thực định dạng âm thanh (WAV, MP3, M4A)\n- Kiểm tra thời lượng âm thanh (tối thiểu 0,5 giây, tối đa 30 giây)\n- Phát hiện tệp bị hỏng/không đầy đủ\n- Trả về lỗi xóa: \u0026ldquo;Định dạng âm thanh không hợp lệ hoặc tệp bị hỏng\u0026rdquo;\n- Xử lý Thời gian Chờ STT:\n- Đặt thời gian chờ cho quá trình xử lý STT (tối đa 30 giây)\n- Nếu hết thời gian chờ, trả về kết quả một phần kèm theo cảnh báo\n- Ghi nhật ký sự kiện hết thời gian chờ để theo dõi\nLogic Thử Lại:\n- Thử lại STT khi gặp lỗi tạm thời (tối đa 3 lần thử lại)\n- Thời gian chờ theo cấp số nhân: 1 giây, 2 giây, 4 giây\n- Trả về lỗi sau số lần thử lại tối đa\nTrường hợp Ngoại lệ:\n- Âm thanh trống/im lặng → Lỗi: \u0026ldquo;Không phát hiện thấy giọng nói\u0026rdquo;\n- Giọng nói không phải tiếng Việt → Cảnh báo độ tin cậy thấp\n- Nhiều người nói → Cảnh báo + trích xuất nỗ lực tốt nhất\n- Âm thanh rất dài (\u0026gt;30 giây) → Lỗi: \u0026ldquo;Âm thanh quá dài\u0026rdquo; \u0026ldquo;dài\u0026rdquo;\nGiảm cấp duyên dáng:\n- Nếu phát hiện danh mục không thành công → Trả về \u0026ldquo;Chưa phân loại\u0026rdquo;\n- Nếu trích xuất số lượng không thành công → Trả về giá trị null kèm cảnh báo\n- Nếu không phát hiện ngày → Sử dụng ngày hiện tại kèm cảnh báo\n- Luôn trả về kết quả một phần khi có thể 13/11/2025 13/11/2025 Sprint 02 - Day 09 6 Kiểm tra và tài liệu toàn diện\n- Chuẩn bị các data cho cho việc kiểm tra hai mô hình Voice và Bill\n- Kiểm tra API của Voice\n- Kiểm tra API của Bill OCR\nKiểm tra các trường hợp của Voice\n- Kiểm tra khi có tiếng ồn xung quanh\n- Kiểm tra khi nói nhanh hoặc chậm\n- Kiểm tra khi đầu vào không đúng giá trị, như người nói và nói tàm phào\n- Kiểm tra đa giao dịch trong một lần ghi âm\n- Kiểm tra đầu vào mơ hồ Kiểm tra các trường hợp của xử lý Bill\n- Kiểm tra anh xoay nhiều hướng có nhận diện được không\n- Kiểm tra chất lượng ảnh\n- Kiểm tra các input không đúng ảnh hóa đơn\n- Kiểm tra với các hóa đơn có độ phức tạp cao\n- Kiểm tra với các hóa đơn có nhiều mặt hàng 14/11/2025 14/11/2025 Sprint 02 - Day 10 Kết quả đạt được tuần 10: 1. Cải Tiến Mô Hình OCR Phát hiện và trích xuất mục hàng đúng định dạng JSON Trích xuất đa mục hàng hóa trong một hóa đơn Tính toán số lượng các thành phần trong hóa đơn tự động Kiểm thử thành công với nhiều loại hóa đơn: siêu thị, nhà hàng, cà phê, quán nước Xây dựng quy tắc trích xuất theo từng loại hóa đơn cụ thể Cải thiện format JSON response cho endpoint Bill 2. Nâng Cao Chất Lượng Voice Processing Xử lý số tiếng Việt (chuyển \u0026ldquo;hai mươi hai\u0026rdquo; → \u0026ldquo;22\u0026rdquo;) Nhận dạng các cụm từ ghép tiếng Việt Sửa lỗi chính tả và xử lý nhiễu âm thanh Cải tiến định dạng phản hồi JSON Tối ưu hóa hiệu suất xử lý Voice 3. Hệ Thống Confidence Scoring OCR Confidence:\nTính toán độ tin cậy cấp trường (Field-level Confidence) Độ tin cậy cho Số tiền/Tổng Độ tin cậy cho Ngày tháng Đánh giá độ rõ nét văn bản và phân tách dòng Phát hiện căn chỉnh giá và số lượng Xây dựng thuật toán độ tin cậy tổng thể Thiết lập Low Confidence Threshold Kiểm thử trên hơn 30 hóa đơn thực tế Voice Confidence:\nTriển khai điểm số tin cậy nhiều lớp (Multi-layer Confidence Scoring) Thuật toán độ tin cậy tổng thể cho Voice Thiết lập Low Confidence Thresholds Kiểm tra hiệu suất trên hơn 50 mẫu (thời gian xử lý \u0026lt;4 giây) 4. Phát Hiện Danh Mục Thông Minh Phân tích tên người bán/merchant Trích xuất keyword dựa vào danh mục Xác định ngữ cảnh giao dịch Phát hiện danh mục nâng cao (Advanced Category Detection) 5. Error Handling \u0026amp; Resilience Xử lý Lỗi Âm Thanh:\nXác thực định dạng âm thanh (WAV, MP3, M4A) Kiểm tra thời lượng (min: 0.5s, max: 30s) Phát hiện tệp bị hỏng/không đầy đủ Xử lý timeout STT (max: 30s) Logic retry với exponential backoff (3 lần, 1s-2s-4s) Xử lý Trường Hợp Ngoại Lệ:\nÂm thanh trống/im lặng → Error: \u0026ldquo;Không phát hiện giọng nói\u0026rdquo; Giọng nói không phải tiếng Việt → Cảnh báo độ tin cậy thấp Nhiều người nói → Cảnh báo + trích xuất nỗ lực tốt nhất Âm thanh quá dài (\u0026gt;30s) → Error: \u0026ldquo;Âm thanh quá dài\u0026rdquo; Graceful Degradation:\nDanh mục không phát hiện được → Trả về \u0026ldquo;Chưa phân loại\u0026rdquo; Số lượng không trích xuất được → Trả về null + cảnh báo Ngày không phát hiện → Sử dụng ngày hiện tại + cảnh báo Luôn trả về kết quả partial khi có thể 6. Kiểm Thử Toàn Diện Voice Testing:\nKiểm tra với tiếng ồn xung quanh Kiểm tra tốc độ nói (nhanh/chậm) Kiểm tra đầu vào không hợp lệ (nói tàm phào) Kiểm tra đa giao dịch trong một lần ghi âm Kiểm tra đầu vào mơ hồ Bill OCR Testing:\nKiểm tra ảnh xoay nhiều hướng Kiểm tra chất lượng ảnh đa dạng Kiểm tra input không đúng định dạng hóa đơn Kiểm tra hóa đơn có độ phức tạp cao Kiểm tra hóa đơn nhiều mặt hàng 7. Tích Hợp Backend Tích hợp các chức năng giao dịch với Backend Xử lý lỗi toàn diện Trả về giá trị JSON chuẩn hóa Tổng kết: Tuần 10 tập trung vào việc nâng cao chất lượng và độ tin cậy của cả hai mô hình Voice và OCR. Đã triển khai thành công hệ thống confidence scoring, xử lý lỗi toàn diện, và kiểm thử đa chiều với nhiều edge cases. Hệ thống đã sẵn sàng tích hợp với Backend và xử lý các tình huống thực tế phức tạp.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Phát hiện và xử lý nhiều giao dịch phức tạp Tích hợp hỗ trợ file PDF cho Bill OCR Triển khai hệ thống feedback và fine-tuning models Nâng cao chất lượng xử lý hình ảnh và âm thanh Tích hợp Backend và lưu trữ MongoDB Automated testing và deployment Docker Làm quen với AWS và các công cụ quản lý Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Phát hiện nhiều giao dịch và hỗ trợ PDF\n- Phân tích cú pháp đa giao dịch phức tạp\n- Tinh chỉnh thuật toán phát hiện đa giao dịch:\n- Phát hiện phân công jar trong cụm từ\n- Xử lý các loại giao dịch hỗn hợp:\nKiểm tra các cụm từ phức tạp\n- Kiểm tra 1 giao dịch với 1 hủ\n- Kiểm tra nhiều giao dịch\n- Kiểm thử chuyển đổi giữa các hủ\n- Kiểm thử các ngữ cảnh hỗn hợp\nCải thiện thêm hỗ trợ file PDF cho phần Bill\n- Cài đặt các thư viện\n- Kiểm thử giao dịch với file PDF 17/11/2025 17/11/2025 Sprint 03 - Day 11 3 Hệ thống phản hồi và học tập của người dùng\n- Xử lý hệ thống feedback từ user của phần Voice\n- Xử lý hệ thống feedback từ user của phần Bill\n- Fine-tuning các model dựa trên các feedback\n- Cải thiện các cú pháp khi nhập vào sai\nKiểm tra độ cải thiện của 2 mô hình Voice và Test 18/11/2025 18/11/2025 Sprint 03 - Day 12 4 Xử lý hình ảnh/âm thanh nâng cao - Phát hiện và nâng cao chất lượng Bill\n- Detect chất lượng ảnh\n- Tự động xoay và nghiên ảnh\n- Phát hiện ROI (Vùng quan tâm)\n- Tích hợp với OCR Pipeline\n- Kiểm thử\nXử lý tiếng ồn nền của Voice\n- Triển khai giảm noise\n- Phát hiện hoạt động giọng nói\n- Cắt phần im lặng\n- Giảm thời gian xử lý\n- Tích hợp với Voice Pipeline\n- Kiểm thử 19/11/2025 19/11/2025 Sprint 03 - Day 13 5 Tích hợp Backend \u0026amp; Lưu trữ Tệp\nTích hợp dịch vụ giao dịch phụ trợ\n- Review về Backend API\n- Test AI và Backend flow\n- Xác minh mức tiêu thụ sự kiện\n- Kiểm tra việc tạo giao dịch tự động\n- Khắc phục sự cố tích hợp\nTích hợp lưu trữ trên MongoDB\n- Thiết lập Database cho Voice và Bill\n- Chuẩn bị cho việc tích hợp cùng với S3 của Amazon\n20/11/2025 20/11/2025 Sprint 03 - Day 14 6 Tạo thử nghiệm tự động\n- Tạo test cho Voice và Bill\n- Nghiệm thu và kiểm tra tất các cá kiểm tra\n- Sửa lỗi\n- Kiểm tra hồi quy đầy đủ\nSetup và Deploy lên Docker 21/11/2025 21/11/2025 Sprint 03 - Day 15 Kết quả đạt được tuần 11: 1. Phát Hiện Nhiều Giao Dịch và Hỗ Trợ PDF Phân tích cú pháp đa giao dịch phức tạp Tinh chỉnh thuật toán phát hiện đa giao dịch Phát hiện phân công jar trong cụm từ Xử lý các loại giao dịch hỗn hợp Kiểm Tra Cụm Từ Phức Tạp:\nKiểm tra 1 giao dịch với 1 hủ Kiểm tra nhiều giao dịch Kiểm thử chuyển đổi giữa các hủ Kiểm thử các ngữ cảnh hỗn hợp Hỗ Trợ PDF:\nCài đặt các thư viện xử lý PDF Kiểm thử giao dịch với file PDF Tích hợp PDF vào OCR Pipeline 2. Hệ Thống Phản Hồi và Học Tập Xử lý hệ thống feedback từ user của phần Voice Xử lý hệ thống feedback từ user của phần Bill Fine-tuning các model dựa trên feedback Cải thiện xử lý các cú pháp nhập vào sai Kiểm tra độ cải thiện của 2 mô hình Voice và Bill 3. Xử Lý Hình Ảnh/Âm Thanh Nâng Cao Nâng Cao Chất Lượng Bill:\nPhát hiện và đánh giá chất lượng ảnh Tự động xoay và nghiêng ảnh Phát hiện ROI (Region of Interest/Vùng quan tâm) Tích hợp với OCR Pipeline Kiểm thử với nhiều điều kiện ảnh khác nhau Xử Lý Tiếng Ồn Nền Voice:\nTriển khai giảm noise (Noise Reduction) Phát hiện hoạt động giọng nói (Voice Activity Detection) Cắt phần im lặng (Silence Trimming) Giảm thời gian xử lý Tích hợp với Voice Pipeline Kiểm thử với nhiều môi trường âm thanh 4. Tích Hợp Backend \u0026amp; Lưu Trữ Tích Hợp Backend:\nReview Backend API endpoints Test AI và Backend workflow Xác minh mức tiêu thụ sự kiện (Event Consumption) Kiểm tra việc tạo giao dịch tự động Khắc phục sự cố tích hợp Tích Hợp MongoDB:\nThiết lập Database cho Voice và Bill Chuẩn bị schema cho tích hợp với S3 của Amazon Triển khai storage strategy 5. Testing Tự Động và Deployment Tạo automated tests cho Voice và Bill Nghiệm thu và kiểm tra tất cả test cases Sửa lỗi phát hiện từ testing Kiểm tra hồi quy đầy đủ (Full Regression Testing) Setup Docker environment Deploy lên Docker container 6. AWS Learning Hiểu AWS và các nhóm dịch vụ cơ bản (Compute, Storage, Networking, Database) Tạo và cấu hình AWS Free Tier account Làm quen với AWS Management Console Cài đặt và cấu hình AWS CLI (Access Key, Secret Key, Region) Thực hiện các thao tác cơ bản với AWS CLI Kết nối và làm quen với cộng đồng First Cloud Journey Tổng kết: Tuần 11 đã hoàn thành việc nâng cao khả năng xử lý đa giao dịch, tích hợp hỗ trợ PDF, triển khai hệ thống feedback và fine-tuning models. Đã cải thiện đáng kể chất lượng xử lý ảnh/âm thanh với các kỹ thuật nâng cao (ROI detection, noise reduction, VAD), tích hợp thành công với Backend và MongoDB, đồng thời hoàn tất automated testing và deployment lên Docker. Bên cạnh đó, đã làm quen với AWS ecosystem và các công cụ quản lý cơ bản, chuẩn bị cho việc triển khai cloud infrastructure.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Kiểm tra tải và tối ưu hóa hiệu suất hệ thống Cải thiện độ chính xác của Voice và OCR models Tăng cường bảo mật và xử lý lỗi toàn diện Triển khai logging và metrics collection nâng cao Chuẩn bị deployment và kiểm tra cuối cùng Nâng cao chất lượng code và documentation Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Thiết lập kiểm tra tải\n- Cài đặt công cụ kiểm tra tải\n- Tạo các kịch bản kiểm tra tải\n- Thiết lập giám sát tài nguyên\n- Chuẩn bị dữ liệu thử nghiệm\nChạy thử nghiệm tải\n- Tải chỉ giọng nói (10 files)\n- Tải hóa đơn (10 files)\n- Tải đồng thời cả hai\nTối ưu hóa\n- Tối ưu hóa Database\n- Triển khai bộ nhớ đệm\n- Tối ưu hóa bộ nhớ 24/11/2025 24/11/2025 Sprint 04 - Day 16 3 Cải thiện độ chính xác của giọng nói\n- Phân tích các trường hợp thất bại\n- Cải thiện quy tắc NLP\n- Kiểm tra lại và lặp lại\nCải thiện độ chính xác của OCR\n- Phân tích các trường hợp thất bại\n- Cải tiến theo định dạng cụ thể\n- Cải tiến nhận dạng ký tự\nCác trường hợp ngoại lệ của việc phân tích số lượng\n- Xử lý các trường hợp mơ hồ\n- Logic xác thực\n- Tổng lượng triết xuất\n- Logic xác thực tổng 25/11/2025 25/11/2025 Sprint 04 - Day 17 4 Tăng cường an ninh\n- Xác thực tải lên tệp\n- Giới hạn tỷ lệ\n- Vệ sinh đầu vào\n- Xác thực JWT\n- Bảo mật MongoDB\n- Danh sách kiểm tra bảo mật\nXử lý lỗi toàn diện\n- Try-Catch tất cả các hàm\n- Mã trạng thái HTTP thích hợp\n- Thông báo lỗi hữu ích\n- Ghi nhật ký với ngữ cảnh\nKiểm tra độ chắc chắn của giọng nói\n- Kiểm tra các tập tin bị hỏng/không hợp lệ\nKiểm tra độ bền OCR\n- Kiểm tra hình ảnh bị hỏng/không hợp lệ 26/11/2025 26/11/2025 Sprint 04 - Day 18 5 Cải tiến ghi nhật ký\n- Ghi nhật ký JSON có cấu trúc\n- Xử lý yêu cầu đăng nhập\n- Các bước xử lý nhật ký với thời gian\n- Ghi lại lỗi bằng Stack Traces\n- ID tương quan để theo dõi\nBộ sưu tập số liệu\n- Theo dõi thời gian xử lý\n- Độ chính xác và tỷ lệ lỗi\n- Lưu trữ số liệu trong MongoDB\n- Tạo API số liệu\nVoice Deployment Prep\nChuẩn bị triển khai OCR 27/11/2025 27/11/2025 Sprint 04 - Day 19 6 Kiểm tra toàn diện cuối cùng\n- Kiểm tra hồi quy đầy đủ\n- Kiểm tra tất cả các tình huống lỗi\n- Kiểm tra tích hợp giao diện người dùng\n- Kiểm tra tích hợp backend\nChất lượng mã\n- Thêm Docstrings\n- Thêm gợi ý nhập\n- Chạy Linter \u0026amp; Sửa lỗi\n- Thêm các bài kiểm tra đơn vị cho các chức năng quan trọng 28/11/2025 28/11/2025 Sprint 04 - Day 20 Kết quả đạt được tuần 12: 1. Kiểm Tra Tải và Tối Ưu Hóa Thiết Lập Load Testing:\nCài đặt công cụ kiểm tra tải (JMeter/Locust) Tạo các kịch bản kiểm tra tải (Voice, Bill, đồng thời) Thiết lập giám sát tài nguyên (CPU, RAM, Disk I/O) Chuẩn bị dữ liệu thử nghiệm Chạy Thử Nghiệm Tải:\nKiểm tra tải Voice (10 files đồng thời) Kiểm tra tải Bill OCR (10 files đồng thời) Kiểm tra tải đồng thời cả Voice và Bill Phân tích bottlenecks và điểm nghẽn Tối Ưu Hóa:\nTối ưu hóa Database queries và indexing Triển khai bộ nhớ đệm (caching) cho kết quả Tối ưu hóa bộ nhớ và garbage collection Cải thiện thời gian phản hồi API 2. Cải Thiện Độ Chính Xác Voice Accuracy:\nPhân tích các trường hợp thất bại (failure cases) Cải thiện quy tắc NLP cho tiếng Việt Kiểm tra lại và lặp lại (testing \u0026amp; iteration) Nâng cao độ chính xác nhận dạng số và danh mục OCR Accuracy:\nPhân tích các trường hợp OCR thất bại Cải tiến theo định dạng hóa đơn cụ thể Cải tiến nhận dạng ký tự đặc biệt Xử lý các trường hợp font chữ khó Xử Lý Số Lượng:\nXử lý các trường hợp mơ hồ Logic xác thực số lượng Trích xuất tổng số lượng Logic xác thực tổng tiền 3. Tăng Cường An Ninh File Security:\nXác thực tải lên tệp (file type, size validation) Giới hạn tỷ lệ (rate limiting) cho API Vệ sinh đầu vào (input sanitization) Xác thực JWT tokens Bảo mật MongoDB (authentication, authorization) Hoàn thành danh sách kiểm tra bảo mật Error Handling:\nTry-Catch toàn diện cho tất cả các hàm Mã trạng thái HTTP thích hợp Thông báo lỗi hữu ích và rõ ràng Ghi nhật ký với ngữ cảnh đầy đủ Robustness Testing:\nKiểm tra Voice với files bị hỏng/không hợp lệ Kiểm tra OCR với hình ảnh bị hỏng/không hợp lệ Xử lý graceful degradation 4. Logging và Metrics Enhanced Logging:\nGhi nhật ký JSON có cấu trúc (structured logging) Logging cho mỗi HTTP request Các bước xử lý nhật ký với timestamp Ghi lại lỗi với stack traces Correlation ID để theo dõi request flow Metrics Collection:\nTheo dõi thời gian xử lý (processing time) Độ chính xác và tỷ lệ lỗi (accuracy \u0026amp; error rates) Lưu trữ metrics trong MongoDB Tạo API endpoints cho metrics Dashboard cho monitoring 5. Deployment Preparation Chuẩn bị triển khai Voice service Chuẩn bị triển khai OCR service Docker configuration và optimization Environment variables và secrets management Health check endpoints 6. Kiểm Tra Toàn Diện và Code Quality Comprehensive Testing:\nKiểm tra hồi quy đầy đủ (full regression testing) Kiểm tra tất cả các tình huống lỗi (error scenarios) Kiểm tra tích hợp UI (frontend integration) Kiểm tra tích hợp Backend (backend integration) End-to-end testing Code Quality:\nThêm Docstrings cho tất cả functions/classes Thêm type hints (Python typing) Chạy Linter (Pylint/Flake8) và sửa lỗi Thêm unit tests cho các chức năng quan trọng Code review và refactoring Tổng kết: Tuần 12 tập trung vào hoàn thiện và production-ready hóa hệ thống AI. Đã thực hiện thành công load testing và tối ưu hóa hiệu suất, cải thiện đáng kể độ chính xác của cả Voice và OCR models. Tăng cường bảo mật toàn diện với file validation, rate limiting, JWT authentication và MongoDB security. Triển khai structured logging và metrics collection để monitoring. Nâng cao chất lượng code với docstrings, type hints, linting và unit tests. Hệ thống đã sẵn sàng cho production deployment với error handling mạnh mẽ và testing toàn diện.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]