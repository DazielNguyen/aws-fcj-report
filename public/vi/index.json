[
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Van Hoang Kha - Cloud Solutions Architec AWS User Group Leader Bach Doan Vuong - Cloud Develops Engineer AWS Community Builder Nội Dung Nổi Bật Tổng quan quản lý dịch vụ AI với từng trường hợp. Feature Engineering Train, Tune, Deploy Bring your own models. Giới thiệu \u0026amp; Tầm quan trọng của Cloud trong Data Science Các dịch vụ phổ biến cảu AWS có thể hỗ trợ được sinh viên trong quá trình train model như SageMarker Amazon Comprehend Chuyên tóm tắt phân loại dữ liệu, và giải pháp cho bài toàn xử lý ngôn ngữ tự nhiên hỗ trợ được nhiều ngôn nhữ khác nhau. Các trường hợp sử dụng thực tế của Amazon Comprehend. Xử lý tài liệu thông minh Xử lý mail hàng loạt -\u0026gt; Hướng trả lời cho người dùng tích cực hay tieuw cực Phân tích cảm xúc khách hàng Phân loại và gắn cho tag các type dữ liệu khác nhau. Phân tích tâm lý khách hàng Phân tích cho tổng đài tư vấn viên -\u0026gt; Trung tâm liên lạc Xác thực thông tin các nhân. Amazon Translate - Neurak machine translation service. Tương tự google dịch Có thể tích hợp các website làm đa ngôn ngữ Dễ tích hợp vào ứng dụng Độ chính xác cao theo từng ngữ cảnh khác nhau Amazon Texttrack Triết xuất Tổng quan về Data Science Pipeline trên AWS (S3, Glue, SageMaker). Demo 1: Xử lý và làm sạch dữ liệu từ dataset IMDb với AWS Glue. Thảo luận chuyên sâu về chi phí, hiệu năng (Cloud vs. On-premise). Hướng dẫn dự án nhỏ sau workshop để củng cố kiến thức. Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Văn Anh Duy\nSố điện thoại: 0387 883 041\nEmail: duynguyenvananh@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Trí Tuệ Nhân Tạo\nLớp: SE181823\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders (Track 2: Migration \u0026amp; Modernization)” Mục Đích Của Sự Kiện Hoàn thành quá trình di chuyển và hiện đại hóa quy mô lớn với AWS Hiện đại hóa ứng dụng bằng các công cụ hỗ trợ AI tạo sinh Thảo luận nhóm: Hiện đại hóa ứng dụng: Đẩy nhanh quá trình chuyển đổi kinh doanh Chuyển đổi VMware với công nghệ hiện đại hóa đám mây dựa trên AI Bảo mật AWS ở quy mô lớn: Từ phát triển đến sản xuất Danh Sách Diễn Giả Nguyen Van Hai - Director of Software Engineering, Techcombank Nguyen The Vinh - Co-Founder \u0026amp; CTO, Ninety Eight Nguyen Minh Nganh - AI Specialist, OCB Nguyen Manh Tuyen - Head of Data Application, LPBank Securities Nội Dung Nổi Bật 1. Tìm hiểu về các chiến lược di chuyển và hiện đại hóa quy mô lớn với AWS thông qua các nghiên cứu điển hình thực tế từ Techcombank. Hành trình hiện đại hóa của Techcombank\nAssess: Đánh giá được môi trường kiểm kê, và xác định được khoảng trống. Mobilize: Thiết lập CCoE, xác định hàng rào, xây dựng sự lưu loát của điện toán đám mây. Migrate \u0026amp; Modernize: Ưu tiên khối lượng công việc có tác động cao Reinvent: AI, tự động hóa, sản phẩm dữ liệu, mô hình doanh mới. Generative trong hiện đại hóa quy mô.\nCode Transformation: Java 8 -\u0026gt; 21, .NET -\u0026gt; .NET 8 Dependency Mapping: Lập bản đồ phụ thuộc để phân tích tự động các mối quan hệ của hệ thống. Environment Assessment: Amazon có hàng ngàn dịch vụ hiện tại hóa với AI có thể đáp ứng được cho doanh nghiệp. Giải pháp và chiến lược mà Techcombank đã ứng dụng trong việc dùng các dịch vụ của AWS.\nAmazon EKS Amazon Aurora MySQL Amazon MSK Amazon ElastiCache for Redis OSS. Tổng quan về chiến lược Modernization Strategy Blueprint. Hiện đại hóa với các công nghệ gốc của AWS.\nAlign: Tài trợ việc triển khai và động lực doanh nghiệp. | Assess: Hiểu rõ về con người, quy trình, và công nghệ | Mobilize: CoE, quản trị, đào tạo | Modernize: Replatform, refactor, rebuild | Reinvent: Data, AI và hiện đại hóa các ứng dụng cho sự đổi mới 2. Tìm hiểu về việc hiện đại hóa ứng dụng bằng các công cụ Generative AI, với những hiểu biết thực tế từ VPBank Hiện đại hóa là quá trình chuyển đổi dần dần các ứng dụng để đạt được lợi ích về tính khả dụng, khả năng mở rộng, tính linh hoạt trong kinh doanh và tối ưu hóa chi phí khi chạy trên nền tảng đám mây Top 4 trường hợp sử dụng hàng đầu - Hiện đại hóa ứng dụng với Generative AI.\nUse case 1: Streamline VMware Migration with AWS Transform for VMware\nĐẩy nhanh quá trình di chuyển và hiện đại hóa cơ sở hạ tầng với khám phá thông minh và thực thi tự động\nRút ngắn thời gian di chuyển VMware với tính năng tự động hóa thông minh của AWS Transform.\nChuyển đổi các cấu hình mạng phức tạp chỉ trong vài giờ thay vì vài tuần nhờ tính năng khám phá, ánh xạ phụ thuộc và lập kế hoạch làn sóng tự động do AWS cung cấp.\nMở rộng quy trình di chuyển của bạn với tính năng tạo nhóm bảo mật tự động, lựa chọn phiên bản EC2 thông minh và các tùy chọn triển khai linh hoạt, bao gồm cấu hình VPC dạng hub-and-spoke hoặc cấu hình VPC riêng biệt.\nCải thiện thời gian thực hiện lên đến 90%, đồng thời giảm 80% công sức thủ công.\nUse case 2: GenAl Development with AWS Serverless and Container Solutions\nXây dựng các ứng dụng GenAl sẵn sàng cho doanh nghiệp trên nền tảng AWS Serverless và Container\nAWS cung cấp hai giải pháp mạnh mẽ cho việc phát triển và triển khai ứng dụng GenAl:\nKhông máy chủ với AWS Bedrock: Phát triển và triển khai nhanh chóng các ứng dụng GenAl bằng AWS Lambda, ECS với Fargate, Step Functions và EventBridge. Lý tưởng cho chatbot, tạo tài liệu và xử lý nội dung thông minh. Tận dụng các bản cập nhật và kiến ​​trúc tham chiếu mới nhất của AWS Bedrock.\nDựa trên container với Amazon EKS: Xây dựng, đào tạo và chạy các ứng dụng GenAl trên Kubernetes, tận dụng khả năng điều phối mạnh mẽ của nó. Sử dụng các công cụ nguồn mở và dịch vụ đám mây gốc cho khối lượng công việc GenAl có khả năng mở rộng. Triển khai linh hoạt trên cả môi trường đám mây và tại chỗ với sự đổi mới liên tục từ cộng đồng OSS.\nChọn một trong hai cách tiếp cận hoặc kết hợp cả hai để phù hợp nhất với yêu cầu ứng dụng GenAl cụ thể của bạn và đẩy nhanh hành trình AI của bạn.\nUse case 3: Revolutionize NET Modernization with AWS Transform for NET\nChuyển đổi các ứng dụng Windown cũ sang Cloud-native với tự động hóa được hỗ trợ bởi AI-powered.\nHiện đại hóa các ứng dụng chạy trên Windows nhanh hơn tới 4 lần với AWS Transform for NET. Tận dụng khả năng tự động hóa của AI để phân tích các phụ thuộc, tái cấu trúc mã và tối ưu hóa cho việc triển khai Linux, đồng thời cắt giảm chi phí cấp phép tới 40%. Chuyển đổi hàng trăm ứng dụng song song với khả năng kiểm tra và xác thực tự động - từ các ứng dụng MVC cũ sang các dịch vụ WCF. Các tính năng nâng cao bao gồm hiện đại hóa Ul tự động, xử lý gói riêng và lập kế hoạch sóng thông minh, mang lại khả năng hiện đại hóa toàn diện với tốc độ vượt trội. Use case 4: Nâng cao Kỹ thuật Nền tảng với Gen Al \u0026amp; IDP\nTận dụng sức mạnh của các trợ lý thông minh như AWS Transform Developer với Nền tảng phát triển nội bộ.\nViệc mở rộng quy mô hiện đại hóa ở cấp độ doanh nghiệp đòi hỏi thời gian và đầu tư để phát triển Nền tảng Phát triển Nội bộ (IDP). Gartner dự đoán rằng đến năm 2026, 80% các tổ chức kỹ thuật phần mềm sẽ thành lập các nhóm nền tảng với tư cách là nhà cung cấp nội bộ các dịch vụ, thành phần và công cụ có thể tái sử dụng để triển khai ứng dụng.\nKhai thác sức mạnh của các trợ lý thông minh như AWS Transform Developer với IDP để:\nTạo quy trình làm việc và tự động hóa các tác vụ lặp lại.\nTìm hiểu các phương pháp hay nhất của IDP từ các tổ chức hàng đầu, chẳng hạn như Adobe, Expedia, JPMC và Goldman Sachs.\nHiểu rõ các bản thiết kế container và kiến ​​trúc tham chiếu của AWS để mang lại tốc độ và khả năng mở rộng nhanh chóng cho sáng kiến ​​hiện đại hóa quy mô doanh nghiệp.\nCác động lực hiện đại hóa phổ biến\nGiảm chi phí\nGiảm/loại bỏ chi phí bản quyền Windows \u0026amp; SQL Server Xây dựng kiến trúc khớp với tải thực tế để tối ưu chi phí Tận dụng kiến trúc ARM64 để có hiệu năng/giá thành tốt hơn Tăng tốc độ đổi mới\nTách monolith thành các dịch vụ nhỏ hơn / microservices Tận dụng công nghệ mới và các tính năng ngôn ngữ C# Tự động hóa các quy trình thủ công Cải thiện khả năng mở rộng\nMở rộng từng thành phần / dịch vụ riêng lẻ Mở rộng chi tiết với containers / serverless Thu hút và giữ chân nhân tài\n3. Nhận thông tin chuyên sâu từ các chuyên gia hàng đầu trong ngành thông qua các buổi thảo luận chuyên đề về hiện đại hóa ứng dụng .NET Framework so với đa nền tảng .NET\n.NET Framework:\nChỉ hệ điều hành Windows Phiên bản 1.0 được phát hành vào năm 2002 Phiên bản cuối cùng là 4.8*, phát hành năm 2019 Cài đặt nguyên khối - Số lượng lớn các thư viện được cài đặt cùng một lúc. EC2, Elastic Beanstalk, ECS và EKS. .NET (trước đây là .NET Core)\nĐa nền tảng (Windows, Linux, MacOS) Phiên bản 1.0 được phát hành năm 2016 Phiên bản GA hiện tại là 8.0, được phát hành vào năm 2023 Hỗ trợ nhiều phiên bản để cài đặt Hầu hết các thư viện được phân phối riêng lẻ EC2, Elastic Beanstalk, ECS, EKS, Lambda Fargate AWS Transform: Trí thông minh được phối hợp\nTrải nghiệm web thống nhất -\u0026gt; Tự động hóa đầu cuối -\u0026gt; Cơ quan chuyên trách -\u0026gt; Định hướng mục tiêu -\u0026gt; Con người trong vòng lặp -\u0026gt; Hợp tác được đơn giản hóa AWS Transform cho .NET\nLợi ích khách hàng\nGiảm chi phí vận hành lên đến 40% Loại bỏ thương mại giấy phép hệ điều hành Tiếp cận nhóm nhà phát triển lớn hơn Quy mô đám mây và hiệu suất. Lợi ích kỹ thuật\nHỗ trợ khắc phục lỗ hổng bảo mật Hỗ trợ đa nền tảng: Windows, macOS, Linux (x86-64, arm64) Tương thích với x86-64 và arm64 LightweightContainer Kiến trúc Lambda Serverless Hoàn thành nâng cấp ngôn ngữ trong vài phút thông qua Amazon Q\nĐẩy nhanh hiện đại hóa ứng dụng Nâng cấp Ngôn ngữ Tự động (Java, .NET) Giảm Nợ Kỹ thuật Tiết kiệm Chi phí và Hiệu quả Vận hành Nâng cao Lợi thế Cạnh tranh Ứng dụng Kiro: Giải pháp cho việc phát triển theo thông số kĩ thuật\nKiro giúp các nhà phát triển và nhóm kỹ thuật vận chuyển phần mềm chất lượng cao với các tác nhân AI. Kiro biến lời nhắc của bạn thành các yêu cầu rõ ràng, thiết kế hệ thống và các nhiệm vụ riêng biệt Lặp lại với Kiro trên thông số kỹ thuật và kiến ​​trúc của bạn Các tác nhân Kiro triển khai thông số kỹ thuật trong khi vẫn giúp bạn kiểm soát. Agent hook\nPhân quyền các tác vụ cho các tác nhân Al được kích hoạt khi có sự kiện như \u0026rsquo;lưu tệp' Các tác nhân tự động thực thi ở chế độ nền dựa trên các lời nhắc được xác định trước của bạn Các hook tác nhân giúp bạn mở rộng quy mô công việc bằng cách tạo tài liệu, kiểm tra đơn vị hoặc tối ưu hóa hiệu suất mã Quản lí ngữ cảnh nâng cao\nKết nối với tài liệu, cơ sở dữ liệu, API và nhiều hơn nữa với tích hợp MCP gốc Cấu hình cách bạn muốn các tác nhân Kiro tương tác với từng dự án thông qua các tệp chỉ đạo Thả một hình ảnh về thiết kế Ul của bạn hoặc một bức ảnh về buổi thảo luận kiến ​​trúc của bạn và Kiro có thể sử dụng nó để hướng dẫn việc triển khai Sức mạnh, tính linh hoạt và bảo mật\nTương thích với VS code\nKiro hỗ trợ plugin, theme và cài đặt VS Code Open VSX trong môi trường Al-ready được sắp xếp hợp lý Các mô hình Claude tiên tiến\nLựa chọn giữa các mô hình Claude Sonnet 3.7 hoặc Sonnet 4, với nhiều tùy chọn hơn sẽ sớm được bổ sung Bảo mật cấp doanh nghiệp\nKiro được xây dựng và vận hành bởi AWS Các trường hợp sử dụng\nXây dựng ứng dụng mới\nNhanh chóng chuyển từ nguyên mẫu sang mã sản xuất và triển khai, với các phương pháp hay nhất được tích hợp sẵn, bao gồm thiết kế có cấu trúc, tài liệu hướng dẫn hoặc phạm vi kiểm thử Xây dựng trên các ứng dụng hiện có\nVới thông số kỹ thuật và quản lý ngữ cảnh thông minh, Kiro giúp bạn dễ dàng tích hợp và xây dựng trên các ứng dụng hiện có mà vẫn duy trì tính nhất quán Tái cấu trúc và hiện đại hóa\nKiro hiểu rõ cơ sở mã của bạn và có thể hướng dẫn bạn chính xác trong việc tái cấu trúc hơn một triệu cơ sở mã LOC 4. Tìm hiểu về hiện đại hóa đám mây dựa trên AI dành riêng cho môi trường VMware Trạng thái tương lai của khối lượng công việc VMware của bạn\nRELOCATE: Amazon EVS | REHOST: Amazon EC2 | REPLATFORM TO CONTAINERS: Amazon ECS or Amazon EKS | REPLATFORM TO MANAGED SERVICES: Amazon RDS, Amazon FSx, Amazon WorkSpaces, and more | REFACTOR: Modern Application =\u0026gt; Áp dụng nhanh chóng, nền tảng của lợi ích đám mây và ROI nhanh....................----\u0026gt;....................Tất cả các lợi ích gốc của đám mây và ROl cao Chuyển đổi AWS cho VMware\nHiện đại hóa khối lượng công việc VMware lên Amazon EC2 với các tác nhân AI được thiết kế riêng Tự động hóa và đơn giản hóa các tác vụ chuyển đổi Giảm chi phí và phí cấp phép với Amazon EC2 Nâng cao bảo mật, khả năng mở rộng và phục hồi Thúc đẩy đổi mới với hơn 200 dịch vụ gốc của AWS Lập bản đồ công nghệ gốc từ VMware sang AWS\nMột cách tiếp cận dựa trên AI của agentic để hiện đại hóa VMware\n1. Kết nối với môi trường VMware của bạn | 2. Phân tích khối lượng công việc, sự phụ thuộc và mức độ sẵn sàng | 3. Chuyển đổi cấu hình mạng VMware sang các cấu trúc AWS gốc | 4. Tạo các kế hoạch sóng thông minh dựa trên sự phụ thuộc của ứng dụng | 5. Xác thực với nhóm của bạn, sau đó thực hiện =\u0026gt; Chuyển đổi từng bước với xác thực human-in-the-loop Lí do AWS Transform dành cho việc di chuyển sang VMware?\nChi phí thấp hơn\nLoại bỏ phí cấp phép VMware Tối ưu hóa chi phí cơ sở hạ tầng với khả năng điều chỉnh kích thước phiên bản do AI điều khiển Di chuyển nhanh hơn\nTăng tốc chuyển đổi mạng lên đến 80 lần Giảm thiểu gián đoạn, bảo toàn tính toàn vẹn của ứng dụng và đẩy nhanh quá trình chuyển đổi Cải thiện bảo mật\nTăng cường bảo mật với nền tảng đám mây gốc Di chuyển an toàn với quy trình xác thực human-in-the-loop Đổi mới ở quy mô lớn\nGiảm nợ kỹ thuật và xây dựng các ứng dụng hiện đại, có khả năng mở rộng Tích hợp liền mạch với hơn 200 dịch vụ gốc của AWS như data lakes, phân tích nâng cao và AI/ML 5. Kết nối và học hỏi trực tiếp từ các Kiến trúc sư Giải pháp AWS và các chuyên gia trong ngành Phần này các chuyên gia đưa ra những vấn đề khó khăn khi những bước đầu triển khai hiện đại hóa toàn bộ hệ thống từ on-premises lên AWS.\nHọ đưa ra những kế hoạch và chiến lược cụ thể ở từng phần, và họ chuyển những phần quan trọng nhất và thực hiện nó trước. Trong đó họ cũng tuân thủ các quy định và luật pháp hiện hành trong việc quản lí và không thu thập thông tin người dùng. Khi họ đưa lên AWS điều quan trọng nhất là họ có thể mở rộng quy mô của mình rất nhanh, và do đó họ nhận được rất nhiều lợi nhuận khi chuyển lên môi trường AWS. Và việc ứng dụng AI hiện nay rất hiệu quả trong công việc kinh doanh của họ, như anh Vinh đã ứng dụng AI trong việc nhận biết những giao dịch có khả năng lừa đảo, chống Hacker trong Blockchain. 6. Hiểu các phương pháp hay nhất về bảo mật AWS từ phát triển đến môi trường sản xuất Những Gì Học Được Khung 5 bước: Align → Assess → Mobilize → Modernize → Reinvent. GenAI-assisted modernization: code transformation (Java 8→21, .NET→8), dependency mapping, environment assessment. Ưu tiên workloads tác động cao, human-in-the-loop, đo ROI. Tư Duy Thiết Kế Problem→Pilot→Scale; ưu tiên value-first. Strangler Fig refactor từng phần; event-driven mindset. Platform thinking/IDP, security-by-design, governance sớm. Kiến Trúc Kỹ Thuật Microservices, containers (EKS/ECS/Fargate), serverless (Lambda/Step Functions/EventBridge). Data: Aurora MySQL, MSK (Kafka), ElastiCache (Redis). VMware→AWS: rehost EC2 → replatform containers/managed → refactor app. Multi-arch (x86_64 + ARM64), observability end-to-end. Chiến Lược Hiện Đại Hóa Assess/Mobilize/MM/Reinvent (Techcombank blueprint). AWS Transform: for VMware \u0026amp; .NET (tự động hóa di trú/kiểm thử/UL modernization). Cost-first: bỏ license Windows/SQL, right-size, ARM64. Scale \u0026amp; Innovate: tách monolith, automation CI/CD, adopt GenAI. Ứng Dụng Vào Công Việc Lập migration backlog theo ROI; chọn pilot nhỏ. Chuẩn hóa container baseline (EKS) + Bedrock pattern cho GenAI. Dùng Amazon Q/Transform để nâng cấp ngôn ngữ \u0026amp; refactor nhanh. Thiết kế IDP nội bộ: template dịch vụ, golden path, policy guardrails. Trải nghiệm trong event “GenAI-powered Migration \u0026amp; Modernization mang lại cái nhìn toàn diện về cách chuyển đổi ứng dụng \u0026amp; DB ở quy mô doanh nghiệp. Điểm nổi bật: demo tự động hóa di chuyển VMware/.NET, kiến trúc tham chiếu serverless–container, bài học định lượng ROI và mô hình governance thực chiến, cùng case study giúp rút ngắn thời gian di chuyển và giảm chi phí đáng kể.”\nHọc hỏi từ các diễn giả có chuyên môn cao Techcombank: vận hành theo CCoE, đo business outcomes, lộ trình 5 bước. Ninety Eight: AI chống gian lận, security posture mạnh, realtime. OCB/LPBankS: data products, automation, cloud scale an toàn. Trải nghiệm kỹ thuật thực tế Thấy rõ dependency mapping, wave planning, auto SG/EC2 sizing, hub-and-spoke VPC. Auto code upgrade, cross-platform .NET, UI modernization tự động. Ứng dụng công cụ hiện đại AWS Transform (VMware/.NET), Amazon Q (auto language upgrade). Bedrock, Lambda, ECS/Fargate, EKS, Step Functions, EventBridge. Aurora, MSK, ElastiCache, EC2; IDP tooling; Kiro (spec→tasks/agents, MCP). Kết nối và trao đổi Chốt best practices từ SA \u0026amp; ngân hàng lớn; checklist governance/security. Kết nối để mentorship, pattern reuse, đối chiếu ROI \u0026amp; benchmark. Event tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống.\nChiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống.\nCác công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại.\nModernize có chiến lược: đo lường ROI, ưu tiên theo giá trị.\nTự động hóa + GenAI rút ngắn thời gian, giảm nợ kỹ thuật.\nPlatform/IDP là đòn bẩy quy mô; security-by-default không thể thiếu.\nHuman-in-the-loop đảm bảo an toàn khi tự động hóa diện rộng.\nMột số hình ảnh khi tham gia sự kiện Hơn 400 nhà phát triển công nghệ đầy nhiệt huyết tại Thành phố Hồ Chí Minh, văn phòng AWS (Tầng 36) đã tụ họp để theo dõi phiên họp toàn thể trực tiếp từ Hà Nội, cùng chia sẻ sự phấn khích và kiến ​​thức về AWS Cloud Day Vietnam 2025\nTổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/",
	"title": "Giải thích RAG",
	"tags": [],
	"description": "",
	"content": "Định nghĩa ngắn gọn RAG (viết tắt của Retrieval-Augmented Generation) là một kỹ thuật hoặc kiến trúc phần mềm trong lĩnh vực Trí tuệ nhân tạo (AI), được thiết kế để tối ưu hóa đầu ra của một Mô hình Ngôn ngữ Lớn (LLM).\nVề mặt bản chất, RAG là sự kết hợp giữa hai cơ chế:\nCơ chế truy xuất thông tin (Information Retrieval): Tìm kiếm dữ liệu từ một nguồn kiến thức bên ngoài (External Knowledge Base) có độ tin cậy cao. Cơ chế tạo sinh văn bản (Text Generation): Sử dụng khả năng hiểu và tổng hợp ngôn ngữ của LLM để tạo ra câu trả lời tự nhiên. Mục tiêu của RAG là cung cấp cho LLM thêm ngữ cảnh (context) chính xác, cập nhật và cụ thể, giúp mô hình vượt qua giới hạn của dữ liệu huấn luyện tĩnh (static training data).\nVì sao cần RAG? Các mô hình LLM truyền thống thường gặp 3 vấn đề lớn mà RAG có thể giải quyết:\nCập nhật thông tin (Freshness): LLM không cần huấn luyện lại (Re-training) hay tinh chỉnh (Fine-tuning) mà vẫn trả lời được các thông tin mới nhất, chỉ cần cập nhật vào cơ sở dữ liệu tìm kiếm. Sở hữu dữ liệu (Proprietary Data): Cho phép AI trả lời các câu hỏi về dữ liệu riêng tư của doanh nghiệp (tài liệu nội bộ, code base, thông tin khách hàng) mà mô hình gốc không hề biết. Tính xác thực (Grounding): Giảm thiểu \u0026ldquo;ảo giác\u0026rdquo; (Hallucination - AI bịa thông tin) bằng cách buộc AI phải trích dẫn hoặc dựa trên đoạn văn bản thực tế được tìm thấy. Kiến trúc hoạt động Quy trình xử lý một câu hỏi của RAG diễn ra như sau:\nBước Tên gọi Mô tả hành động 1 Retrieval (Truy xuất) Hệ thống tìm kiếm các đoạn văn bản liên quan nhất đến câu hỏi trong kho dữ liệu (thường dùng Vector Database). 2 Augmentation (Tăng cường) Ghép câu hỏi của người dùng + Dữ liệu vừa tìm được thành một \u0026ldquo;lời nhắc\u0026rdquo; (prompt) hoàn chỉnh. 3 Generation (Tạo sinh) Gửi prompt đó cho AI (LLM) để nó tổng hợp và viết ra câu trả lời cuối cùng cho người dùng. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu tổng quan Trong bài thực hành này, chúng ta sẽ tập trung xây dựng một trợ lý AI thông minh có khả năng \u0026ldquo;đọc hiểu\u0026rdquo; và trả lời câu hỏi dựa trên dữ liệu riêng của doanh nghiệp (kỹ thuật RAG).\nMục tiêu chính là thiết lập một quy trình xử lý dữ liệu hoàn toàn tự động và không máy chủ (Serverless), bao gồm các bước:\nIngestion (Nhập liệu): Đưa tài liệu gốc vào hệ thống. Indexing (Tạo chỉ mục): Chuyển đổi văn bản thành vector và lưu trữ để tra cứu. Retrieval \u0026amp; Generation (Truy xuất \u0026amp; Tạo sinh): Cấu hình mô hình AI để tìm kiếm thông tin liên quan và trả lời câu hỏi của người dùng. 💡 Điểm nổi bật: Giải pháp này giúp bạn không cần quản lý bất kỳ hạ tầng máy chủ nào, tối ưu hóa chi phí và thời gian vận hành.\nNội dung Giải thích RAG Giới thiệu các dịch vụ "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/5.1.2-services/",
	"title": "Giới thiệu các dịch vụ",
	"tags": [],
	"description": "",
	"content": "Kiến trúc giải pháp được xây dựng dựa trên sự phối hợp của 4 thành phần dịch vụ chính sau đây:\nKnowledge Bases for Amazon Bedrock Đây là một khả năng được quản lý toàn diện (fully managed capability) giúp kết nối các Mô hình Nền tảng (Foundation Models) với nguồn dữ liệu nội bộ của doanh nghiệp.\nTự động hóa quy trình RAG: Quản lý toàn bộ luồng công việc từ đầu đến cuối (end-to-end), bao gồm nhập dữ liệu (ingestion), chia nhỏ văn bản (chunking), tạo vector (embedding) và truy xuất thông tin (retrieval). Kết nối ngữ cảnh: Giúp các ứng dụng AI trả lời câu hỏi dựa trên dữ liệu riêng tư thay vì chỉ dựa vào dữ liệu huấn luyện chung chung. Không cần quản lý hạ tầng: Loại bỏ nhu cầu tự xây dựng và duy trì các đường ống dữ liệu (data pipelines) phức tạp. Amazon Simple Storage Service (Amazon S3) Là dịch vụ lưu trữ đối tượng (object storage) với khả năng mở rộng, độ bền dữ liệu 99,999999999% (11 số 9) và bảo mật hàng đầu.\nVai trò nguồn dữ liệu (Data Source): Đóng vai trò là kho chứa \u0026ldquo;sự thật\u0026rdquo; (source of truth). Lưu trữ tài liệu: Chứa các tệp phi cấu trúc như PDF, Word, hoặc Text mà doanh nghiệp muốn AI học. Đồng bộ hóa: Knowledge Base sẽ định kỳ quét bucket S3 này để đồng bộ hóa và cập nhật kiến thức mới nhất. Amazon OpenSearch Serverless Là tùy chọn triển khai không máy chủ (serverless) của Amazon OpenSearch Service, giúp chạy khối lượng công việc tìm kiếm và phân tích mà không cần quản lý cụm (cluster).\nVai trò kho lưu trữ Vector (Vector Store): Lưu trữ các chỉ mục vector (vector embeddings) được tạo ra từ tài liệu gốc. Tìm kiếm ngữ nghĩa (Semantic Search): Thực hiện thuật toán tìm kiếm tương đồng (similarity search/k-NN) để xác định các đoạn văn bản có ý nghĩa gần nhất với câu hỏi của người dùng. Tự động mở rộng: Tự động điều chỉnh tài nguyên tính toán và lưu trữ dựa trên nhu cầu thực tế. Amazon Bedrock Foundation Models (FMs) Cung cấp quyền truy cập vào các mô hình AI hàng đầu thông qua API thống nhất. Trong kiến trúc này, chúng ta sử dụng hai loại mô hình với vai trò riêng biệt:\nEmbedding Model (Amazon Titan Embeddings v2): Chuyển đổi văn bản (tài liệu từ S3 và câu hỏi của người dùng) thành các vector số học. Giúp máy tính có thể so sánh mức độ tương đồng về ý nghĩa giữa các đoạn văn. Text Generation Model (Anthropic Claude 3): Đóng vai trò là \u0026ldquo;bộ não\u0026rdquo; suy luận. Nhận câu hỏi kèm theo thông tin ngữ cảnh đã được truy xuất từ Vector Store. Tổng hợp thông tin và sinh ra câu trả lời tự nhiên, chính xác, có kèm trích dẫn nguồn. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/5.3.1-create-kb/",
	"title": "Khởi tạo Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Chúng ta sẽ sử dụng Amazon Bedrock Wizard để thiết lập toàn bộ kiến trúc RAG. Quá trình này sẽ kết nối nguồn dữ liệu S3, mô hình Embedding và tự động khởi tạo kho lưu trữ Vector (OpenSearch Serverless).\nCác Bước Thực hiện Đăng nhập vào AWS Management Console và truy cập dịch vụ Amazon Bedrock. Trong menu bên trái, chọn Knowledge bases. Nhấp vào nút Create knowledge base ở góc trên bên phải của màn hình. Chọn Knowledge Base with vector store Bước 1: Cấu hình Knowledge Base\nTrên màn hình cấu hình đầu tiên:\nKnowledge base name: Nhập tên knowledge-base-demo Knowledge Base description - optional: Nhập Knowledge Base from AWS Overview (Phần này bạn cần mô tả dữ liệu bạn đã upload lên S3 trước đó). IAM permissions: Chọn tùy chọn Create and use a new service role. Service role name: Giữ giá trị mặc định do AWS đề xuất (bắt đầu bằng AmazonBedrockExecutionRoleForKnowledgeBase_...). Nhấp Next. Bước 2: Cấu hình Nguồn Dữ liệu\nKết nối đến S3 Bucket chứa các tài liệu:\nData source name: Nhập knowledge-base-demo S3 URI: Nhấp vào nút Browse S3. Trong cửa sổ pop-up, chọn bucket rag-workshop-demo\u0026gt; mà bạn đã tạo trong phần trước. Nhấp Choose. Giữ lại các cấu hình Default. Nhấp Next. Bước 3: Lưu trữ \u0026amp; Xử lý Đây là bước quan trọng nhất để xác định mô hình AI và vị trí lưu trữ vector:\nEmbeddings model:\nNhấp Select model. Chọn model: Titan Embeddings G1 - Text v2. Vector Store:\nVector store creation method: Chọn Quick create a new vector store - Recommended Vector store type - new: Chọn Amazon OpenSearch Serverless Lưu ý: Tùy chọn này cho phép AWS tự động tạo một cluster Amazon OpenSearch Serverless để lưu trữ dữ liệu, giúp bạn không phải quản lý cơ sở hạ tầng thủ công. Nhấp Next. Bước 4: Xem xét và Tạo Knowledge Base\nXem xét tất cả thông tin cấu hình trên trang Review. Đảm bảo các mục S3 URI và Model đều chính xác. Cuộn xuống cuối trang và nhấp vào nút Create knowledge base. Bước 5: Chờ Khởi tạo\nSau khi nhấp Create, hệ thống sẽ bắt đầu quá trình khởi tạo cơ sở hạ tầng nền cho Vector Store.\nThời gian chờ: Khoảng 2 - 5 phút. Lưu ý: Vui lòng không đóng trình duyệt trong thời gian này. Thành công: Khi màn hình hiển thị thông báo màu xanh \u0026ldquo;Knowledge base created successfully\u0026rdquo;, bạn đã hoàn thành bước này và sẵn sàng cho phần tiếp theo. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.2-prerequiste/5.2.1-model-access/",
	"title": "Kiểm tra truy cập Model",
	"tags": [],
	"description": "",
	"content": "Tổng quan Theo chính sách mới của AWS, các mô hình nền tảng (Foundation Models) thường được tự động kích hoạt. Tuy nhiên, đối với các mô hình của đối tác thứ ba như Anthropic (Claude), người dùng lần đầu tiên sử dụng tại một Region mới bắt buộc phải khai báo thông tin sử dụng (Use Case) mới có thể gọi được mô hình.\nĐảm bảo tài khoản AWS của bạn có quyền truy cập và sử dụng mô hình Anthropic Claude 3 Sonnet. Đây là bước bắt buộc để tránh lỗi AccessDenied khi Chatbot hoạt động sau này. Nếu đây là lần đầu tiên bạn sử dụng model này tại Region mới, bạn cần thực hiện khai báo mục đích sử dụng (Use Case).\nKiểm tra truy cập Chúng ta sẽ thực hiện một bài kiểm tra nhanh (Test Run) để đảm bảo tài khoản của bạn đã sẵn sàng.\nĐầu tiên ở thanh tìm kiếm, truy cập vào Amazon Bedrock.\nBước 1. Truy cập Chat Playground\nTại menu bên trái Bedrock Console, tìm mục Playgrounds. Click Chat. Bước 2. Chọn Model kiểm thử\nClick Select model (phía trên khung chat). Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet). Throughput: Chọn On-demand. Click Apply. Bước 3. Gửi tin nhắn kích hoạt\nTrong khung chat: Nhập Hello. Click Run. Quan sát kết quả: Nếu AI trả lời: Thành công (Chuyển ngay sang phần 5.2.2). Nếu hiện lỗi màu đỏ hoặc popup \u0026ldquo;Submit use case details\u0026rdquo;: Cần khai báo thông tin (Làm tiếp bước 4 bên dưới).\nBước 4. Khai báo Use Case (Chỉ thực hiện nếu gặp lỗi ở bước 3)\nClick Submit use case details (trong thông báo lỗi). Điền biểu mẫu: Company Name: Nhập Personal Learning. Industry: Chọn Technology. Intended Use: Chọn Research \u0026amp; Development. Click Submit. Đợi 1 phút, quay lại khung chat, Click Run lại tin nhắn Hello để xác nhận thành công. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với các nền tảng AWS và tìm hiểu về chương trình FCJ 2025\nTuần 2: Dịch vụ mạng trên AWS (AWS VPC, VPC Peering \u0026amp; Transit Gateway, VPN \u0026amp; Direct Connect, Elastic Load Balancing)\nTuần 3: Dịch vụ Compute VM trên AWS (Amazon EC2, Amazon Lighsail, Amazon EFS/FSX, AWS Application Migration Service (MGN) Tuần 4: Dịch vụ lưu trữ trên AWS (S3, Snow Family, Amazon Storage Gateway, Disaster Recovery on AWS, AWS Backup)\nTuần 5: Dịch vụ Bảo Mật trên AWS - \u0026ldquo;Security is job zero\u0026rdquo; (Share Responsibility Model, AWS Identify and Access Management, Amazon Cognito, AWS Organization, AWS Identify Center (SSO), AWS Key Management Service - KMS, AWS Security Hub)\nTuần 6: Dịch vụ Cơ sở dữ liệu trên AWS (Database Concepts, Amazon RDS, Amazon Aurora, Amazon Redshift, Amazon ElastiCache)\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối với những bạn trong team và làm quen với các anh chị Champion trong First Cloud Journey. Tìm hiểu về các dịch vụ của AWS đem lại cho khách hàng. Hoàn thành bài Lab cũng như kiến thức của Module 1 trong FJC 2025 Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Đọc kĩ các lưu ý, nội quy và quy định tại AWS\n- Kết nối và giao lưu với các thành viên trong team\n- Lập nhóm và lên kế hoạch học tập cũng như về timing của dự án cần chuẩn bị trong kì thực tập tại doanh nghiệp.\n- Tạo google sheet để quản lí việc học tập và cũng như theo dõi tiến độ của thành viên trong team. 08/09/2025 08/09/2025 - Documentation: https://cloudjourney.awsstudygroup.com/\n- Youtube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\n- Notes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_01/Take_notes_module_01.md 3 - Tìm hiểu về các khái niệm cơ bản:\n+ Hiểu về điện toán đám mây là gì?\n+ Lợi ích của việc sử dụng điện toán đám mây là gì?.\n+ Điều gì tạo nên sự khác biệt của AWS.\n+ Làm sao để bắt đầu một hành trình lên mây? 09/09/2025 09/09/2025 - Documentation: https://cloudjourney.awsstudygroup.com/\n- Youtube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\n- Notes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_01/Take_notes_module_01.md\" 4 - Tìm hiểu về hạ tầng toàn cầu của AWS.\n- Tìm hiểu về công cụ Quản Lý AWS Services.\n- Cách tối ưu hóa chi phí trên AWS.\n- Thực hành Lab 01:\n+ Tạo AWS account.\n+ Cài MFA cho tài khoản cũng như hiểu về MFA là gì?\n+ Tạo Admin Group và Admin User.\n+ Thử nghiệm dùng AWS Support. 10/09/2025 10/09/2025 - Documentation: https://cloudjourney.awsstudygroup.com/\n- Youtube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\n- Notes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_01/Take_notes_module_01.md\" 5 - Thực hành Lab 07:\n+ Tạo Budget\n+ Tạo Cost Budget\n+ Tạo Usage Budget\n+ Tạo RI Budget\n+ Tạo Saving Plan Budget\n+ Cách xóa tài nguyên.\n- Tìm hiểu về các dịch vụ của từng Budget\n- Và nhận biết những Budget nào phù hợp với đối tượng nào. 11/09/2025 11/09/2025 - Documentation: https://cloudjourney.awsstudygroup.com/\n- Youtube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\n- Notes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_01/Take_notes_module_01.md\" 6 - Thực hành Lab 09:\n+ Tìm hiểu các gói hỗ trợ của AWS Support\n+ Truy cập AWS Support\n+ Khởi tạo các yêu cầu hỗ trợ. 12/09/2025 12/09/2025 - Documentation: https://cloudjourney.awsstudygroup.com/\n- Youtube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\n- Notes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_02/Take_notes_module_02.md Kết quả đạt được tuần 1: Hiểu AWS là gì và các khái niệm và dịch vụ mà AWS cung cấp:\nĐiện toán đám mây. Sự khác biệt của AWS Cách để bắt đầu một hành trình lên mây Hạ tầng toàn cầu của AWS Công cụ quản lí AWS Services Cách tối ưu hóa chi phí trên AWS Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định MFA cho tài khoản Admin Group Admin User AWS Support Biết cách thiết lập các Budget:\nCost Budget Usage Budget RI Budget Saving Plan Budget Clean tài nguyên Hiểu rõ về các gói hỗ trợ và cách truy cập AWS Support\nGói Basic Gói Developer Gói Business Gói Enterprise "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Hiểu rõ AWS VPC: Nắm vững khái niệm cơ bản về VPC (Virtual Private Cloud) như một môi trường mạng logic cô lập, bao gồm các thành phần chính như Subnets (Public và Private), Route Tables, và ENI.\nKiểm soát lưu lượng và bảo mật: Học cách cấu hình các lớp bảo mật (Security Groups và NACLs) và kiểm soát đường đi của lưu lượng mạng ra/vào Internet (Internet Gateway và NAT Gateway).\nKết nối mạng phức tạp: Phân biệt và biết cách sử dụng các phương thức kết nối giữa các VPC (VPC Peering) và mô hình kết nối trung tâm (Transit Gateway).\nXây dựng môi trường Hybrid Cloud: Tìm hiểu các giải pháp kết nối mạng tại chỗ (on-premises) với AWS, bao gồm VPN (Site-to-Site) và kết nối riêng tư (AWS Direct Connect).\nPhân phối tải ứng dụng: Hiểu chức năng của Elastic Load Balancing (ELB) và phân biệt được các loại bộ cân bằng tải khác nhau (ALB, NLB, CLB, GLB) để đảm bảo tính sẵn sàng cao và khả năng mở rộng cho ứng dụng.\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Tìm hiểu về AWS Virtual Private Cloud (VPC)\n+ VPC là gì?\n+ Cấu trúc của VPC được hoạt động như thế nào?\n- Tìm hiểu về VPC-Subnets và kiến trúc của Subnet?\n- Tìm hiểu về VPC-Route Table?\n- Tìm hiểu về VPC-ENI và kiến trúc của VPC-ENI?\n- Tìm hiểu về VPC-Endpoint và kiến trúc của VPC-Endpoint?\n- Tìm hiểu về VPC-Internet Gateway và kiến trúc của VPC-Internet Gateway?\n- Tìm hiểu về VPC-NAT Gateway và kiến trúc của VPC-NAT Gateway?\n- Tìm hiểu về VPC-Security Group và kiến trúc của VPC-Security Group?\n- Tìm hiểu về VPC-NACL và kiên trúc của VPC-NACL?\n- Tìm hiểu về VPC-Flow Logs 15/09/2025 15/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_02/Take_notes_module_02.md 3 - Tìm hiểu về các dịch vụ mạng trên AWS?\n- Tìm hiểu về VPC Peering và kiến trúc của VPC Peering?\n- Tìm hiểu về Transit Gateway và kiến trúc của Transit Gateway?\n- Nắm rõ các khái niệm về dịch vụ VPN \u0026amp; Direct Connect?\n- VPN Site to Site là gì? Việc thiết lập nó như thế nào?\n- Tìm hiểu về VPN Client to Site?\n- AWS Direct Connect là gì? 16/09/2025 16/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_02/Take_notes_module_02.md 4 - Tìm hiểu về các khái niệm và tổng quan về Elastic Load Balancing? Và các loại ELB hiện nay?\n- Tìm hiểu về ELB - Application Load Balancer và kiến trúc của nó?\n- Tìm hiểu về ELB - Network Load Balancer và nắm rõ khái niệm?\n- Tìm hiểu về ELB - Classic Load Balancer và nắm rõ khái niệm?\n- Tìm hiểu về ELB - ELB - Gateway Load Balancer và kiến trúc của nó? 17/09/2025 17/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_02/Take_notes_module_02.md 5 - Lab 03 - Khởi tạo VPC\n1. Cấu hình tường lửa VPC\n2.Thực hành tạo 1 VPC\n3. Cấu hình Site to Site VPN\n- Lab 58 - System Manage - Session Manage\n1. Tạo kết nối đến máy chủ EC2\n2. Quản lí sessioin logs\n3. Sử tính năng Port Forwarding\n- Lab 19 - Thiết lập VPC Peering\n1. Cập nhật Network ACL\n2. Tạo kết nối Peering\n3. Cấu hình Route tables\n4. Kích hoạt Cross-Peer DNS 18/09/2025 18/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_02/Take_notes_module_02.md 6 - Lab 20 - Thiết lập Transit Gateway\n1. Thiết lập hạ tầng\n2. Tạo Transit Gateway -\u0026gt; Nối nhiều VPC lại với nhau\n3. Transit Gateway Attachments\n4. Tạo Route Table cho TGW\n5. Thêm Gateway vào Route Tables \u0026amp; Kiểm tra kết quả\n- Lab 10 - Hybrid DNS\n1. Thiết lập Hybrid DNS\n2. Tạo Outbound Endpoint\n3. Tạo Route 53 Resolver Rule\n4. Tạo Inbound Endpoint.\n- Nghiên cứu bổ sung về AWS Advanced Networking - Specialty Study Guid 19/09/2025 19/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_02/Take_notes_module_02.md Research Link: https://www.amazon.com/Certified-Advanced-Networking-Official-Study/dp/1119439833 Kết quả đạt được tuần 2: Giải thích được VPC là gì, vai trò của nó trong AWS, và các thành phần cốt lõi của nó (Subnet, Route Table, ENI). Phân biệt rõ ràng giữa Public Subnet (có Internet Gateway) và Private Subnet (sử dụng NAT Gateway để truy cập Internet). So sánh và đối chiếu hai cơ chế tường lửa chính: Security Group (stateful, áp dụng cho ENI) và NACL (stateless, áp dụng cho Subnet). Trình bày được cách thức kết nối riêng tư từ VPC đến các dịch vụ AWS (như S3) mà không cần qua Internet bằng VPC Endpoint. Đánh giá được ưu nhược điểm giữa hai giải pháp kết nối VPC: VPC Peering (kết nối 1:1, không hỗ trợ bắc cầu) và Transit Gateway (mô hình hub-and-spoke, đơn giản hóa quản lý). Mô tả được các phương thức thiết lập kết nối hybrid cloud, bao gồm VPN Site-to-Site (qua Internet) và AWS Direct Connect (kết nối vật lý riêng). Phân loại và lựa chọn được loại Elastic Load Balancer phù hợp cho từng kịch bản cụ thể: Application Load Balancer (ALB): Cho lưu lượng HTTP/HTTPS (Layer 7), hỗ trợ path-based routing. Network Load Balancer (NLB): Cho lưu lượng TCP/TLS (Layer 4), cần hiệu suất cực cao và IP tĩnh. Gateway Load Balancer (GLB): Dùng để tích hợp các thiết bị mạng ảo (virtual appliances). Xác định được các bài thực hành (Lab) cần thiết để củng cố kiến thức đã học về VPC, Peering, Transit Gateway và các dịch vụ liên quan. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Ứng dụng quản lý tài chính cá nhân 1. Tóm tắt điều hành Dự án Personal Finance Management App hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Ứng dụng cho phép người dùng ghi nhận thu chi, tạo và quản lý nhiều hũ tiền (money jars) theo mục đích khác nhau, lập kế hoạch chi tiêu, nhận cảnh báo thông minh và tạo báo cáo phân tích trực quan.\nỨng dụng được xây dựng với kiến trúc microservices trên nền tảng .NET và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt, khả năng mở rộng và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint), với thời gian hoàn thành MVP trong 2 tháng.\n2. Tuyên bố vấn đề Vấn đề hiện tại Trên thị trường đã có rất nhiều ứng dụng quản lý tài chính, tuy nhiên phần lớn vẫn yêu cầu người dùng nhập liệu thủ công — một công việc tốn thời gian, dễ sai sót và khiến người dùng nhanh chóng bỏ cuộc. Các ứng dụng hiện có chỉ tập trung vào thống kê chi tiêu mà chưa thực sự giúp người dùng tự động hóa quy trình quản lý tài chính cá nhân.\nGiải pháp Giải pháp sử dụng AWS Cloud kết hợp kiến trúc microservices để xây dựng một nền tảng quản lý tài chính cá nhân tự động hóa, tích hợp AI trong xử lý giọng nói và nhận diện hóa đơn. Hệ thống được triển khai trên AWS ECS Fargate cho các service backend (.NET), FastAPI cho xử lý AI, và Next.js cho frontend. So với các nền tảng tài chính phổ biến như Money Lover hay Misa Money Keeper, ứng dụng này tập trung vào tự động hóa hoàn toàn nhập liệu tài chính thông qua AI voice-to-text và bill scanning chi tiết tiếng Việt, giúp giảm thao tác thủ công và sai sót. Hệ thống phù hợp cho người dùng cá nhân và nhóm nhỏ, đồng thời có thể mở rộng khi cần cho quy mô doanh nghiệp hoặc ứng dụng ngân hàng số.\nLợi ích và hoàn vốn đầu tư (ROI) Giải pháp mang lại nhiều lợi ích thiết thực cả về mặt kỹ thuật và giá trị kinh doanh:\nTự động hóa nhập liệu: Giảm hơn 70% thao tác thủ công nhờ AI nhận diện giọng nói và hóa đơn. Tăng độ chính xác: Hạn chế sai sót nhập liệu, đảm bảo tính toàn vẹn của dữ liệu tài chính (\u0026gt;90% chính xác). Cải thiện hiệu suất người dùng: Ghi nhận và phân loại giao dịch chỉ trong vài giây, tối ưu trải nghiệm sử dụng. Tiết kiệm chi phí: Chi phí hạ tầng thấp nhờ tận dụng AWS Free Tier đến năm 2026; chỉ ước tính ~60 USD/tháng cho AWS và ~30 USD cho compute AI. Hoàn vốn nhanh: Dự kiến hoàn vốn trong 6–12 tháng, nhờ tiết kiệm thời gian nhập liệu và tăng hiệu suất vận hành. Khả năng mở rộng \u0026amp; tích hợp: Kiến trúc microservices trên AWS cho phép dễ dàng bổ sung tính năng (mobile app, phân tích nâng cao, tích hợp ngân hàng). 3. Kiến trúc giải pháp Hệ thống được triển khai theo mô hình microservices trên nền tảng AWS Cloud, kết hợp các dịch vụ serverless, container, và cơ sở dữ liệu quản lý để đảm bảo hiệu năng và khả năng mở rộng.\nNgười dùng truy cập ứng dụng web Next.js thông qua Amazon CloudFront, nội dung tĩnh được lưu trữ trong Amazon S3 và phân phối qua Amazon Route 53. Lớp bảo mật đầu tiên được cung cấp bởi AWS WAF nhằm ngăn chặn các tấn công phổ biến như SQL Injection hoặc XSS.\nKhi người dùng đăng nhập, quá trình xác thực được xử lý bởi Amazon Cognito, cấp token truy cập để frontend gửi các yêu cầu API qua Amazon API Gateway. API Gateway định tuyến yêu cầu đến Application Load Balancer (ALB) thông qua AWS PrivateLink, sau đó chuyển tiếp đến Amazon ECS (Fargate) — nơi triển khai các container backend bao gồm:\nBackend Service (.NET): Xử lý nghiệp vụ chính của hệ thống.\nAI Service (FastAPI): Xử lý hóa đơn, nhận dạng giọng nói và các tác vụ AI.\nKhi người dùng tải hóa đơn hoặc ghi âm, file tạm thời được lưu trong Amazon S3.\nAI Service có thể truy cập tệp từ Amazon S3 để thực hiện các xử lý dữ liệu, sau đó trả kết quả lại cho Backend Service thông qua message broker.\nHình ảnh container được lưu trữ trong Amazon ECR, và quá trình triển khai được tự động hóa qua GitLab CI/CD Pipeline — bao gồm các bước build image, push lên ECR, và cập nhật Task Definition trên ECS.\nTất cả logs, metrics và cảnh báo từ ECS, API Gateway, và ALB được gửi về Amazon CloudWatch để giám sát tập trung, đồng thời Amazon SNS được cấu hình để gửi cảnh báo tự động khi có sự cố.\nDịch vụ AWS sử dụng\nAmazon Route 53: Quản lý DNS và tên miền truy cập. AWS WAF: Bảo vệ hệ thống khỏi các tấn công web phổ biến. Amazon CloudFront: Phân phối nội dung tĩnh toàn cầu và tăng tốc truy cập frontend. Amazon S3: Lưu trữ website tĩnh và file người dùng (hóa đơn, ghi âm). Amazon Cognito: Xác thực và quản lý người dùng. Amazon API Gateway: Cổng vào của hệ thống, định tuyến request từ frontend đến backend. AWS PrivateLink: Tạo kết nối riêng giữa API Gateway và ALB trong VPC để tăng cường bảo mật. Application Load Balancer (ALB): Cân bằng tải giữa các container backend trên ECS. Amazon ECS (Fargate): Chạy các microservices Backend và FastAPI (AI). Amazon ECR: Kho lưu trữ image container cho ECS. Amazon CloudWatch: Giám sát logs, hiệu năng và cảnh báo hệ thống. Amazon SNS: Gửi thông báo hoặc cảnh báo khi có sự cố. GitLab CI/CD: Tự động hóa pipeline build, push và deploy container lên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai Nghiên cứu và vẽ kiến trúc: Nghiên cứu các mô hình microservices và thiết kế kiến trúc tổng thể trên AWS (bao gồm CloudFront, ECS Fargate, RDS, S3, API Gateway, Cognito) — (Tháng 1). Tính toán chi phí và điều chỉnh giải pháp: Sử dụng AWS Pricing Calculator để ước tính chi phí, tối ưu lựa chọn dịch vụ nhằm đảm bảo chi phí thấp và dễ triển khai cho người mới học — (Tháng 2–3). Phát triển, kiểm thử, triển khai: Xây dựng frontend (Next.js), backend (.NET), và AI service (FastAPI); kiểm thử tích hợp microservices, sau đó triển khai toàn bộ hệ thống lên AWS bằng ECS Fargate và thiết lập giám sát qua CloudWatch — (Tháng 3–4). Yêu cầu kỹ thuật Frontend: Ứng dụng web Next.js được lưu trữ trong Amazon S3 và phân phối qua CloudFront, giao tiếp với backend thông qua API Gateway. Người dùng đăng nhập qua Amazon Cognito, nhận token để gọi API bảo mật. Backend: Viết bằng .NET hoặc framework tương tự, triển khai trên ECS Fargate. Các service xử lý nghiệp vụ người dùng, giao dịch và các yêu cầu từ frontend. Container image được lưu trong ECR, được cập nhật qua pipeline CI/CD từ GitLab. ALB được dùng để cân bằng tải giữa các container backend. AI Service: Viết bằng FastAPI, xử lý hình ảnh hóa đơn và giọng nói, kết nối đến S3 để đọc dữ liệu. Kết quả được trả về Backend Service thông qua API nội bộ. Hạ tầng Cloud: Sử dụng Amazon VPC (multi-AZ), Application Load Balancer, và CloudWatch để giám sát. Hình ảnh container được lưu trữ trên ECR và triển khai qua ECS Fargate. CI/CD được thực hiện qua GitLab CI/CD để tự động hóa build và deploy. Bảo mật: Quản lý quyền truy cập người dùng bằng Amazon Cognito. Sử dụng IAM Roles cho ECS, S3, CloudWatch, và API Gateway để giới hạn quyền truy cập. Security Group được cấu hình chặt chẽ giữa ECS, ALB và các dịch vụ khác để đảm bảo an toàn mạng. AWS WAF được cấu hình để bảo vệ tầng frontend khỏi các tấn công web phổ biến. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch. Thực tập (Tháng 1–4): Tháng 1: Học AWS và nâng cấp kỹ năng lập trình. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3-4: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm về mobile và triển khai sau tháng thứ 5. 6. Ước tính ngân sách Bạn có thể xem chi tiết bảng dự toán chi phí bằng cách tải về các tệp sau: 📊 Tệp định dạng CSV 💾 Tệp định dạng JSON\nDịch vụ Chi Phí AWS Fargate (ECS) 17,30 USD / tháng Application Load Balancer 18,98 USD / tháng Amazon API Gateway 2,50 USD / tháng Amazon Cognito 0,00 USD / tháng Amazon ECR 1,00 USD / tháng Amazon Route 53 0,54 USD / tháng AWS WAF 7,20 USD / tháng Amazon CloudFront 2,00 USD / tháng AWS PrivateLink 10,49 USD / tháng Amazon S3 0,34 USD / tháng Tổng ước tính ≈ 60,35 USD / tháng (≈ 724,21 USD / năm) Ghi chú: Chi phí trên được tính toán dựa trên AWS Pricing Calculator cho khu vực Asia Pacific (Singapore) với giả định sử dụng cho 100 người dùng hoạt động hàng tháng và các tài nguyên cơ bản.\n7. Đánh giá rủi ro Ma trận rủi ro\nMô hình AI nhận dạng sai (voice/bill): Ảnh hưởng trung bình, xác suất trung bình. Mất kết nối AWS hoặc lỗi dịch vụ vùng (region): Ảnh hưởng cao, xác suất thấp. Vượt ngân sách sử dụng AWS: Ảnh hưởng trung bình, xác suất thấp. Lỗi đồng bộ dữ liệu giữa các microservices: Ảnh hưởng trung bình, xác suất trung bình. Lộ thông tin người dùng (Cognito/Database): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nAI: Cải thiện mô hình OCR và voice-to-text qua huấn luyện thêm, kiểm thử định kỳ với dữ liệu thực tế. AWS Region: Thiết lập triển khai đa vùng (multi-AZ) và backup định kỳ cơ sở dữ liệu RDS. Chi phí: Cấu hình AWS Budget Alert và tối ưu ECS, S3 theo mức sử dụng thực tế. Microservices: Dùng SQS/RabbitMQ để đảm bảo xử lý bất đồng bộ và retry khi lỗi. Bảo mật: Mã hóa dữ liệu (AES-256, HTTPS), kiểm soát IAM theo nguyên tắc “Least Privilege”. Kế hoạch dự phòng\nNếu AWS gặp sự cố: Tạm thời chuyển sang lưu trữ dữ liệu giao dịch cục bộ và đồng bộ lại sau khi khôi phục. Khôi phục hạ tầng bằng AWS CloudFormation hoặc IaC (Infrastructure as Code) đã lưu sẵn. Giữ bản sao cơ sở dữ liệu định kỳ (RDS snapshot) để phục hồi trong tình huống mất dữ liệu. 8. Kết quả kỳ vọng của dự án Tự động hóa nhập liệu tài chính: Ứng dụng giúp người dùng không cần nhập thủ công, chỉ cần chụp hóa đơn hoặc ghi âm giọng nói để hệ thống tự phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo tháng, và nhận gợi ý tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối giản: Giao diện web thân thiện, thiết kế hiện đại, tối ưu cho thiết bị di động và phù hợp với người mới quản lý tài chính. Hệ thống ổn định, dễ mở rộng: Kiến trúc microservices giúp dễ dàng bổ sung tính năng mới như nhắc nhở chi tiêu, phân tích dự báo AI, hoặc mở rộng sang mobile app. Nâng cao kỹ năng nhóm phát triển: Thành viên dự án tiếp cận thực tế với quy trình DevOps, triển khai CI/CD, và tối ưu ứng dụng trên nền tảng cloud. 9. Hạn chế của dự án Mô hình AI tiếng Việt còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay chưa đạt độ chính xác cao. Chưa có ứng dụng di động riêng: Phiên bản MVP chỉ hỗ trợ nền web, chưa có mobile app native. Giới hạn người dùng: Kiến trúc hiện tại chỉ tối ưu cho 50–100 người dùng hoạt động; khi mở rộng quy mô cần tái cấu trúc hạ tầng. Phụ thuộc kết nối Internet: Mọi thao tác xử lý và lưu trữ đều qua cloud, không thể hoạt động offline. Chưa triển khai hệ thống bảo mật nâng cao: Mới dừng ở xác thực Cognito và mã hóa cơ bản, chưa có MFA (Multi-Factor Authentication) hay log bảo mật chuyên sâu. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.2-prerequiste/5.2.2-prepare-data/",
	"title": "Chuẩn bị dữ liệu nguồn",
	"tags": [],
	"description": "",
	"content": "Tổng quan Khởi tạo một kho lưu trữ đối tượng (S3 Bucket) để chứa các tài liệu gốc (PDF, Word, Text). Đây đóng vai trò là \u0026ldquo;nguồn sự thật\u0026rdquo; (Source of Truth) mà Knowledge Base sẽ truy cập để đọc hiểu, phân tích và đồng bộ hóa kiến thức cho AI. Bạn có thể lưu trữ kiến thức liên quan đến lĩnh vực của bạn sử dụng trong việc tạo trợ lý cá nhân hoặc Chatbot cho riêng bạn.\nChuẩn bị dữ liệu Chúng ta sẽ tạo một S3 Bucket để lưu trữ tài liệu gốc, đóng vai trò là nguồn tri thức cho Chatbot.\nBước 1. Tạo S3 Bucket\nTruy cập dịch vụ S3 từ thanh tìm kiếm. AWS Region: Chọn United States (N. Virginia us-east-1). Click Create bucket. Cấu hình thông tin Bucket: Bucket Type: Chọn General purpose Bucket name: Nhập rag-workshop-demo Object Ownership: Giữ mặc định ACLs disabled. Block Public Access settings: Giữ mặc định (Đã chọn Block all public access). Kéo xuống cuối trang, Click Create bucket. Kiểm tra tạo S3 Bucket thành công. Bước 2. Tải lên tài liệu mẫu\nĐây tài liệu mẫu, liên quan để tổng quan về kiến thức điện toán đám mây của AWS. Bạn có thể sử dụng để chạy demo hoặc upload dữ liệu của bạn. Tệp định dạng PDF\nTại danh sách Buckets, Click vào tên bucket bạn vừa tạo. Click Upload. Tại giao diện Upload: Click Add files. Chọn file tài liệu mẫu đính kèm ở phần trên hoặc file từ máy tính của bạn (Khuyên dùng file PDF hoặc Word có nhiều nội dung văn bản). Khi upload file xong, chọn file vừa upload, kéo xuống cuối trang, Click Upload. Khi thấy thông báo màu xanh \u0026ldquo;Upload succeeded\u0026rdquo;, Click Close. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.2-prerequiste/",
	"title": "Chuẩn bị môi trường",
	"tags": [],
	"description": "",
	"content": "1. Mục tiêu Trước khi bắt tay vào xây dựng ứng dụng, chúng ta cần thiết lập một nền tảng vững chắc. Giống như việc chuẩn bị nguyên liệu trước khi nấu ăn, phần này đảm bảo rằng tài khoản AWS của bạn đã sẵn sàng với đầy đủ quyền hạn và dữ liệu cần thiết.\nTrong phần này, chúng ta sẽ hoàn thành 3 mục tiêu khởi tạo quan trọng:\nChọn Region (Vùng): Thiết lập môi trường làm việc tại vùng United States N. Virginia (us-east-1) để tối ưu hóa tốc độ kết nối và đảm bảo tính sẵn sàng của dịch vụ. Kích hoạt Model (Model Access): Kiểm tra và đảm bảo tài khoản có quyền gọi model Anthropic Claude 3 – \u0026ldquo;bộ não\u0026rdquo; ngôn ngữ chính của hệ thống. Chuẩn bị Dữ liệu (Data Setup): Khởi tạo kho lưu trữ (S3 Bucket) và tải lên tài liệu nguồn để phục vụ cho quá trình nạp kiến thức (Ingestion) sau này. 2. Các thành phần chính Trong phần chuẩn bị này, chúng ta sẽ tương tác với các thành phần sau:\nAWS Management Console (Region Selector): Giao diện quản lý chung để chuyển đổi Region làm việc sang United States N. Virginia. Amazon Bedrock (Model Access \u0026amp; Playground): Nơi quản lý quyền truy cập các mô hình nền tảng (Foundation Models) và công cụ chat để kiểm tra nhanh khả năng phản hồi của AI. Amazon S3 (Simple Storage Service): Dịch vụ lưu trữ đối tượng, nơi chúng ta sẽ tạo Bucket để chứa các file tài liệu gốc (PDF, Word, Text). 3. Các bước triển khai Kiểm tra truy cập Model Chuẩn bị dữ liệu nguồn "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/5.3.2-sync-data/",
	"title": "Kiểm tra Vector Store và Đồng bộ Dữ liệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Trước khi AI có thể trả lời, dữ liệu phải được nhập vào kho lưu trữ vector (Vector Store). Chúng ta sẽ thực hiện kiểm tra \u0026ldquo;Trước và Sau\u0026rdquo; để thấy rõ cách Bedrock tự động mã hóa và lưu trữ dữ liệu vào OpenSearch.\nCác Bước Thực hiện Bước 1: Kiểm tra Vector Store (Trạng thái Rỗng)\nChúng ta sẽ truy cập trực tiếp vào Amazon OpenSearch Serverless để xác nhận rằng chưa có dữ liệu nào tồn tại.\nTrong thanh tìm kiếm AWS Console, gõ Amazon OpenSearch Service và chọn Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Nhấp vào tên Collection mới được tạo bởi Bedrock (thường có tên dạng bedrock-knowledge-data...). Trên trang chi tiết Collection, nhấp vào nút Open Dashboard (nằm ở góc trên bên phải màn hình).\nLưu ý: Nếu được yêu cầu đăng nhập, hãy sử dụng thông tin đăng nhập AWS hiện tại của bạn. Trong giao diện OpenSearch Dashboard: Nhấp vào biểu tượng Menu (3 đường ngang) ở góc trên bên trái. Chọn Dev Tools (thường nằm ở cuối danh sách menu). Trong ngăn Console (bên trái), nhập lệnh sau để kiểm tra dữ liệu: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Nhấp vào nút Play (Run) (tam giác nhỏ bên cạnh dòng lệnh). Kết quả: Quan sát ngăn bên phải, hits -\u0026gt; total -\u0026gt; value là 0. Bước 2: Đồng bộ Dữ liệu\nBây giờ chúng ta sẽ kích hoạt Bedrock để đọc các file từ S3 và tải chúng vào OpenSearch.\nQuay lại tab Amazon Bedrock trên trình duyệt. Chọn Knowledge bases trong menu bên trái và nhấp vào tên KB bạn vừa tạo. Cuộn xuống phần Data source, đánh dấu vào ô (tick) bên cạnh tên nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Quá trình này sẽ mất 5 - 10 phút tùy thuộc vào kích thước tài liệu mẫu. Chờ cho đến khi cột Sync status chuyển từ Syncing sang Available. Bước 3: Kiểm tra lại Vector Store (Đã có Dữ liệu)\nSau khi Bedrock báo hoàn tất Sync, chúng ta quay lại kho lưu trữ để xác minh dữ liệu đã được nhập thành công.\nChuyển sang tab OpenSearch Dashboard (vẫn còn mở từ Bước 1). Trong Dev Tools, nhấp lại nút Play (Run) với lệnh cũ: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Kết quả: Phần hits -\u0026gt; total -\u0026gt; value sẽ lớn hơn 0 (ví dụ: 10, 20\u0026hellip; tùy thuộc vào số lượng đoạn văn bản). Bạn sẽ thấy chi tiết các vector (mảng số) và nội dung văn bản được lưu trữ trong trường _source. Chúc mừng! Bạn đã hoàn thành việc xây dựng \u0026ldquo;bộ não\u0026rdquo; cho AI. Dữ liệu đã được mã hóa và nằm an toàn trong Vector Database, sẵn sàng cho việc truy xuất.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Hiểu kiến thức toàn diện về các dịch vụ máy chủ ảo (Compute VM) trên AWS. Tập trung vào dịch vụ cốt lõi là Amazon EC2, bao gồm cách lựa chọn cấu hình (Instance Types), các loại lưu trữ (EBS, Instance Store), và cách tự động hóa (User data, Auto Scaling). Tìm hiểu về các các dịch vụ liên quan như Amazon Lightsail (dịch vụ chi phí thấp), các giải pháp lưu trữ file chia sẻ (EFS cho Linux và FSx cho Windows/Linux), và dịch vụ di dời ứng dụng AWS MGN để chuyển máy chủ lên AWS hoặc xây dựng Disaster Recovery. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Amazon Elastic Compute Cloud (EC2)\n- Học về kiến trúc của Amazon EC2, một dịch vụ máy chủ ảo linh hoạt, có khả năng khởi tạo nhanh và co giãn tài nguyên mạnh mẽ.\n- Tìm hiểu về kĩ thuật lựa chọn cấu hình máy chủ thông qua EC2 Instance Type, yếu tố quyết định các yếu tố như CPU, Memory, Network và Storage.\n- Học về cách sử dụng AMI (Amazon Machine Image) để khởi tạo (provision) một hoặc nhiều EC2 Instances và dùng Key Pair (public và private key) để mã hóa thông tin đăng nhập.\n- Tìm hiểu về kĩ thuật lưu trữ khối EBS (Elastic Block Store), vốn hoạt động độc lập, được replicate dữ liệu (nhân 3) để đảm bảo độ sẵn sàng và kết nối với EC2 qua mạng.\n- Phân biệt EBS với Instance Store, là vùng đĩa NVME tốc độ cực cao nhưng dữ liệu sẽ bị xóa hết khi stop EC2.\n- Học về kĩ thuật tự động hóa User Data, một đoạn script (bash shell hoặc powershell) chạy một lần khi khởi tạo EC2.\n- Tìm hiểu về Meta Data, các thông tin liên quan đến EC2 (như IP, Hostname) có thể được truy cập từ chính máy chủ đó, thường dùng cho tự động hóa.\n- Tìm hiểu về kĩ thuật EC2 Auto Scaling để tự động tăng (scale-out) hoặc giảm (scale-in) số lượng EC2 Instance dựa theo các điều kiện (scaling policy).\n- Học về các EC2 Pricing Option (On-demand, Reserved Instance, Saving Plans, Spot Instance) để tối ưu chi phí. 22/09/2025 22/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_03/Take_notes_module_03.md 3 Amazon Lightsail\n- Học về dịch vụ Amazon Lightsail, một giải pháp máy chủ ảo chi phí thấp (từ 3,5$/tháng) phù hợp cho các workload nhẹ, môi trường test/dev.\n- Tìm hiểu về kĩ thuật kết nối Lightsail (nằm trong VPC đặc biệt) với VPC thông thường qua VPC Peering (chỉ bằng 1 click).\nAmazon EFS/FSX\n- Học về EFS (Elastic File System), dịch vụ lưu trữ file mạng (NFSv4) cho phép nhiều EC2 Instance (chỉ hỗ trợ Linux) mount vào cùng lúc, tính phí theo dung lượng sử dụng.\n- Học về Amazon FSx, dịch vụ cho phép tạo NTFS volume (giao thức SMB) để gán vào nhiều EC2 Instance (hỗ trợ Windows và Linux).\n- Tìm hiểu về kĩ thuật deduplication của FSx giúp giảm trùng lặp dữ liệu và giảm chi phí lưu trữ.\nAWS Application Migration Service (MGN)\n- Học về dịch vụ AWS MGN dùng để migrate (di dời) và replicate máy chủ (thật hoặc ảo) từ on-premise lên môi trường AWS.\n- Tìm hiểu về kĩ thuật sao chép (replication) của MGN để phục vụ mục đích xây dựng Disaster Recovery Site với chi phí thấp (sử dụng các máy staging cấu hình nhỏ). 23/09/2025 23/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_03/Take_notes_module_03.md 4 Lab: 000004 - Thao tác EC2 cơ bản.\n- Tạo máy chủ EC2\n- Thực hiện snapshot EC2 Instance\n- Cài đặt ứng dụng trên EC2\nLab: 000027 - Quản lí tài nguyên bằng Tag và Resource Group\n- Sử dụng Tag\n- Sử dụng Resource Group 24/09/2025 24/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_03/Take_notes_module_03.md 5 Lab: 000008 - Quản lí tài nguyên với Amazon Cloud Watch\n- CloudWatch Agent\n- Tạo CloudWatch Dashboard\nLab: 000006 - Triển khai Autoscaling Group\n- Khởi tạo Launch Template\n- Khởi tạo Target Group\n- Khởi tạo Load Balancer\n- Khởi tạo Auto Scaling Group\n- Kiểm tra kết quả. 25/09/2025 25/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_03/Take_notes_module_03.md 6 Lab: 000045 - Bắt đầu với Amazon Lightsail\n- Chuẩn bị\n- Kiểm tra ứng dụng trên Lightsail\n- Sử dụng Lightsail Loadbalancer\n- Sử dụng RDS\n- Dịch chuyển sang EC2.\n[Nghiên cứu bổ sung] - Microsoft Workloads on AWS\n- Series các bài thực hành bố sung dành cho việc chạy các máy chủ và ứng dụng của Microsoft trên AWS\n- Bổ sung kiến thức về hệ điều hành\n- Bổ sung các kiến thức về hệ điều hành Linux như LBI1, LBI2\n- Bổ sung các kiến thức về hệ điều hành Window học thêm về hệ thống quản trị Bundo. Tham khảo các series thực hành 26/09/2025 26/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_03/Take_notes_module_03.md\nResearch Link: [https://www.youtube.com/playlist?list=PLhr1KZpdzukdJ|IxuIUM7pMB7aJ2_FfTP] Kết quả đạt được tuần 3: Dịch vụ EC2: Hiểu rõ EC2 là dịch vụ máy chủ ảo cốt lõi của AWS. Kĩ thuật cấu hình EC2: Biết cách lựa chọn Instance Type (cấu hình CPU, RAM, Network) và sử dụng AMI để khởi tạo hệ điều hành cho máy chủ. Kĩ thuật bảo mật EC2: Nắm được cách dùng Key Pair (public/private key) để mã hóa thông tin đăng nhập, thay vì dùng mật khẩu. Dịch vụ lưu trữ (Storage): Phân biệt rõ ràng 2 loại lưu trữ đĩa chính cho EC2: EBS (Elastic Block Store): Là ổ đĩa mạng, hoạt động độc lập, dữ liệu được replicate x3 trong 1 AZ (độ sẵn sàng 99.999%), có thể backup bằng snapshot. Instance Store: Là ổ đĩa vật lý (NVME) tốc độ cực cao, nhưng dữ liệu là tạm thời (sẽ bị xóa khi stop EC2), thường dùng cho cache/buffer hoặc swap. Kĩ thuật tự động hóa (Automation): Biết cách dùng User Data để chạy script 1 lần khi máy chủ khởi động (ví dụ: cài đặt web server). Hiểu Meta Data là gì và cách dùng nó để lấy thông tin (IP, hostname) của máy chủ từ bên trong chính nó, phục vụ cho các script tự động hóa. Kĩ thuật co giãn (Scaling): Nắm vững khái niệm EC2 Auto Scaling để tự động tăng (scale-out) hoặc giảm (scale-in) số lượng máy chủ theo tải (ví dụ: khi ActiveConnectionCount cao hoặc thấp). Kĩ thuật tối ưu chi phí (Pricing): Nhận biết 4 mô hình giá EC2: On-demand (theo giờ/giây, đắt nhất), Reserved Instance (cam kết 1-3 năm), Saving Plans (cam kết 1-3 năm, linh hoạt hơn), và Spot Instance (giá rẻ, tận dụng tài nguyên dư nhưng có thể bị đòi lại). Dịch vụ Lightsail: Hiểu Amazon Lightsail là dịch vụ VM chi phí thấp, đơn giản hóa, phù hợp cho workload nhẹ, và biết cách peering nó với VPC. Dịch vụ lưu trữ file (File Storage): Phân biệt 2 dịch vụ lưu trữ file chia sẻ cho nhiều máy chủ: EFS (Elastic File System): Dùng cho Linux (giao thức NFSv4), tính phí theo dung lượng sử dụng. FSx: Dùng cho Windows/Linux (giao thức SMB), hỗ trợ tính năng deduplication để giảm chi phí. Dịch vụ di dời (Migration): Hiểu AWS MGN là dịch vụ để di dời máy chủ từ on-premise lên AWS hoặc dùng để xây dựng hệ thống Disaster Recovery (DR) với chi phí thấp thông qua staging area. Thực hành: Nắm được các bước thực hành cơ bản với EC2 (tạo, snapshot), triển khai một cụm Auto Scaling Group hoàn chỉnh (với Load Balancer), và làm quen với Lightsail. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/",
	"title": "Tạo và Cấu hình Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Sau khi hoàn thành việc chuẩn bị môi trường và dữ liệu, bước tiếp theo là thiết lập thành phần cốt lõi của kiến trúc RAG. Trong phần này, chúng ta sẽ khởi tạo Knowledge Base, đóng vai trò là cơ chế trung gian thông minh kết nối các nguồn dữ liệu phi cấu trúc với khả năng suy luận của các foundation models.\nChúng ta sẽ thực hiện 3 mục tiêu kỹ thuật chính:\nThiết lập Pipeline Tự động: Cấu hình Knowledge Base để tự động hóa toàn bộ quy trình xử lý dữ liệu RAG (bao gồm trích xuất, phân đoạn văn bản và tạo vector) nhằm loại bỏ các tác vụ xử lý thủ công. Khởi tạo Vector Store: Triển khai một collection trên Amazon OpenSearch Serverless để lưu trữ các vector ngữ nghĩa, phục vụ việc truy xuất thông tin chính xác và hiệu quả. Đồng bộ hóa Dữ liệu (Data Ingestion): Thực hiện quy trình nhập dữ liệu ban đầu, chuyển đổi các tài liệu tĩnh từ S3 thành các vector có thể tìm kiếm trong hệ thống. Các Thành phần Chính Trong quá trình cấu hình này, chúng ta sẽ tương tác và kết nối các dịch vụ sau:\nKnowledge Bases for Amazon Bedrock: Dịch vụ được quản lý đóng vai trò là bộ điều phối luồng dữ liệu, kết nối các nguồn thông tin và thực thi các truy vấn ngữ nghĩa. Amazon Titan Embeddings G1 - Text v2: Mô hình chuyên dụng để chuyển đổi dữ liệu văn bản thành các vector số (Embeddings) với độ chính xác cao và hỗ trợ đa ngôn ngữ. Amazon OpenSearch Serverless: Cơ sở dữ liệu vector được quản lý hoàn toàn, chịu trách nhiệm lưu trữ và thực thi các thuật toán tìm kiếm tương đồng (k-NN). Các Bước Thực hiện Khởi tạo Knowledge Base Kiểm tra Vector Store và Đồng bộ Dữ liệu "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Tìm hiểu kiến thức toàn diện về các dịch vụ lưu trữ đa dạng trên AWS. Tập trung sâu vào dịch vụ cốt lõi là Amazon S3 (Simple Storage Service), một dịch vụ lưu trữ đối tượng, bao gồm các đặc tính (như độ bền 11 số 9, nhân bản 3 AZ), các lớp lưu trữ (Storage Classes). Học về các tính năng quan trọng như quản lý vòng đời (Lifecycle Management), Versioning (lập phiên bản), và Static Website Hosting. Các giải pháp di dời dữ liệu quy mô lớn (dòng Snow Family), giải pháp lưu trữ hybrid kết nối on-premise với cloud (Storage Gateway), dịch vụ quản lý sao lưu tập trung (AWS Backup), và các khái niệm, chiến lược cơ bản về Disaster Recovery (DR). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Amazon Simple Storage Service - S3\n- Học về kiến trúc của Amazon S3, một dịch vụ lưu trữ dạng đối tượng (object), phù hợp với dữ liệu ghi một lần đọc nhiều lần (WORM).\n- Tìm hiểu về kĩ thuật nhân bản dữ liệu tự động trên 3 AZ trong 1 Region để đảm bảo độ sẵn sàng cao.\n- Tìm hiểu về độ bền (durability) của S3 được thiết kế lên đến 99.999999999% (11 số 9).\n- Tìm hiểu về kĩ thuật upload (HTTP PUT) và truy cập (HTTP GET) dữ liệu S3 thông qua REST API.\n- Học về kiến trúc của các lớp lưu trữ (Storage Class), bao gồm S3 Standard, S3 Standard IA, S3 Intelligent Tiering, S3 One Zone IA, và Amazon Glacier/Deep Archive.\n- Tìm hiểu về kĩ thuật quản lý vòng đời (Object Life Cycle Management) để tự động di chuyển object giữa các lớp lưu trữ theo thời gian.\n- Tìm hiểu về kĩ thuật host Static Website (phù hợp cho Single Page Application) và cấu hình CORS (Cross-origin resource sharing).\n- Tìm hiểu về kĩ thuật kiểm soát truy cập (Control Access) bằng S3 Access Control List (ACL) (gắn vào bucket/object) và S3 Bucket Policy (dễ quản lý hơn).\n- Học về kiến trúc của S3 Endpoint, cho phép truy cập S3 bucket thông qua mạng riêng của AWS mà không cần Internet.\n- Tìm hiểu về kĩ thuật Versioning (lập phiên bản) để khôi phục đối tượng sau khi vô tình xóa hay ghi đè, và hỗ trợ chống ransomware.\n- Tìm hiểu về kĩ thuật tối ưu hiệu năng (performance) S3 bằng cách dùng random prefix (tiền tố ngẫu nhiên) cho object key, giúp S3 lưu trữ object trên nhiều partition.\n- Học về kiến trúc của S3 Glacier, dịch vụ lưu trữ chi phí thấp, dài hạn, yêu cầu phải retrieve (truy xuất) dữ liệu (Expedited, Standard, Bulk) về S3 Bucket trước khi sử dụng. 29/09/2025 29/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_04/Take_notes_module_04.md 3 Snow Family\n- Học về các dịch vụ Snow Family (Snowball, Snowball Edge, Snowmobile) dùng để di dời (migrate) dữ liệu quy mô PetaByte (PB) đến Exabyte (EB) từ on-premise lên AWS (S3 hoặc Glacier).\n- Tìm hiểu về kĩ thuật của Snowball Edge là thiết bị đặc biệt có sẵn tài nguyên tính toán (compute) để xử lý dữ liệu local.\nAmazon Storage Gateway\n- Học về kiến trúc của AWS Storage Gateway, một giải pháp lưu trữ Hybrid kết hợp dung lượng lưu trữ trên AWS với on-premise.\n- Tìm hiểu về kĩ thuật của ba loại gateway:\n+ File Gateway: Cho phép lưu trữ file lên S3 qua giao thức NFS và SMB.\n+ Volume Gateway: Cung cấp lưu trữ dạng khối (block storage) qua iSCSI, dữ liệu được lưu trên S3.\n+ Tape Gateway: Cung cấp thư viện băng từ ảo (VTL) iSCSI, lưu dữ liệu tape ảo vào S3 hoặc Glacier. 30/09/2025 30/09/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_04/Take_notes_module_04.md 4 Disaster Recovery on AWS\n- Tìm hiểu về kĩ thuật\u0026hellip; thiết kế Disaster Recovery (DR) dựa trên hai chỉ số chính:\n+ RTO (Recovery Time Objective): Thời gian cần thiết để phục hồi dịch vụ.\n+ RPO (Recovery Point Objective): Khoảng thời gian tối đa mà dữ liệu có thể bị mất.\n- Học về 4 chiến lược DR trên AWS: Sao lưu và khôi phục, Pilot Light, Low Capacity Active-Active, và Full Capacity Active-Active.\nAWS Backup\n- Học về dịch vụ AWS Backup, một dịch vụ quản lý tập trung, cho phép cấu hình và lập lịch (schedule), chính sách lưu giữ (retention) cho việc sao lưu nhiều tài nguyên AWS (EBS, EC2, RDS, EFS, Storage Gateway\u0026hellip;). 01/10/2025 01/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_04/Take_notes_module_04.md 5 Lab: 000057 - Khởi đầu với Amazon S3\n- Tạo S3 Bucket\n- Upload dữ liệu trên S3\n- Host static website trên S3\nLab: 000013 - AWS Backup\n- Chuẩn bị hạ tầng\n- Khởi tạo Backup Plan\n- Thiết lập Notification\n- Kiểm tra hoạt động\nLab: 000014 - AWS Import/Export\n- Chuẩn bị máy ảo\n- Import máy ảo lên AWS\n- Export máy ảo từ AWS 02/10/2025 02/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_04/Take_notes_module_04.md 6 Lab: 000024 - Storage Gateway\n- Khởi tạo Storage Gateway\n- Khởi tạo File Sharing\n- Kết nối File Share với máy\nLab: 000025 - FSX\n- AWS Managed MS AD\n- Triển khai Instance\n- Thiết lập và sử dụng FSx\n[Nghiên cứu bổ sung] - AWS Skill Builder\n- Series các bài lý thuyết chuyên sâu cho chuyên gia lưu trữ trên AWS.\n- Storage Learning Plan: Block Storage\n- Storage Learning Plan: Object Storage 03/10/2025 03/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_04/Take_notes_module_04.md\nResearch Link: https://explore.skillbuilder.aws/ Kết quả đạt được tuần 4: Dịch vụ S3 (Cơ bản): Hiểu rõ Amazon S3 là dịch vụ lưu trữ đối tượng (object storage), không phải lưu trữ khối, hoạt động theo mô hình WORM (Ghi 1 lần, đọc nhiều lần). Bài học về Độ bền (Durability): Nắm được S3 được thiết kế cho độ bền 11 số 9 (99.999999999%) bằng cách tự động nhân bản dữ liệu trên 3 Availability Zone (AZ). Kĩ thuật Tối ưu chi phí S3: Phân biệt được các lớp lưu trữ (Storage Classes) như S3 Standard (truy cập thường xuyên), S3 Standard IA (không thường xuyên), và S3 Glacier (lưu trữ dài hạn, chi phí thấp, phải retrieve). Kĩ thuật Tự động hóa S3: Biết cách dùng Object Life Cycle Management để tự động chuyển dữ liệu xuống các lớp rẻ hơn (ví dụ: từ Standard sang Glacier) theo thời gian. Hiểu về Trigger Event (ví dụ: kích hoạt serverless function khi upload file). Kĩ thuật Bảo mật S3: Phân biệt hai cơ chế kiểm soát truy cập: S3 ACL (cơ chế cũ) và S3 Bucket Policy (dễ dàng xác định quyền truy cập hơn). Bài học về Bảo vệ Dữ liệu (S3): Hiểu rõ tính năng Versioning (lập phiên bản) cho phép khôi phục lại các phiên bản cũ của file, giúp chống xóa nhầm hoặc tấn công ransomware. Kĩ thuật Mạng S3: Nắm được cách dùng S3 Endpoint để truy cập S3 từ trong VPC qua mạng riêng của AWS mà không cần Internet. Biết cách host Static Website trên S3 và cấu hình CORS. Dịch vụ Di dời Dữ liệu (Migration): Nhận biết dòng Snow Family (Snowball, Snowmobile) là giải pháp di dời dữ liệu vật lý quy mô lớn (Petabyte, Exabyte) từ on-premise. Dịch vụ Lưu trữ Hybrid: Hiểu Storage Gateway là giải pháp lưu trữ lai, cho phép các ứng dụng on-premise sử dụng các giao thức (NFS, SMB, iSCSI) để lưu trữ dữ liệu lên S3/Glacier. Bài học về Disaster Recovery (DR): Nắm được 2 khái niệm cơ bản để thiết kế DR là RTO (thời gian phục hồi) và RPO (lượng dữ liệu chấp nhận mất). Dịch vụ Sao lưu (Backup): Biết AWS Backup là dịch vụ quản lý tập trung, giúp tự động hóa việc sao lưu (schedule, retention) cho nhiều tài nguyên AWS (EBS, RDS, EFS\u0026hellip;). Thực hành: Nắm được các bước thực hành tạo S3 bucket, host website tĩnh, và cấu hình AWS Backup. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.4-test-chatbox/",
	"title": "Kiểm thử Chatbot (RAG)",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Sau khi đã nhập dữ liệu thành công vào Vector Store, đã đến lúc xác minh kết quả. Trong phần này, bạn sẽ đóng vai trò là người dùng cuối, đặt câu hỏi cho Chatbot trực tiếp trong giao diện AWS Console để quan sát cách hệ thống RAG hoạt động.\nChúng ta sẽ tập trung vào 2 yếu tố:\nĐộ chính xác: AI có trả lời đúng dựa trên tài liệu không? Tính minh bạch: AI có thể trích dẫn nguồn (Citation) của thông tin không? Các Bước Thực hiện Bước 1: Cấu hình cửa sổ kiểm thử\nĐể bắt đầu trò chuyện, chúng ta cần chọn một Foundation Model sẽ đóng vai trò là \u0026ldquo;người trả lời\u0026rdquo;.\nTrong giao diện chi tiết Knowledge Base của bạn, hãy xem bảng điều khiển bên phải có tiêu đề Test knowledge base. Nhấp vào nút Select model.\nTrong bảng điều khiển lựa chọn xuất hiện: Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet / Haiku tùy thuộc vào model bạn đã kích hoạt). Throughput: Giữ nguyên On-demand. Nhấp Apply. Bước 2: Tiến hành hội thoại (Chat)\nBây giờ, hãy thử đặt một câu hỏi liên quan đến nội dung tài liệu bạn đã tải lên.\nTrong ô nhập liệu (Message input), gõ câu hỏi của bạn. Ví dụ: Nếu bạn đã tải lên tài liệu \u0026ldquo;Quy trình Nghỉ phép\u0026rdquo;, hãy hỏi: \u0026ldquo;Tôi cần làm gì để xin nghỉ 3 ngày?\u0026rdquo;. Nhấp Run. Quan sát kết quả: AI sẽ suy nghĩ trong vài giây (truy vấn Vector Store). Sau đó, nó sẽ trả lời bằng ngôn ngữ tự nhiên, tóm tắt thông tin tìm được. Bước 3: Xác minh nguồn dữ liệu\nĐây là tính năng quan trọng nhất của RAG giúp phân biệt với ChatGPT thông thường: khả năng chứng minh nguồn thông tin.\nTrong câu trả lời của AI, hãy chú ý đến các số nhỏ (chú thích) hoặc văn bản Show source details. Nhấp vào các số đó hoặc nút chi tiết. Một cửa sổ Source details sẽ xuất hiện, hiển thị: Source chunk: Đoạn văn bản gốc chính xác mà AI tìm thấy trong tài liệu. Score: Điểm tương đồng (mức độ liên quan). S3 Location: Đường dẫn đến file gốc. Việc nhìn thấy đoạn văn bản gốc này chứng minh rằng AI không \u0026ldquo;ảo tưởng\u0026rdquo; mà đang thực sự đọc tài liệu của bạn.\nBước 4: Kiểm thử với câu hỏi không liên quan (Tùy chọn)\nĐể xem hệ thống phản ứng như thế nào khi không tìm thấy thông tin.\nĐặt một câu hỏi hoàn toàn không liên quan đến tài liệu. Ví dụ: \u0026ldquo;Ai là người đầu tiên đặt chân lên mặt trăng?\u0026rdquo; (Trong khi tài liệu của bạn là về Tài chính). Kết quả mong đợi: AI có thể trả lời dựa trên kiến thức tổng quát của nó (nếu không bị hạn chế). HOẶC AI sẽ trả lời \u0026ldquo;Xin lỗi, tôi không thể trả lời câu hỏi của bạn dựa trên dữ liệu truy xuất được\u0026rdquo; - Đây là hành vi lý tưởng cho một ứng dụng RAG doanh nghiệp. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Tìm hiểu kiến thức nền tảng và các dịch vụ cốt lõi về bảo mật trên AWS, xoay quanh triết lý \u0026ldquo;Security is job zero\u0026rdquo;. Bắt đầu với khái niệm cơ bản nhất là Mô hình chia sẻ trách nhiệm (Share Responsibility Model). Tập trung sâu vào việc quản lý định danh và quyền truy cập (Identify and Access Management - IAM), bao gồm các thành phần: User, Group, Policy, và Role. Mở rộng tìm hiểu thêm các dịch vụ quản lý định danh ở quy mô lớn hơn như AWS Organizations (quản lý nhiều tài khoản), AWS Identity Center (SSO) (đăng nhập một lần), và Amazon Cognito (quản lý người dùng cho ứng dụng web/di động). Nắm rõ kiến thức về bảo vệ dữ liệu thông qua mã hóa với AWS KMS và giám sát, kiểm tra tuân thủ với AWS Security Hub. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Share Responsibility Model\n- Học về Mô hình chia sẻ trách nhiệm, trong đó AWS chịu trách nhiệm bảo mật của đám mây (hạ tầng vật lý, software nền tảng) và khách hàng chịu trách nhiệm bảo mật trong đám mây (cấu hình, dữ liệu, ứng dụng).\n- Tìm hiểu về sự thay đổi trách nhiệm bảo mật tùy thuộc vào loại hình dịch vụ (hạ tầng, quản lý kết hợp, hay quản lý hoàn toàn).\nAWS Identify and Access Management (IAM)\n- Tìm hiểu về Root Account, tài khoản có toàn quyền tuyệt đối, và các best practice để bảo vệ nó (tạo IAM Admin User để dùng thay thế, khóa root credentials).\n- Học về IAM User, một thực thể (principal) dùng để tương tác với AWS, khi mới tạo mặc định không có bất cứ quyền gì.\n- Tìm hiểu về kĩ thuật quản lý user hiệu quả bằng cách gom nhiều IAM User vào chung một IAM Group.\n- Học về IAM Policy, một văn bản JSON định nghĩa quyền hạn, bao gồm 2 loại:\n+ Identity-based Policy: Gán trực tiếp cho một IAM Principal (User, Group, Role).\n+ Resource-based Policy: Gán trực tiếp vào một tài nguyên (ví dụ: S3 Bucket Policy).\n- Tìm hiểu về kĩ thuật đánh giá quyền của IAM, trong đó một Deny tường minh (explicit deny) luôn luôn được ưu tiên, bất kể có policy Allow nào khác.\n- Học về kiến trúc của IAM Role, một tập hợp quyền (policy) mà không đi kèm credentials (mật khẩu/access key) vĩnh viễn.\n- Tìm hiểu về kĩ thuật Assume Role: Một IAM User (hoặc Service) sử dụng dịch vụ AWS STS (Security Token Service) để tạm thời \u0026ldquo;đảm nhận\u0026rdquo; quyền của IAM Role và nhận về thông tin chứng thực tạm thời.\n- Tìm hiểu về ứng dụng thực tế của IAM Role, ví dụ cấp quyền cho dịch vụ EC2 truy cập vào S3 mà không cần lưu trữ access key trên máy chủ. 06/10/2025 06/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_05/Take_notes_module_05.md 3 Amazon Cognito\n- Học về Amazon Cognito, dịch vụ quản lý xác thực (đăng nhập, đăng ký) và cấp phép cho người dùng cuối của các ứng dụng web và di động (khác với IAM User là người quản trị AWS).\n- Tìm hiểu về hai thành phần chính của Cognito:\n+ User Pool: Thư mục quản lý người dùng, hỗ trợ đăng nhập trực tiếp hoặc qua các bên thứ ba (Facebook, Google).\n+ Identity Pool: Cấp cho người dùng ứng dụng quyền truy cập (thường là tạm thời) vào các dịch vụ AWS khác.\nAWS Organization\n- Học về AWS Organizations, dịch vụ giúp quản lý và điều hành tập trung nhiều tài khoản AWS.\n- Tìm hiểu về kĩ thuật Consolidated Billing (thanh toán tập trung) cho tất cả tài khoản.\n- Tìm hiểu về kĩ thuật gom các tài khoản vào OU (Organization Unit) và áp dụng Service Control Policies (SCP) để giới hạn quyền tối đa mà các IAM User/Role trong tài khoản đó có thể thực hiện (kể cả deny-based).\nAWS Identify Center (SSO)\n- Học về AWS Identity Center (SSO), dịch vụ giúp quản lý quyền truy cập tập trung (đăng nhập một lần) vào tất cả các tài khoản AWS trong Organization và các ứng dụng bên ngoài.\n- Tìm hiểu về kĩ thuật sử dụng Permission Set (một bộ quyền được lưu trữ trong Identity Center) để gán cho User/Group. Khi user truy cập 1 tài khoản, Permission Set sẽ được cấp dưới dạng một IAM Role trong tài khoản đó. 07/10/2025 07/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_05/Take_notes_module_05.md 4 AWS Key Management Service (KMS)\n- Học về AWS KMS, dịch vụ tạo và quản lý các khóa mã hóa (encryption key) để bảo vệ dữ liệu ở trạng thái nghỉ (Encryption at rest).\n- Tìm hiểu về\u0026hellip; CMK (Customer Managed Key) (khóa chính nằm trong KMS) và Data Key (khóa dùng để mã hóa/giải mã dữ liệu thực tế, được tạo ra bởi CMK).\nAWS Security Hub\n- Học về AWS Security Hub, dịch vụ kiểm tra bảo mật liên tục, dựa trên các best practices của AWS và tiêu chuẩn ngành (như PCIDSS).\n- Tìm hiểu về cách Security Hub cung cấp kết quả dưới dạng điểm số và xác định các tài nguyên cần chú ý.\nLab: 000002 - Bắt đầu với IAM và IAM Role\n- IAM Group và IAM User\n- Tạo IAM Role\n- Assume Role\nLab: 000044 - IAM Role và Condition\n- Giới thiệu về IAM\n- Tạo User quản trị EC2\n- Tạo User quản trị RDS\n- Tạo Group quản trị-Cấu hình IAM Role Condition\n- Tạo IAM Role có quyền Admin 5.2 Tạo IAM User 5.3 Cấu hình Switch role 5.4 Giới hạn IP 5.5 Giới hạn theo thời gian.\n08/10/2025 08/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_05/Take_notes_module_05.md 5 Lab: 000048 - IAM Role và Application\n- Sử dụng access key\n- IAM Role trên EC2\nLab: 000030 - IAM Permission Boundary\n- Giới thiệu IAM Permission Boundary\n- Tạo Policy giới hạn\n- Tạo IAM User giới hạn quyền\n- Kiểm tra User bị giới hạn\nLab: 000027 - Tag và Resource Groups\n- Sử dụng thẻ\n- Sử dụng thẻ bằng Console\n- Hiển thị các thẻ\n- Thêm hoặc xóa thẻ\n- Gắn thẻ cho một máy ảo\n- Lọc tài nguyên theo thẻ\n- Sử dụng thẻ bằng CLI\n- Resource Group\nLab: 000028 - Quản lý EC2 qua Resource Tag\n- Tạo IAM Policy\n- Tạo IAM Role\n- Kiểm tra IAM Role 09/10/2025 09/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_05/Take_notes_module_05.md 6 Lab: 000018 - Sử dụng AWS Security Hub\n- Các tiêu chuẩn bảo mật\n- Kích hoạt Security HUb\n- Điểm từng bộ tiêu chuẩn\nLab: 000012 - Sử dụng AWS SSO\n- Các bước chuẩn bị\n- Tạo AWS Account trong AWS Organizations\n- Thiết lập Organization Unit\n- Thiết lập AWS SSO\n- Kiểm tra\nLab: 000033 - KMS Workshop\n- Thiết lập môi trường\n- Bắt đầu với AWS KMS\n- Mã hóa với AWS KMS\n- Key Policy và các best practices\n- Giám sát việc sử dụng AWS KMS.\n[Nghiên cứu bổ sung] - AWS Certified Security Special All-in-One-Exam Guide (Exam SCS-C01)\n- Tài liệu học để thi chúng chỉ Security Specialty 10/10/2025 10/10/2025 \u0026ldquo;Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_05/Take_notes_module_05.md\nResearch Link: [https://www.amazon.com/Certified-Security-Specialty-Guide-SCS-C01/dp/1260461726]\u0026rdquo; Kết quả đạt được tuần 5: Bài học Nền tảng: Nắm vững Mô hình chia sẻ trách nhiệm (Share Responsibility Model), hiểu rõ đâu là trách nhiệm của AWS và đâu là của khách hàng. Dịch vụ IAM (Cốt lõi): Phân biệt rõ ràng Root Account (toàn quyền, cần khóa lại) và IAM User (dùng hàng ngày, mặc định không có quyền). Nắm vững 3 thành phần chính để cấp quyền: IAM User (đối tượng), IAM Policy (giấy phép - viết bằng JSON), và IAM Group (nhóm các đối tượng). Hiểu rõ IAM Role: một cơ chế cấp quyền tạm thời (không có credentials vĩnh viễn) cho cả User và Service (như EC2). Kĩ thuật IAM (Quan trọng): Biết cách một User/Service \u0026ldquo;nhận\u0026rdquo; quyền của Role thông qua kĩ thuật Assume Role (sử dụng dịch vụ STS). Hiểu quy tắc đánh giá quyền: Explicit Deny (Deny tường minh) luôn thắng mọi quyền Allow. Dịch vụ Quản lý Định danh (Identity Services): Phân biệt rõ IAM (quản lý người quản trị AWS) và Amazon Cognito (quản lý người dùng cuối của ứng dụng web/mobile). Biết Cognito User Pool là thư mục người dùng (có thể login bằng Facebook, Google) và Identity Pool là nơi cấp quyền cho user đó truy cập tài nguyên AWS. Dịch vụ Quản lý Đa tài khoản (Multi-Account): Hiểu AWS Organizations dùng để quản lý tập trung nhiều tài khoản, cho phép Consolidated Billing (thanh toán gộp). Biết dùng Service Control Policies (SCP) trong Organization để giới hạn quyền tối đa của các tài khoản con. Nắm được AWS Identity Center (SSO) là giải pháp đăng nhập một lần, sử dụng Permission Set để cấp quyền vào các tài khoản trong Organization. Dịch vụ Mã hóa (Encryption): Biết AWS KMS là dịch vụ để tạo và quản lý khóa mã hóa. Hiểu cơ chế mã hóa Encryption at rest và phân biệt được CMK (khóa chính trong KMS) với Data Key (khóa dùng để mã hóa dữ liệu thực tế). Dịch vụ Giám sát Bảo mật (Monitoring): Biết AWS Security Hub là dịch vụ quét và chấm điểm bảo mật, giúp kiểm tra tuân thủ (compliance) theo các tiêu chuẩn (như PCIDSS). Thực hành: Thực hành tạo và quản lý User, Group, Policy, Role. Thực hành triển khai SSO và KMS. Thực hành sử dụng các tính năng nâng cao của IAM như Conditions và Permission Boundary. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.5-client-integration/",
	"title": "Tích hợp ứng dụng Client (Tùy chọn)",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Bạn sẽ biến dòng code Python thành một Giao diện Web Chatbot (GUI) chuyên nghiệp, thân thiện với người dùng cuối (tương tự như giao diện ChatGPT) chỉ trong vài phút.\nChúng ta sử dụng:\nBackend: AWS CloudShell. Frontend: Streamlit. AI Model: Claude 3.5 Sonnet. Các bước thực hiện Bước 1: Khởi động CloudShell\nTại thanh menu trên cùng của AWS Console, click vào biểu tượng CloudShell \u0026gt;_. Đợi terminal khởi động. Bước 2: Cài đặt thư viện và chuẩn bị code\nCài đặt thư viện pip install streamlit boto3 Tạo file: nano app.py Dán đoạn code sau (Nhớ thay KB_ID của bạn): import streamlit as st import boto3 # --- CẤU HÌNH --- # TODO: Thay thế ID bên dưới bằng Knowledge Base ID của bạn KB_ID = \u0026#34;THAY_ID_CUA_BAN_VAO_DAY\u0026#34; MODEL_ARN = \u0026#34;arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0\u0026#34; # Khởi tạo Client kết nối AWS client = boto3.client(service_name=\u0026#39;bedrock-agent-runtime\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;) st.set_page_config(page_title=\u0026#34;Trợ lý AI Doanh Nghiệp\u0026#34;) st.title(\u0026#34;🤖 Chat với Tài Liệu Riêng\u0026#34;) # Khởi tạo lịch sử chat if \u0026#34;messages\u0026#34; not in st.session_state: st.session_state.messages = [] # Hiển thị lịch sử chat lên màn hình for message in st.session_state.messages: with st.chat_message(message[\u0026#34;role\u0026#34;]): st.markdown(message[\u0026#34;content\u0026#34;]) # Xử lý khi người dùng nhập câu hỏi if prompt := st.chat_input(\u0026#34;Hỏi gì đó về tài liệu của bạn...\u0026#34;): # 1. Hiển thị câu hỏi người dùng st.chat_message(\u0026#34;user\u0026#34;).markdown(prompt) st.session_state.messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: prompt}) # 2. Gọi AI xử lý with st.chat_message(\u0026#34;assistant\u0026#34;): message_placeholder = st.empty() message_placeholder.markdown(\u0026#34;⏳ Đang đọc tài liệu...\u0026#34;) try: # Gọi API RetrieveAndGenerate của Bedrock response = client.retrieve_and_generate( input={\u0026#39;text\u0026#39;: prompt}, retrieveAndGenerateConfiguration={ \u0026#39;type\u0026#39;: \u0026#39;KNOWLEDGE_BASE\u0026#39;, \u0026#39;knowledgeBaseConfiguration\u0026#39;: { \u0026#39;knowledgeBaseId\u0026#39;: KB_ID, \u0026#39;modelArn\u0026#39;: MODEL_ARN } } ) # Lấy kết quả trả về answer = response[\u0026#39;output\u0026#39;][\u0026#39;text\u0026#39;] # (Optional) Hiển thị nguồn trích dẫn citations = response[\u0026#39;citations\u0026#39;][0][\u0026#39;retrievedReferences\u0026#39;] if citations: doc_uri = citations[0][\u0026#39;location\u0026#39;][\u0026#39;s3Location\u0026#39;][\u0026#39;uri\u0026#39;] doc_name = doc_uri.split(\u0026#39;/\u0026#39;)[-1] answer += f\u0026#34;\\n\\n---\\n📚 *Nguồn tham khảo: {doc_name}*\u0026#34; message_placeholder.markdown(answer) st.session_state.messages.append({\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: answer}) except Exception as e: st.error(f\u0026#34;Lỗi: {str(e)}\u0026#34;) Bước 3: Cập nhật Knowledge Base ID:\nDi chuyển con trỏ đến dòng KB_ID = \u0026quot;...\u0026quot;. Xóa nội dung cũ và điền ID của bạn vào (Lấy trong Bedrock Console). Lưu file (Ctrl+O -\u0026gt; Enter) và Thoát (Ctrl+X). Bước 4: Mở giao diện Web\nĐây là bước chuyển từ màn hình console sang giao diện web.\nTại dòng lệnh, chạy server: streamlit run app.py --server.port 8080 Nhìn lên góc phải khung CloudShell, chọn nút Actions (biểu tượng hình vuông). Chọn Preview Web App. Nhập port 8080 Nhấn Preview. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Xây dựng ứng dụng RAG sử dụng Knowledge Bases cho Amazon Bedrock Tổng quan Knowledge Bases for Amazon Bedrock là một tính năng được quản lý hoàn toàn giúp bạn triển khai kỹ thuật RAG (Retrieval-Augmented Generation) bằng cách kết nối các Foundation Models với nguồn dữ liệu nội bộ của bạn để cung cấp các phản hồi chính xác, có trích dẫn và phù hợp với ngữ cảnh.\nRAG là một kỹ thuật để tối ưu hóa đầu ra của Large Language Model (LLM) bằng cách truy xuất thông tin từ cơ sở dữ liệu bên ngoài đáng tin cậy (Retrieval) và thêm nó vào ngữ cảnh (Augmentation) trước khi tạo ra câu trả lời (Generation). Phương pháp này giúp khắc phục những hạn chế về dữ liệu huấn luyện lỗi thời và đảm bảo AI trả lời dựa trên thông tin thực tế được cung cấp.\nTrong bài lab này, chúng ta sẽ học cách xây dựng một trợ lý AI có khả năng \u0026ldquo;đọc và hiểu\u0026rdquo; các tài liệu doanh nghiệp độc quyền. Bạn sẽ thực hiện quy trình từ việc nhập dữ liệu và tạo chỉ mục vector đến cấu hình mô hình để trả lời câu hỏi dựa trên những tài liệu đó mà không cần quản lý bất kỳ máy chủ nào.\nChúng ta sẽ sử dụng ba thành phần chính để thiết lập quy trình xử lý RAG hoàn chỉnh:\nNguồn dữ liệu (Amazon S3) - Đóng vai trò là kho lưu trữ \u0026ldquo;sự thật\u0026rdquo;. Bạn sẽ tải các tài liệu (PDF, Word, Text) lên một S3 bucket. Knowledge Base sẽ sử dụng nguồn này để đồng bộ hóa dữ liệu. Vector Store (OpenSearch Serverless) - Nơi lưu trữ các embeddings vector (dữ liệu được mã hóa bằng số). Khi người dùng đặt câu hỏi, hệ thống sẽ thực hiện tìm kiếm ngữ nghĩa tại đây để trích xuất các đoạn văn bản liên quan nhất thay vì tìm kiếm từ khóa tiêu chuẩn. Foundation Model (Claude 3) - Large Language Model đóng vai trò là bộ não xử lý. Nó nhận câu hỏi của người dùng cùng với thông tin tìm thấy từ Vector Store, sau đó tổng hợp và tạo ra câu trả lời tự nhiên, chính xác kèm theo trích dẫn nguồn. Kết quả đạt được Khi kết thúc workshop, bạn sẽ có một hệ thống Chatbot thực tế, hoạt động với các tính năng sau:\nTrò chuyện hỏi đáp về nội dung tài liệu độc quyền. Câu trả lời chính xác, không có ảo giác (hallucinations). Trích dẫn nguồn (biết chính xác câu trả lời đến từ trang nào). Triển khai nhanh chóng mà không cần viết mã xử lý dữ liệu phức tạp. Nội dung Tổng quan về Workshop Chuẩn bị môi trường Tạo và cấu hình Knowledge Base Kiểm tra Chatbot (RAG) Tích hợp ứng dụng Client (Tùy chọn) Cập nhật dữ liệu Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Ôn tập các khái niệm cơ sở dữ liệu (CSDL) nền tảng, bao gồm RDBMS (khóa chính, khóa ngoại), các kỹ thuật tối ưu (Index, Partition), và các khái niệm về vận hành (Database Log, Buffer). Phân biệt rõ hai loại hệ thống CSDL chính: OLTP (Online Transaction Processing - xử lý giao dịch) và OLAP (Online Analytical Processing - xử lý phân tích hay Kho dữ liệu). Hiểu rõ dịch vụ CSDL quan hệ được quản lý Amazon RDS, bao gồm các tính năng cốt lõi như Multi-AZ (cho tính sẵn sàng cao) và Read Replicas (cho hiệu năng đọc). Tìm hiểu về Amazon Aurora, dịch vụ CSDL cloud-native của AWS, với kiến trúc lưu trữ chia sẻ độc đáo, hiệu năng cao và các tính năng vượt trội như Zero Replication Lag. Tìm hiểu về Amazon Redshift, dịch vụ kho dữ liệu (Data Warehouse) quy mô petabyte, được thiết kế cho OLAP, và hiểu rõ kiến trúc MPP cùng kỹ thuật Columnar Storage. Hiểu về vai trò của Amazon ElastiCache (Redis, Memcached) như một lớp bộ nhớ đệm (caching) tốc độ cao để giảm tải cho CSDL chính. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Database Concepts\n- Bài học: Ôn tập các khái niệm CSDL căn bản như Database (hệ thống thông tin có cấu trúc) và Session (phiên làm việc).\n- Học về kiến trúc: CSDL Quan hệ (RDBMS), bao gồm Primary Key (Khóa chính) để xác định duy nhất một hàng và Foreign Key (Khóa ngoại) để tạo liên kết giữa các bảng.\n- Tìm hiểu về kĩ thuật: Normalization (Chuẩn hóa), là kỹ thuật chia dữ liệu ra nhiều bảng (sử dụng khóa) để chống trùng lặp dữ liệu.\n- Tìm hiểu về kĩ thuật: Tối ưu hiệu năng:\n+ Index (Chỉ mục): Một cấu trúc dữ liệu giúp tăng tốc độ truy xuất (đọc), nhưng làm tăng chi phí ghi.\n+ Partition (Phân vùng): Chia một bảng lớn thành nhiều phần nhỏ để tăng tốc độ truy vấn.\n+ Execution Plan (Kế hoạch thực thi): Là tập hợp các bước mà CSDL quyết định dùng để truy cập dữ liệu (ví dụ: có dùng Index hay không).\n- Tìm hiểu về kĩ thuật: Đảm bảo toàn vẹn và tốc độ:\n+ Database Log (Nhật ký CSDL): Ghi lại tất cả thay đổi, quan trọng cho việc khôi phục (recovery) và đồng bộ hóa (replication).\n+ Buffer (Bộ nhớ đệm): Vùng lưu trữ tạm thời trong RAM, giúp tăng tốc độ đọc vì đọc từ RAM nhanh hơn đọc từ ổ cứng.\n- Bài học: Phân loại CSDL:\n+ RDBMS (ACID): Cấu trúc cố định (Schema), tối ưu lưu trữ (Normalization), mở rộng theo chiều dọc (Vertical Scaling).\n+ NoSQL (BASE): Cấu trúc linh hoạt (Dynamic Schema), tối ưu hiệu năng (Denormalization), mở rộng theo chiều ngang (Horizontal Scaling).\n- Bài học: Phân loại hệ thống:\n+ OLTP (Online Transaction Processing): Hệ thống xử lý giao dịch (ngân hàng, đặt hàng), cần xử lý nhanh các thao tác đọc/ghi/cập nhật và đảm bảo toàn vẹn (roll back).\n+ OLAP (Online Analytical Processing): Hệ thống kho dữ liệu (Data Warehouse), lưu trữ dữ liệu lịch sử để phân tích phức tạp (báo cáo, tìm xu hướng). 13/10/2025 13/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_06/Take_notes_module_06.md 3 Amazon RDS\n- Học về dịch vụ: Amazon RDS (Relational Database Service), một dịch vụ CSDL quan hệ được quản lý hoàn toàn (managed service), hỗ trợ các engine phổ biến (MySQL, PostgreSQL, Oracle, v.v.).\n- Bài học: Mục tiêu của RDS là tự động hóa các tác vụ quản trị (cập nhật, sao lưu) để người dùng tập trung vào ứng dụng.\n- Tìm hiểu về kĩ thuật: Automated Backups (Sao lưu tự động) CSDL và transaction log, cho phép Point-in-Time Recovery (phục hồi tại một thời điểm) trong vòng 35 ngày.\n- Học về kiến trúc: Multi-AZ (High Availability)\n+ Tự động tạo một bản sao standby (dự phòng) ở một AZ khác.\n+ Sử dụng Synchronous Replication (sao chép đồng bộ).\n+ Hỗ trợ Automatic Failover (tự động chuyển đổi) nếu CSDL chính gặp sự cố.\n- Học về kiến trúc: Read Replicas (Tối ưu Hiệu năng Đọc)\n+ Tạo ra các bản sao chỉ đọc để giảm tải cho CSDL chính (ví dụ: cho các tác vụ báo cáo).\n+ Sử dụng Asynchronous Replication (sao chép bất đồng bộ), có thể gây ra \u0026ldquo;replication lag\u0026rdquo; (độ trễ).\n- Bài học: RDS thường được sử dụng cho các ứng dụng OLTP và được bảo vệ bằng Security Group. 14/10/2025 14/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_06/Take_notes_module_06.md 4 Amazon Aurora\n- Học về dịch vụ: Amazon Aurora, một CSDL do AWS phát triển, tương thích MySQL/PostgreSQL, thuộc dịch vụ RDS nhưng có hiệu năng cao hơn (gấp 3-5 lần).\n- Học về kiến trúc: Khác biệt lớn nhất của Aurora là tái thiết kế lại tầng lưu trữ.\n- Học về kiến trúc: Một \u0026ldquo;Cluster\u0026rdquo; Aurora bao gồm 1 Writer (bản ghi) và tối đa 15 Readers (bản đọc), tất cả cùng chia sẻ một phân vùng lưu trữ (Cluster Volume) duy nhất.\n- Tìm hiểu về kĩ thuật: Dữ liệu trên Cluster Volume được nhân bản 6 lần qua 3 AZ để đảm bảo độ bền.\n- Bài học: Ưu điểm vượt trội của Aurora là Zero Replication Lag (không có độ trễ sao chép) vì các bản Readers đọc chung volume với Writer.\n- Tìm hiểu về kĩ thuật: Các tính năng doanh nghiệp như Backtrack (tua ngược CSDL mà không cần restore) và Global Database (tạo bản sao chỉ đọc ở các Region khác nhau). 15/10/2025 15/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_06/Take_notes_module_06.md 5 Amazon Redshift\n- Học về dịch vụ: Amazon Redshift, một dịch vụ Data Warehouse (Kho dữ liệu) quy mô petabyte, được tối ưu cho OLAP.\n- Học về kiến trúc: Massively Parallel Processing (MPP) (Xử lý song song hàng loạt).\n+ Leader Node (Nút Lãnh đạo): Tiếp nhận, phân tích và điều phối truy vấn.\n+ Compute Nodes (Nút Tính toán): Lưu trữ và thực thi các phần công việc song song.\n- Tìm hiểu về kĩ thuật: Columnar Storage (Lưu trữ dạng Cột).\n+ Khác với OLTP (lưu theo hàng), Redshift lưu dữ liệu của cùng một cột gần nhau.\n+ Kỹ thuật này cực kỳ hiệu quả cho các truy vấn phân tích (OLAP) (ví dụ: Tính tuổi trung bình chỉ cần đọc cột Tuổi).\n- Tìm hiểu về kĩ thuật: Redshift Spectrum, cho phép chạy truy vấn SQL trực tiếp trên dữ liệu nằm trong Amazon S3 mà không cần tải về.\nAmazon ElastiCache\n- Học về dịch vụ: Amazon ElastiCache, một dịch vụ bộ nhớ đệm (caching) trong bộ nhớ RAM tốc độ cao.\n- Mục tiêu: Tăng tốc độ ứng dụng và giảm tải cho cơ sở dữ liệu chính (như RDS).\n- Tìm hiểu về các engine hỗ trợ: Redis (hỗ trợ nhiều kiểu dữ liệu, thường được ưu tiên) và Memcached.\n- Bài học: Trách nhiệm của người dùng là phải tự viết và quản lý Caching Logic (logic quyết định cái gì và khi nào cần cache) trong ứng dụng của mình. 16/10/2025 16/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_06/Take_notes_module_06.md 6 Lab: 000005 - Bắt đầu với Amazon RDS\n1. Tạo cơ sở dữ liệu (database) trên Amazon RDS\n2. Kết nối ứng dụng vào CSDL\n3. Sao lưu và Phục hồi\nLab: 000043 - Dịch chuyển CSDL với DMS và SCT\n1. Các bước chuẩn bị\n2. Oracle sang Amazon Aurora (PostgreSQL)\n2.1 Chuyển dổi Schema\n2.2 Dịch chuyển cơ sở dữ liệu. [Nghiên cứu bổ sung] - Database Internals\n- Tài liệu tìm hiểu cách thức vận hành bên trong của cơ sở dữ liệu. Link: [https://www.amazon.com/Database-Internals-Deep-Distributed-Systems/dp/1492040347]\n[Nghiên cứu bổ sung] - The Data Warehouse Toolkit\n- Tài liệu tìm hiểu cách thức thiết kế và các kỹ thuật được sử dụng trong việc xây dựng Data-warehouse\nLink: [https://www.amazon.com/Data-Warehouse-Toolkit-Definitive-Dimensional/dp/1118530802] 17/10/2025 17/10/2025 Documentation: https://cloudjourney.awsstudygroup.com/\nYoutube: https://youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026si=W80Cdf_fSc6sjOV\nNotes: https://github.com/DazielNguyen/aws-fcj-report/blob/main/TAKE_NOTES_%26_LABS/Module_06/Take_notes_module_06.md Kết quả đạt được tuần 6: Bài học (Nền tảng): Phân biệt rõ ràng hai mô hình hệ thống: OLTP (Online Transaction Processing - xử lý giao dịch) và OLAP (Online Analytical Processing - xử lý phân tích, kho dữ liệu). Nắm vững các kỹ thuật tối ưu CSDL cơ bản: Index (tăng tốc độ đọc) và Partition (chia nhỏ bảng). Hiểu vai trò của Database Log (để khôi phục/đồng bộ) và Buffer (dùng RAM để tăng tốc). Dịch vụ (RDS): Biết Amazon RDS là dịch vụ CSDL quan hệ (OLTP) được quản lý. Phân biệt rõ 2 tính năng chính của RDS: Multi-AZ (dùng cho tính Sẵn sàng cao - HA) và Read Replicas (dùng để tăng hiệu năng đọc). Kĩ thuật (Replication): Phân biệt Synchronous Replication (Sao chép đồng bộ - dùng cho RDS Multi-AZ) và Asynchronous Replication (Sao chép bất đồng bộ - dùng cho RDS Read Replicas, có thể bị trễ). Dịch vụ (Aurora): Biết Amazon Aurora là CSDL hiệu năng cao, cloud-native. Hiểu kiến trúc lưu trữ chia sẻ (Cluster Volume) của Aurora và lợi ích vượt trội là Zero Replication Lag (không có độ trễ). Nắm được các tính năng cao cấp như Backtrack và Global Database. Dịch vụ (Redshift): Biết Amazon Redshift là dịch vụ kho dữ liệu (OLAP). Hiểu kiến trúc MPP (Massively Parallel Processing) (gồm Leader Node và Compute Nodes). Nắm vững kỹ thuật cốt lõi của OLAP: Columnar Storage (Lưu trữ dạng Cột), giúp tăng tốc các truy vấn phân tích. Dịch vụ (ElastiCache): Biết Amazon ElastiCache (Redis/Memcached) là dịch vụ caching trong RAM. Hiểu vai trò của caching là giảm tải cho CSDL chính. Nhận thức được trách nhiệm phải tự viết Caching Logic trong ứng dụng. Thực hành: Biết cách tạo và vận hành (backup/restore) một CSDL RDS. Biết cách sử dụng dịch vụ DMS và SCT để dịch chuyển (migrate) CSDL từ Oracle sang Aurora. "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.6-update-data/",
	"title": "Cập nhật dữ liệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Một trong những lợi thế lớn nhất của RAG so với Fine-tuning (huấn luyện lại) mô hình là khả năng cập nhật dữ liệu nhanh chóng. Khi doanh nghiệp có quy định mới, bạn chỉ cần nhập chúng vào Knowledge Base, và AI sẽ \u0026ldquo;học\u0026rdquo; chúng ngay lập tức.\nTrong phần này, chúng ta sẽ mô phỏng kịch bản sau:\nHỏi AI về một thông tin không tồn tại (AI sẽ trả lời là không biết). Cung cấp thông tin đó cho hệ thống bằng cách tải lên file mới. Hỏi lại câu hỏi tương tự để chứng kiến AI trả lời đúng ngay lập tức. Các Bước Thực hiện Bước 1: Xác minh \u0026ldquo;thiếu kiến thức\u0026rdquo; ban đầu\nChúng ta cần xác nhận rằng AI hiện tại không biết gì về thông tin bí mật mà chúng ta sắp tạo.\nQuay lại giao diện Streamlit Chatbot (được tạo trong Phần 5) hoặc sử dụng cửa sổ Test Knowledge Base trên Console. Đặt một câu hỏi về thông tin giả định không có thật. Ví dụ: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Quan sát kết quả: AI sẽ trả lời rằng không thể tìm thấy thông tin trong các tài liệu được cung cấp hoặc sẽ cố gắng đưa ra câu trả lời chung chung (nếu không bị hạn chế). Bước 2: Tạo dữ liệu mới\nChúng ta sẽ tạo một file văn bản chứa \u0026ldquo;bí mật\u0026rdquo; này để nhập vào hệ thống.\nTrên máy tính của bạn, mở Notepad (Windows) hoặc TextEdit (Mac). Sao chép và dán nội dung sau vào file: THÔNG BÁO MẬT: Dự án Omega bí mật chính thức khởi động vào ngày 01/12/2025. Mã kích hoạt là: \u0026#34;AWS-ROCKS-2025-SINGAPORE\u0026#34;. Người Quản lý Dự án là Ông Robot. Vui lòng giữ thông tin này tuyệt đối bí mật. Lưu file với tên: secret-project.txt. Bước 3: Tải lên và Đồng bộ\nBây giờ, chúng ta sẽ cung cấp kiến thức mới này vào \u0026ldquo;bộ não\u0026rdquo; của AI.\nTruy cập S3 Console, điều hướng đến bucket cũ của bạn (rag-workshop-\u0026lt;tên-của-bạn\u0026gt;). Nhấp Upload -\u0026gt; Add files -\u0026gt; Chọn file secret-project.txt -\u0026gt; Upload. Chuyển sang Amazon Bedrock Console -\u0026gt; Chọn Knowledge bases từ menu bên trái. Nhấp vào tên Knowledge Base của bạn. Cuộn xuống phần Data source, chọn nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Chờ khoảng 30 giây đến 1 phút cho đến khi cột Status chuyển từ Syncing sang Available. Bước 4: Xác minh lại (Khoảnh khắc \u0026ldquo;Wow\u0026rdquo;)\nHệ thống hiện đã có kiến thức mới. Hãy thách thức AI một lần nữa.\nQuay lại giao diện Streamlit Chatbot (Không cần tải lại trang hoặc khởi động lại server). Hỏi chính xác câu hỏi tương tự như trước: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Kết quả mong đợi: AI trả lời chính xác: \u0026ldquo;Mã kích hoạt là AWS-ROCKS-2025-SINGAPORE\u0026rdquo;. AI trích dẫn nguồn là file secret-project.txt. Kết luận Bạn vừa chứng kiến sức mạnh thực sự của RAG!\nKhông cần chỉnh sửa code. Không cần huấn luyện lại mô hình. Chỉ cần Sync dữ liệu. Chatbot của bạn đã trở nên thông minh hơn và cập nhật với thông tin mới nhất chỉ trong vài bước đơn giản. Đây chính là lý do tại sao các doanh nghiệp chọn giải pháp này để xây dựng trợ lý ảo nội bộ.\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/5-workshop/5.7-cleanup/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/aws-fcj-report/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]